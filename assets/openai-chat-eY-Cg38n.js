const e="openai-chat",t="OpenAI Chat Completions",n={baseUrl:"https://api.openai.com",endpoints:{chat:"/v1/chat/completions"}},o={type:"bearer",header:"Authorization",envVar:"OPENAI_API_KEY"},s={defaultConcurrency:8,maxConcurrency:64,description:"OpenAI API - high concurrency supported"},r={"Content-Type":"application/json"},i=[{pattern:"^o[0-9]",name:"O-Series (Reasoning Models)",params:{max_completion_tokens:{type:"integer",description:"Maximum tokens for completion including reasoning",min:1,default:128,is_output_length:!0,basic:!0},reasoning_effort:{type:"string",description:"Reasoning effort level",enum:["low","medium","high"],basic:!1}},forbidden:["temperature","top_p","frequency_penalty","presence_penalty","stop"]},{pattern:"^gpt",name:"GPT Models",params:{temperature:{type:"number",description:"Sampling temperature",min:0,max:2,default:0,basic:!0},max_completion_tokens:{type:"integer",description:"Maximum tokens for completion",min:1,default:128,is_output_length:!0,basic:!0},top_p:{type:"number",description:"Nucleus sampling threshold",min:0,max:1,basic:!1},frequency_penalty:{type:"number",description:"Penalize frequent tokens",min:-2,max:2,basic:!1},presence_penalty:{type:"number",description:"Penalize tokens based on presence",min:-2,max:2,basic:!1},stop:{type:"array",description:"Stop sequences",basic:!1},seed:{type:"integer",description:"Seed for deterministic outputs",basic:!1},response_format:{type:"object",description:"Response format (text, json_object, or json_schema)",basic:!1},logprobs:{type:"boolean",description:"Include log probabilities",basic:!1},top_logprobs:{type:"integer",description:"Number of top log probabilities",min:0,max:20,basic:!1},n:{type:"integer",description:"Number of completions to generate",basic:!1},user:{type:"string",description:"User identifier for tracking",basic:!1}}}],a={text:{id:"text",label:"Text",description:"Standard text response",parameters:{},responseTransform:{contentPath:"choices[0].message.content",fallbackPaths:["choices[0].text","message.content"],errorPath:"error.message"}},json_mode:{id:"json_mode",label:"JSON Mode",description:"Structured JSON output",parameters:{response_format:{type:"json_object"}},promptTransform:{append:"\nPlease respond with a JSON object in the form {'answer': answer}"},responseTransform:{contentPath:"choices[0].message.content",fallbackPaths:["choices[0].text","message.content"],errorPath:"error.message",isJSON:!0}},function_calling:{id:"function_calling",label:"Function Calling",description:"Call functions with structured parameters",parameters:{tools:[{type:"function",function:{name:"provide_answer",description:"Provides the answer to the question",parameters:{type:"object",properties:{answer:{type:"string",description:"The answer value"}},required:["answer"]}}}],tool_choice:{type:"function",function:{name:"provide_answer"}}},responseTransform:{contentPath:"choices[0].message.tool_calls[0].function.arguments",fallbackPaths:["choices[0].message.content"],errorPath:"error.message",isJSON:!0}}},p={promptKey:"messages",wrapPrompt:!0,messageRole:"user"},c={id:e,name:t,api:n,auth:o,execution:s,headers:r,modelRules:i,responseModes:a,requestTransform:p};export{n as api,o as auth,c as default,s as execution,r as headers,e as id,i as modelRules,t as name,p as requestTransform,a as responseModes};
