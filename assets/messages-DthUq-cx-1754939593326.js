const e="anthropic",t="Anthropic Messages",s="/v1/messages",r=[{type:"validation_rule",config:{condition:"messages_present",requiredFields:["max_tokens"],errorMessage:"max_tokens is required for Anthropic API",description:"Enforce that max_tokens parameter is provided"}}],o={promptTokensPath:"usage.input_tokens",completionTokensPath:"usage.output_tokens",totalTokensPath:"usage.total_tokens"},n=[{pattern:"^claude",name:"Claude Models",params:{max_tokens:{type:"integer",description:"Maximum tokens to generate",min:1,max:16384,default:128,basic:!0,required:!0,is_output_length:!0},temperature:{type:"number",description:"Sampling temperature",min:0,max:1,default:0,basic:!0}}}],a={text:{id:"text",label:"Text",description:"Standard text response",parameters:{},responseTransform:{contentPath:"content[0].text",fallbackPaths:["content[0]","content"],errorPath:"error.message"}}},i={promptKey:"messages",wrapPrompt:!0,messageRole:"user"},m={id:e,name:t,endpoint:s,requestTransforms:r,usageExtraction:o,modelRules:n,responseModes:a,requestTransform:i};export{m as default,s as endpoint,e as id,n as modelRules,t as name,i as requestTransform,r as requestTransforms,a as responseModes,o as usageExtraction};
