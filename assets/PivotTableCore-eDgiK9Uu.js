import{_ as e}from"./BaseModal.vue_vue_type_style_index_0_lang-D3rbY83j.js";import{d as t,a6 as a,Y as n,a1 as l,_ as r,ag as s,f as o,c as i,o as c,b as d,k as u,Z as p,H as m,u as f,W as v,F as g,a8 as b,G as h,a0 as y,a7 as _,V as C,n as k,w,B as x,ab as S,s as I,al as P,ae as T,ad as E,q as M,aj as A}from"./vendor-DImCB_rW.js";import{_ as N,l as $,q as F,z as O,a as R,u as D,p as j,f as q,E as L,t as U,d as z,G as B,A as V,H as K,J as G,K as Y}from"./index-C3IQIdkL.js";import{u as H}from"./designs-db-CQk2xSLK.js";import{u as J}from"./variables-db-BA-HAITb.js";import{u as W}from"./models-db-DWfdcSHr.js";import{u as X}from"./useEnvironmentalCost-BGQiHcVF.js";import{a as Q}from"./cost-formatting-Bv_drrqY.js";import{G as Z}from"./GenericModelSelectorModal-Cw_itTNt.js";const ee={class:"modal-footer"},te={key:0,class:"footer-left"},ae={class:"footer-actions"},ne=N(t({__name:"ModalFooter",setup:e=>(e,t)=>(n(),a("div",ee,[e.$slots.left?(n(),a("div",te,[s(e.$slots,"left",{},void 0,!0)])):l("",!0),r("div",ae,[s(e.$slots,"default",{},void 0,!0)])]))}),[["__scopeId","data-v-3a3879d0"]]);const le={class:"design-selection-step"},re={class:"step-body"},se={class:"design-selector","data-testid":"design-selector"},oe={key:0,class:"no-designs-state"},ie={class:"no-designs-content"},ce={key:1,class:"design-list","data-testid":"design-list"},de=["data-design-id","data-design-name","onClick"],ue={class:"design-header"},pe={class:"design-title-section"},me={class:"design-name"},fe={key:0,class:"design-inline-description"},ve={class:"design-date"},ge=["innerHTML"],be={class:"design-stats"},he={class:"stat-item"},ye={class:"stat-value"},_e={class:"stat-item"},Ce={class:"stat-value"},ke={class:"stat-item"},we={class:"stat-value"},xe=N(t({__name:"DesignSelectionStep",emits:["select","create-new"],setup(e){const t=H(),{designSearch:s,filteredDesigns:_,countVariables:C,formatLastEditDate:k,getOutputTypeColor:w,getCombinationCount:x,getPreviewTemplateHTML:S}=function(){const e=H(),t=J(),a=o(""),n=o(0);let l=null;const r=i(()=>{const t=e.designs;if($.info("Designs available",{count:t.length}),!a.value)return t;const n=a.value.toLowerCase();return t.filter(e=>e.name.toLowerCase().includes(n)||e.promptTemplate.toLowerCase().includes(n))});function s(e){return e.replace(/\n+/g," ").replace(/\s+/g," ").trim()}function u(e){if(!e.variableBindings)return[{}];const a=[];for(const[l,r]of Object.entries(e.variableBindings))if("direct"===r.type&&r.values)a.push({name:l,values:r.values});else if("list"===r.type&&r.listId){const e=t.lists.find(e=>e.id===r.listId);if(e){let t=[];t="simple"===e.category&&e.values?e.values:"attributed"===e.category&&e.items?e.items.map(e=>e.value):[`${l}_sample`],a.push({name:l,values:t})}}if(0===a.length)return[{}];const n=[...a.map(e=>e.values).reduce((e,t)=>e.flatMap(e=>t.map(t=>[...e,t])),[[]])];for(let t=n.length-1;t>0;t--){const e=Math.floor(Math.random()*(t+1));[n[t],n[e]]=[n[e],n[t]]}return n.map(e=>{const t={};return a.forEach((a,n)=>{t[a.name]=e[n]}),t})}function p(e){const t=document.createElement("div");return t.textContent=e,t.innerHTML}function m(){l||(l=setInterval(()=>{n.value++},1e3))}function f(){l&&(clearInterval(l),l=null)}return c(()=>{m()}),d(()=>{f()}),{designSearch:a,previewCycleIndex:n,filteredDesigns:r,countVariables:function(e){return Object.keys(e.variableBindings).length},truncateTemplate:s,formatLastEditDate:function(e){const t=new Date,a=t.getTime()-e.getTime(),n=Math.floor(a/864e5);if(0===n)return"Today";if(1===n)return"Yesterday";if(n<7)return`${n} days ago`;if(n<30){const e=Math.floor(n/7);return`${e} week${e>1?"s":""} ago`}return e.toLocaleDateString("en-US",{month:"short",day:"numeric",year:e.getFullYear()!==t.getFullYear()?"numeric":void 0})},getOutputTypeColor:function(e){return{text:"blue",number:"green",boolean:"purple",json:"orange"}[e]||"default"},getCombinationCount:function(e){if(!e.variableBindings)return"1";let a=1;for(const n of Object.values(e.variableBindings))if("direct"===n.type&&n.values)a*=n.values.length;else if("list"===n.type&&n.listId){const e=t.lists.find(e=>e.id===n.listId);a*=e?.itemCount||1}return a>1e3?`${(a/1e3).toFixed(1)}k`:a.toString()},generateVariableCombinations:u,getPreviewTemplateHTML:function(e){const t=u(e);if(t.length<=1)return p(s(e.promptTemplate));const a=t[n.value%t.length],l=["variable-highlight-blue","variable-highlight-green","variable-highlight-purple","variable-highlight-orange","variable-highlight-pink","variable-highlight-teal"];let r=e.promptTemplate;Object.keys(e.variableBindings||{}).forEach((e,t)=>{if(void 0!==a[e]){const n=new RegExp(`\\{\\{\\s*${e}\\s*\\}\\}`,"g"),s=`<span class="${l[t%l.length]}">${p(String(a[e]))}</span>`;r=r.replace(n,s)}});let o=p(r);return l.forEach(e=>{o=o.replace(new RegExp(`&lt;span class="${e}"&gt;`,"g"),`<span class="${e}">`).replace(/&lt;\/span&gt;/g,"</span>")}),s(o)},escapeHtml:p,startCycling:m,stopCycling:f}}();return(e,o)=>{const i=v("a-input"),c=v("a-button"),d=v("a-tag");return n(),a("div",le,[o[11]||(o[11]=r("div",{class:"step-header"},[r("h3",null,"What are you testing?")],-1)),r("div",re,[r("div",se,[u(i,{value:f(s),"onUpdate:value":o[0]||(o[0]=e=>m(s)?s.value=e:null),placeholder:"Search designs...",size:"large",class:"design-search","data-testid":"input-design-search",allowClear:""},{prefix:p(()=>[u(f(O))]),_:1},8,["value"]),0===f(_).length?(n(),a("div",oe,[r("div",ie,[o[4]||(o[4]=r("p",null,"No designs found",-1)),u(c,{onClick:o[1]||(o[1]=()=>f(t).initialize())},{default:p(()=>o[3]||(o[3]=[h("Refresh Designs")])),_:1,__:[3]})])])):(n(),a("div",ce,[(n(!0),a(g,null,b(f(_),t=>(n(),a("div",{key:t.id,class:"design-item","data-testid":"design-item","data-design-id":t.id,"data-design-name":t.name,onClick:a=>e.$emit("select",t)},[r("div",ue,[r("div",pe,[r("h4",me,[h(y(t.name)+" ",1),t.description?(n(),a("span",fe,"- "+y(t.description),1)):l("",!0)])]),r("span",ve,y(f(k)(t.updated)),1)]),r("p",{class:"design-description",innerHTML:f(S)(t)},null,8,ge),r("div",be,[u(d,{size:"small",color:f(w)(t.outputType),class:"output-type-tag"},{default:p(()=>[h(y(t.outputType||"text"),1)]),_:2},1032,["color"]),r("span",he,[r("span",ye,y(f(C)(t)),1),o[5]||(o[5]=r("span",{class:"stat-label"},"vars",-1))]),o[8]||(o[8]=r("span",{class:"stat-divider"},"•",-1)),r("span",_e,[r("span",Ce,y(f(x)(t)),1),o[6]||(o[6]=r("span",{class:"stat-label"},"combos",-1))]),o[9]||(o[9]=r("span",{class:"stat-divider"},"•",-1)),r("span",ke,[r("span",we,y(t.tokenEstimate?.avgTokens||"?"),1),o[7]||(o[7]=r("span",{class:"stat-label"},"tokens",-1))])])],8,de))),128)),r("div",{class:"design-card design-card-create","data-testid":"btn-create-design",onClick:o[2]||(o[2]=t=>e.$emit("create-new"))},[u(f(F),{style:{"font-size":"24px"}}),o[10]||(o[10]=r("span",null,"Create New Design",-1))])]))])])])}}}),[["__scopeId","data-v-355d68e6"]]),Se={class:"trial-metadata-form"},Ie={class:"form-section"},Pe={class:"trial-name-section"},Te={class:"repeat-section"},Ee={class:"form-stats"},Me={class:"stat-item"},Ae={class:"stat-value"},Ne={class:"stat-item"},$e={class:"stat-value"},Fe=N(t({__name:"TrialMetadataForm",props:{modelValue:{},totalCombinations:{}},emits:["update:modelValue"],setup(e,{emit:t}){const l=e,s=t;function o(e){s("update:modelValue",{...l.modelValue,trialName:e})}function i(e){s("update:modelValue",{...l.modelValue,repeatCount:e||1})}return(e,t)=>{const l=v("a-input"),s=v("a-input-number");return n(),a("div",Se,[r("div",Ie,[r("div",Pe,[t[0]||(t[0]=r("label",{class:"form-label"},"Trial Name:",-1)),u(l,{value:e.modelValue.trialName,"onUpdate:value":o,placeholder:"Enter trial name (optional)",class:"trial-name-input","data-testid":"input-trial-name",size:"large"},null,8,["value"])]),r("div",Te,[t[1]||(t[1]=r("label",{class:"form-label"},"Repeat Each Prompt:",-1)),u(s,{value:e.modelValue.repeatCount,"onUpdate:value":i,min:1,max:10,size:"large",class:"repeat-count-input"},null,8,["value"]),t[2]||(t[2]=r("span",{class:"repeat-suffix"},"times",-1))])]),r("div",Ee,[r("div",Me,[t[3]||(t[3]=r("span",{class:"stat-label"},"Total Combinations:",-1)),r("span",Ae,y(e.totalCombinations),1)]),r("div",Ne,[t[4]||(t[4]=r("span",{class:"stat-label"},"API Calls per Model:",-1)),r("span",$e,y(e.totalCombinations*e.modelValue.repeatCount),1)])])])}}}),[["__scopeId","data-v-540c5b26"]]),Oe={class:"model-configuration-section"},Re={class:"quick-add-row"},De={class:"quick-add-section"},je={class:"quick-add-buttons"},qe={key:0,class:"quick-cost"},Le={key:0,class:"config-table","data-testid":"model-config-table"},Ue=["data-config-index","data-provider","data-model"],ze={class:"col-model"},Be={class:"model-name"},Ve={class:"model-provider"},Ke={class:"col-params"},Ge={class:"params-text"},Ye={class:"col-calls"},He={class:"calls-breakdown"},Je={class:"calls-value"},We={class:"col-cost"},Xe={class:"cost-breakdown"},Qe={key:0,class:"cost-value"},Ze={key:1,class:"env-cost"},et={class:"col-total"},tt={class:"cost-breakdown"},at={key:0,class:"cost-value total-cost"},nt={key:1,class:"env-cost"},lt={class:"col-actions"},rt={key:0,class:"table-summary-row"},st={class:"col-model"},ot={class:"summary-label"},it={class:"col-calls"},ct={class:"summary-calls"},dt={class:"col-total"},ut={key:0,class:"summary-cost"},pt={key:1,class:"empty-config-state"},mt=N(t({__name:"ModelConfigurationSection",props:{configurations:{},design:{},totalCombinations:{},repeatCount:{}},emits:["show-model-selector","add","remove"],setup(e,{emit:t}){const s=e,o=t,c=W(),d=R(),m=D(),{hasDataForModel:w}=X(),x=i(()=>d.financialCostsEnabled),S=i(()=>d.environmentalCostsEnabled),I=i(()=>s.totalCombinations*s.configurations.length*s.repeatCount),P=i(()=>{let e=0;for(const t of s.configurations)e+=N(t)*s.totalCombinations*s.repeatCount;return e}),T=i(()=>{const e=e=>d.hasApiKey(e),t=(e,t)=>!!c.enabledModels.find(a=>a.provider===e&&a.modelId===t&&a.enabled),a=[],n=new Set,l=[...m.trials].sort((e,t)=>new Date(t.created).getTime()-new Date(e.created).getTime());for(const c of l){if(a.length>=5)break;for(const l of c.configurationSnapshots||[]){if(a.length>=5)break;const r=`${l.provider}:${l.modelId}:${JSON.stringify(l.parameters)}`;if(!n.has(r)&&e(l.provider)&&t(l.provider,l.modelId)){const e=j.getParametersForModel(l.provider,l.modelId);if(!e)continue;if(Object.keys(l.parameters).some(t=>!(t in e)))continue;n.add(r),a.push({provider:l.provider,modelId:l.modelId,displayName:l.modelId,parameters:l.parameters,outputType:"text"})}}}const r=(e,t)=>{const a=j.getParametersForModel(e,t),n={},l=(e,t)=>{Object.entries(e).forEach(([e,a])=>{"object"===a.type&&a.properties?(t[e]={},l(a.properties,t[e])):void 0!==a.default&&(t[e]=a.default)})};l(a,n),n.temperature||!n.options||n.options.temperature||(n.options?n.options.temperature=0:n.temperature=0);const r=(e,t)=>{for(const[a,n]of Object.entries(e))"object"===n.type&&n.properties?(t[a]||(t[a]={}),r(n.properties,t[a])):n.is_output_length&&void 0===t[a]&&(t[a]=128)};return r(a,n),n},s=[{provider:"openai-chat",modelId:"gpt-4.1-nano",displayName:"gpt-4.1-nano",parameters:r("openai-chat","gpt-4.1-nano"),outputType:"text"},{provider:"anthropic",modelId:"claude-3-haiku-20240307",displayName:"claude-3-haiku-20240307",parameters:r("anthropic","claude-3-haiku-20240307"),outputType:"text"}],o=new Set(a.map(e=>`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`));for(const c of s){const n=`${c.provider}:${c.modelId}:${JSON.stringify(c.parameters)}`;!o.has(n)&&e(c.provider)&&t(c.provider,c.modelId)&&a.push(c)}const i=[],u=new Set;for(const c of a){const e=`${c.provider}:${c.modelId}`;u.has(e)||(u.add(e),i.push(c))}return i.slice(0,7)});function E(e){const t=[];for(const[a,n]of Object.entries(e))null!=n&&t.push(`${a}=${n}`);return t.join(", ")||"Default settings"}function M(e){return s.configurations.some(t=>t.provider===e.provider&&t.modelId===e.modelId&&JSON.stringify(t.parameters)===JSON.stringify(e.parameters))}function A(e){const t=c.enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t||!s.design)return 0;const a=s.design.tokenEstimate?.avgTokens||0,n=j.getParametersForModel(e.provider,e.modelId);let l=0;for(const[r,s]of Object.entries(n))if(s.is_output_length&&e.parameters[r]){l=e.parameters[r];break}if(0===a||0===l)return 0;return((t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*l)*s.totalCombinations*s.repeatCount}function N(e){const t=c.enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t||!s.design)return 0;const a=s.design.tokenEstimate?.avgTokens||0,n=j.getParametersForModel(e.provider,e.modelId);let l=0;for(const[r,s]of Object.entries(n))if(s.is_output_length&&e.parameters[r]){l=e.parameters[r];break}if(0===a||0===l)return 0;return(t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*l}function $(e){return N(e)*s.totalCombinations*s.repeatCount}function O(e){return w(e.provider,e.modelId)}function q(e,t){return"per-call"===t?"<1mg CO₂e":"~10mg CO₂e"}return(e,t)=>{const s=v("a-button");return n(),a("div",Oe,[r("div",Re,[u(s,{onClick:t[0]||(t[0]=t=>e.$emit("show-model-selector")),type:"primary",size:"large",class:"big-add-model-btn","data-testid":"btn-add-model","aria-label":"Add Model Configuration"},{default:p(()=>[u(f(F)),t[1]||(t[1]=h(" Add Model "))]),_:1,__:[1]}),t[3]||(t[3]=r("div",{class:"separator-bar"},null,-1)),r("div",De,[t[2]||(t[2]=r("div",{class:"quick-add-label"},"Quick add recent/popular models (with default temperature=0, max response length = 128):",-1)),r("div",je,[(n(!0),a(g,null,b(T.value,e=>(n(),C(s,{key:`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`,onClick:t=>function(e){M(e)||(o("add",{name:e.displayName,provider:e.provider,modelId:e.modelId,parameters:e.parameters}),k(()=>{const e=document.querySelector(".ant-modal-body");e&&e.scrollTo({top:e.scrollHeight,behavior:"smooth"})}))}(e),size:"small",class:"quick-preset-btn",disabled:M(e),"data-testid":"quick-add-model","data-provider":e.provider,"data-model":e.modelId,"aria-label":`Quick add ${e.displayName} model`},{default:p(()=>[h(y(e.displayName)+" ",1),x.value?(n(),a("span",qe,y(f(Q)(A(e))),1)):l("",!0)]),_:2},1032,["onClick","disabled","data-provider","data-model","aria-label"]))),128))])])]),e.configurations.length>0?(n(),a("div",Le,[t[8]||(t[8]=_('<div class="table-header" data-v-82ddd342><div class="col-model" data-v-82ddd342>Model</div><div class="col-params" data-v-82ddd342>Parameters</div><div class="col-calls" data-v-82ddd342>API Calls</div><div class="col-cost" data-v-82ddd342>Cost per Call</div><div class="col-total" data-v-82ddd342>Total Cost</div><div class="col-actions" data-v-82ddd342>Actions</div></div>',1)),(n(!0),a(g,null,b(e.configurations,(o,i)=>(n(),a("div",{key:i,class:"table-row","data-testid":"model-config-row","data-config-index":i,"data-provider":o.provider,"data-model":o.modelId},[r("div",ze,[r("div",Be,y(o.provider)+":"+y(o.modelId),1),r("div",Ve,y(o.provider),1)]),r("div",Ke,[r("span",Ge,y(E(o.parameters)),1)]),r("div",Ye,[r("span",He,y(e.totalCombinations)+" × "+y(e.repeatCount)+" = ",1),r("span",Je,y(e.totalCombinations*e.repeatCount),1)]),r("div",We,[r("div",Xe,[x.value?(n(),a("span",Qe,y(f(Q)(N(o))),1)):l("",!0),S.value&&O(o)?(n(),a("small",Ze,y(q(0,"per-call")),1)):l("",!0)])]),r("div",et,[r("div",tt,[x.value?(n(),a("span",at,y(f(Q)($(o))),1)):l("",!0),S.value&&O(o)?(n(),a("small",nt,y(q(0,"total")),1)):l("",!0)])]),r("div",lt,[u(s,{type:"text",size:"small",danger:"",onClick:t=>e.$emit("remove",i),class:"remove-btn","data-testid":"remove-model-config","data-config-index":i,"aria-label":`Remove ${o.provider} ${o.modelId} configuration`},{default:p(()=>t[4]||(t[4]=[h("Remove")])),_:2,__:[4]},1032,["onClick","data-config-index","aria-label"])])],8,Ue))),128)),e.configurations.length>1?(n(),a("div",rt,[r("div",st,[r("div",ot,"TOTAL ("+y(e.configurations.length)+" models)",1)]),t[5]||(t[5]=r("div",{class:"col-params"},null,-1)),r("div",it,[r("span",ct,y(I.value),1)]),t[6]||(t[6]=r("div",{class:"col-cost"},null,-1)),r("div",dt,[x.value?(n(),a("span",ut,y(f(Q)(P.value)),1)):l("",!0)]),t[7]||(t[7]=r("div",{class:"col-actions"},null,-1))])):l("",!0)])):(n(),a("div",pt,t[9]||(t[9]=[r("p",null,"No models configured yet. Add at least one model to continue.",-1)])))])}}}),[["__scopeId","data-v-82ddd342"]]);const ft={key:0,class:"trial-creation-form"},vt={class:"streamlined-content"},gt={class:"content-section"},bt={class:"section-header"},ht={class:"section-body"},yt={key:1,class:"selected-design-with-template"},_t={class:"unified-header"},Ct={class:"combinations-count"},kt={class:"header-controls"},wt=["innerHTML"],xt={key:0,class:"content-section","data-testid":"trial-config-section"},St={class:"section-body"},It={class:"model-section"},Pt={class:"tab-footer"},Tt={class:"footer-actions"},Et={class:"streamlined-content"},Mt={class:"content-section"},At={class:"section-header"},Nt={class:"section-body"},$t={key:1,class:"selected-design-with-template"},Ft={class:"unified-header"},Ot={class:"combinations-count"},Rt={class:"header-controls"},Dt=["innerHTML"],jt={key:0,class:"content-section","data-testid":"trial-config-section"},qt={class:"section-body"},Lt={class:"model-section"},Ut=N(t({__name:"TrialCreationModalNew",props:{initialDesignId:{},trialToDuplicate:{},isEditMode:{type:Boolean},isTabMode:{type:Boolean}},emits:["close","created","created-and-started","export-trial"],setup(t,{emit:s}){const c=t,d=s,m=D(),g=o(null),b=o(""),_=o(1),k=o([]),x=o(!1),S=o(null),I=function(e){const t=H(),a=J(),n=W(),l=D(),r=R(),s=o(null),c=o(""),d=o(1),u=o([]),p=o(!1),m=o(!1),f=o(!1),v=o(!1),g=i(()=>{if(!s.value)return 0;let e=1;for(const t of Object.values(s.value.variableBindings))if("direct"===t.type)e*=t.values?.length||1;else if(t.listId){const n=a.lists.find(e=>e.id===t.listId);e*=n?.itemCount||1}return e}),b=i(()=>g.value*u.value.length*d.value),h=i(()=>{let e=0;for(const t of u.value)e+=k(t)*g.value*d.value;return e}),y=i(()=>null!==s.value&&u.value.length>0);function _(e){s.value=e,c.value=C(e),f.value=!0}function C(e){return e||s.value?`${e?.name||s.value?.name||"Trial"} - ${(new Date).toLocaleString("en-US",{month:"short",day:"numeric",hour:"2-digit",minute:"2-digit"})}`:"New Trial"}function k(e){const t=n.enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t)return 0;const a=s.value?.tokenEstimate?.avgTokens||0,l=j.getParametersForModel(e.provider,e.modelId);let r=0;for(const[n,s]of Object.entries(l))if(s.is_output_length&&e.parameters[n]){r=e.parameters[n];break}return 0===a||0===r?0:(t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*r}return{selectedDesign:s,trialName:c,repeatCount:d,configurations:u,creating:p,showModelSelector:m,liveUpdatePaused:f,showPlaceholders:v,totalCombinations:g,totalExperiments:b,totalCost:h,canProceed:y,selectDesign:_,generateTrialName:C,addConfiguration:function(e){u.value.push(e)},removeConfiguration:function(e){u.value.splice(e,1)},getConfigCostPerCall:k,createDraftTrial:async function(){if(s.value&&0!==u.value.length){p.value="draft";try{const e=await l.createTrial({name:c.value||C(),designId:s.value.id,configurations:u.value.map(e=>({name:e.name,provider:e.provider,modelId:e.modelId,parameters:JSON.parse(JSON.stringify(e.parameters||{}))})),repeatConfig:d.value>1?{callsPerPrompt:d.value,strategy:"sequential"}:void 0});return q.success("Trial created as draft!"),e}catch(e){throw $.error("Failed to create draft trial",e),q.error("Failed to create draft trial"),e}finally{p.value=!1}}},createAndStartTrial:async function(){if(s.value&&0!==u.value.length){p.value="start";try{const e=await l.createTrial({name:c.value||C(),designId:s.value.id,configurations:u.value.map(e=>({name:e.name,provider:e.provider,modelId:e.modelId,parameters:JSON.parse(JSON.stringify(e.parameters||{}))})),repeatConfig:d.value>1?{callsPerPrompt:d.value,strategy:"sequential"}:void 0});return q.success("Trial created! Starting execution..."),setTimeout(async()=>{try{await l.executeTrial(e)}catch(t){$.error("Failed to start trial",t),q.error("Failed to start trial execution")}},100),e}catch(e){throw $.error("Failed to create trial",e),q.error("Failed to create trial"),e}finally{p.value=!1}}},createAndExportTrial:async function(){if(s.value&&0!==u.value.length){p.value="export";try{const e=await l.createTrial({name:c.value||C(),designId:s.value.id,configurations:u.value.map(e=>({name:e.name,provider:e.provider,modelId:e.modelId,parameters:JSON.parse(JSON.stringify(e.parameters||{}))})),repeatConfig:d.value>1?{callsPerPrompt:d.value,strategy:"sequential"}:void 0}),t=await l.getTrial(e);if(!t)throw new Error("Trial not found after creation");return q.success("Trial created! Opening export options..."),t}catch(e){throw $.error("Failed to create trial for export",e),q.error("Failed to create trial for export"),e}finally{p.value=!1}}},initialize:async function(){await Promise.all([t.initialize(),a.initialize(),l.initialize()]);const n=e.value;if(n.initialDesignId){const e=t.designs.find(e=>e.id===n.initialDesignId);e&&_(e)}if(n.sourceTrial){const e=n.sourceTrial,a=t.designs.find(t=>t.id===e.designSnapshot.originalId);a&&(s.value=a,c.value="edit"===n.type?e.name:`Copy of ${e.name}`,e.repeatConfig?.callsPerPrompt&&(d.value=e.repeatConfig.callsPerPrompt),e.configurationSnapshots&&e.configurationSnapshots.length>0&&(u.value=e.configurationSnapshots.map(e=>({name:e.name||e.modelId,provider:e.provider,modelId:e.modelId,parameters:e.parameters||{}}))),f.value=!0)}},designsStore:t,variableListsStore:a,modelsStore:n,settingsStore:r}}(i(()=>({type:c.isEditMode?"edit":c.trialToDuplicate?"duplicate":"create",initialDesignId:c.initialDesignId,sourceTrial:c.trialToDuplicate||void 0}))),P=i(()=>I.totalCombinations.value),T=o(!1),E=o(!1),M=i(()=>c.isEditMode&&c.trialToDuplicate?`Edit Trial: ${c.trialToDuplicate.name}`:c.trialToDuplicate?`Duplicate Trial: ${c.trialToDuplicate.name}`:"Create New Trial"),A=i(()=>!!(g.value&&b.value.trim()&&k.value.length>0));function N(e){g.value=e,I.selectDesign(e)}async function F(e){try{const t=await z.designs.get(e);t&&(g.value=t,I.selectDesign(t))}catch(t){$.error("Failed to load design",t),U.error({title:"Failed to load design",content:t instanceof Error?t.message:"Unknown error"})}}function O(){g.value=null,k.value=[]}async function B(){d("close"),window.location.href="#/designs"}function V(e){b.value=e.trialName,_.value=e.repeatCount}function K(e){k.value.push(e)}function G(e){k.value.splice(e,1)}function Y(e){K(e),x.value=!1}async function X(){if(A.value&&g.value){S.value="draft";try{const e=await m.createTrial({name:b.value.trim(),designId:g.value.id,configurations:k.value,repeatConfig:{callsPerPrompt:_.value,strategy:"sequential"}});U.success({title:"Trial created",content:"Your trial has been saved as a draft"}),d("created",e),d("close")}catch(e){$.error("Failed to create trial",e),U.error({title:"Failed to create trial",content:e instanceof Error?e.message:"Unknown error"})}finally{S.value=null}}}async function Q(){if(A.value&&g.value){S.value="export";try{const e=await m.createTrial({name:b.value.trim(),designId:g.value.id,configurations:k.value,repeatConfig:{callsPerPrompt:_.value,strategy:"sequential"}}),t=await z.trials.get(e);if(!t)throw new Error("Failed to retrieve created trial");d("export-trial",t),d("close")}catch(e){$.error("Failed to export trial",e),U.error({title:"Failed to export trial",content:e instanceof Error?e.message:"Unknown error"})}finally{S.value=null}}}async function ee(){if(A.value&&g.value){S.value="start";try{const e=await m.createTrial({name:b.value.trim(),designId:g.value.id,configurations:k.value,repeatConfig:{callsPerPrompt:_.value,strategy:"sequential"}});await m.executeTrial(e),U.success({title:"Trial started",content:"Your trial is now running"}),d("created-and-started",e),d("close")}catch(e){$.error("Failed to create and start trial",e),U.error({title:"Failed to start trial",content:e instanceof Error?e.message:"Unknown error"})}finally{S.value=null}}}function te(){T.value=!T.value}function ae(){E.value=!E.value}function le(e){if(!e||T.value)return re(e?.promptTemplate||"");const t={};g.value&&g.value.variableBindings&&Object.entries(g.value.variableBindings).forEach(([e,a])=>{"direct"===a.type&&a.values&&a.values.length>0&&(t[e]=String(a.values[0]))});let a=e.promptTemplate;return Object.entries(t).forEach(([e,t])=>{const n=new RegExp(`{{\\s*${e}\\s*}}`,"g");a=a.replace(n,`<span class="variable-preview">${re(t)}</span>`)}),a=a.replace(/{{[^}]+}}/g,e=>`<span class="variable-placeholder">${re(e)}</span>`),a}function re(e){const t=document.createElement("div");return t.textContent=e,t.innerHTML}return w(()=>c.trialToDuplicate,()=>{c.trialToDuplicate&&async function(){if(c.trialToDuplicate)try{c.trialToDuplicate.designSnapshot?.originalId&&await F(c.trialToDuplicate.designSnapshot.originalId),c.isEditMode?b.value=c.trialToDuplicate.name:b.value=`${c.trialToDuplicate.name} (Copy)`,_.value=c.trialToDuplicate.repeatConfig?.callsPerPrompt||1,k.value=c.trialToDuplicate.configurationSnapshots||[]}catch(e){$.error("Failed to initialize duplication",e),U.error({title:"Failed to load trial data",content:e instanceof Error?e.message:"Unknown error"})}}()},{immediate:!0}),w(()=>c.initialDesignId,()=>{c.initialDesignId&&!c.trialToDuplicate&&async function(){c.initialDesignId&&await F(c.initialDesignId)}()},{immediate:!0}),(t,s)=>{const o=v("a-button");return t.isTabMode?(n(),a("div",ft,[r("div",vt,[r("section",gt,[r("div",bt,[s[6]||(s[6]=r("h3",null,"What are you testing?",-1)),g.value?(n(),C(o,{key:0,onClick:O,size:"small",class:"back-button",style:{"margin-left":"2em"}},{default:p(()=>s[5]||(s[5]=[h(" ← Back to Select Design ")])),_:1,__:[5]})):l("",!0)]),r("div",ht,[g.value?(n(),a("div",yt,[r("div",_t,[r("h4",null,y(g.value.name),1),r("span",Ct,y(P.value)+" combinations",1),r("div",kt,[u(o,{onClick:te,size:"small",type:T.value?"default":"primary",class:"pause-btn"},{default:p(()=>[h(y(T.value?"Start Variable Substitution":"Pause Variable Substitution"),1)]),_:1},8,["type"]),u(o,{onClick:ae,size:"small",type:E.value?"primary":"default",class:"placeholders-btn"},{default:p(()=>[h(y(E.value?"Show Live":"Show Raw Template"),1)]),_:1},8,["type"])])]),r("div",{class:"live-template-preview",innerHTML:E.value?re(g.value.promptTemplate):le(g.value)},null,8,wt)])):(n(),C(xe,{key:0,onSelect:N,onCreateNew:B}))])]),g.value?(n(),a("section",xt,[s[8]||(s[8]=r("h3",null,"Trial Configuration",-1)),r("div",St,[u(Fe,{"model-value":{trialName:b.value,repeatCount:_.value},"total-combinations":P.value,"onUpdate:modelValue":V},null,8,["model-value","total-combinations"]),r("div",It,[s[7]||(s[7]=r("h4",null,"Model Configuration",-1)),u(mt,{configurations:k.value,design:g.value,"total-combinations":P.value,"repeat-count":_.value,onShowModelSelector:s[0]||(s[0]=e=>x.value=!0),onAdd:K,onRemove:G},null,8,["configurations","design","total-combinations","repeat-count"])])])])):l("",!0)]),r("div",Pt,[r("div",Tt,[u(o,{size:"large",onClick:X,loading:"draft"===S.value,disabled:!A.value,"data-testid":"btn-create-draft-tab","aria-label":"Create trial as draft"},{default:p(()=>s[9]||(s[9]=[h(" Create as Draft ")])),_:1,__:[9]},8,["loading","disabled"]),u(o,{size:"large",onClick:Q,loading:"export"===S.value,disabled:!A.value,"data-testid":"btn-export-python-tab","aria-label":"Export trial to Python"},{default:p(()=>s[10]||(s[10]=[h(" Export to Python ")])),_:1,__:[10]},8,["loading","disabled"]),u(o,{type:"primary",size:"large",onClick:ee,loading:"start"===S.value,disabled:!A.value,"data-testid":"btn-create-and-start-tab","aria-label":"Create and start trial execution"},{default:p(()=>[u(f(L)),s[11]||(s[11]=h(" Create and Start "))]),_:1,__:[11]},8,["loading","disabled"])])]),u(Z,{open:x.value&&!!g.value,mode:"trial",design:g.value||void 0,"existing-configurations":k.value,onClose:s[1]||(s[1]=e=>x.value=!1),onAddConfiguration:Y},null,8,["open","design","existing-configurations"])])):(n(),C(e,{key:1,"model-value":!0,title:M.value,size:"full","data-testid":"modal-trial-creation","onUpdate:modelValue":s[4]||(s[4]=e=>t.$emit("close"))},{footer:p(()=>[u(ne,null,{default:p(()=>[u(o,{size:"large",onClick:X,loading:"draft"===S.value,disabled:!A.value,"data-testid":"btn-create-draft","aria-label":"Create trial as draft"},{default:p(()=>s[16]||(s[16]=[h(" Create as Draft ")])),_:1,__:[16]},8,["loading","disabled"]),u(o,{size:"large",onClick:Q,loading:"export"===S.value,disabled:!A.value,"data-testid":"btn-export-python","aria-label":"Export trial to Python"},{default:p(()=>s[17]||(s[17]=[h(" Export to Python ")])),_:1,__:[17]},8,["loading","disabled"]),u(o,{type:"primary",size:"large",onClick:ee,loading:"start"===S.value,disabled:!A.value,"data-testid":"btn-create-and-start","aria-label":"Create and start trial execution"},{default:p(()=>[u(f(L)),s[18]||(s[18]=h(" Create and Start "))]),_:1,__:[18]},8,["loading","disabled"])]),_:1})]),default:p(()=>[r("div",Et,[r("section",Mt,[r("div",At,[s[13]||(s[13]=r("h3",null,"What are you testing?",-1)),g.value?(n(),C(o,{key:0,onClick:O,size:"small",class:"back-button",style:{"margin-left":"2em"}},{default:p(()=>s[12]||(s[12]=[h(" ← Back to Select Design ")])),_:1,__:[12]})):l("",!0)]),r("div",Nt,[g.value?(n(),a("div",$t,[r("div",Ft,[r("h4",null,y(g.value.name),1),r("span",Ot,y(P.value)+" combinations",1),r("div",Rt,[u(o,{onClick:te,size:"small",type:T.value?"default":"primary",class:"pause-btn"},{default:p(()=>[h(y(T.value?"Start Variable Substitution":"Pause Variable Substitution"),1)]),_:1},8,["type"]),u(o,{onClick:ae,size:"small",type:E.value?"primary":"default",class:"placeholders-btn"},{default:p(()=>[h(y(E.value?"Show Live":"Show Raw Template"),1)]),_:1},8,["type"])])]),r("div",{class:"live-template-preview",innerHTML:E.value?re(g.value.promptTemplate):le(g.value)},null,8,Dt)])):(n(),C(xe,{key:0,onSelect:N,onCreateNew:B}))])]),g.value?(n(),a("section",jt,[s[15]||(s[15]=r("h3",null,"Trial Configuration",-1)),r("div",qt,[u(Fe,{"model-value":{trialName:b.value,repeatCount:_.value},"total-combinations":P.value,"onUpdate:modelValue":V},null,8,["model-value","total-combinations"]),r("div",Lt,[s[14]||(s[14]=r("h4",null,"Model Configuration",-1)),u(mt,{configurations:k.value,design:g.value,"total-combinations":P.value,"repeat-count":_.value,onShowModelSelector:s[2]||(s[2]=e=>x.value=!0),onAdd:K,onRemove:G},null,8,["configurations","design","total-combinations","repeat-count"])])])])):l("",!0)]),u(Z,{open:x.value&&!!g.value,mode:"trial",design:g.value||void 0,"existing-configurations":k.value,onClose:s[3]||(s[3]=e=>x.value=!1),onAddConfiguration:Y},null,8,["open","design","existing-configurations"])]),_:1},8,["title"]))}}}),[["__scopeId","data-v-e57a73ff"]]),zt={class:"trial-overview"},Bt={class:"overview-section"},Vt={class:"cost-value"},Kt={key:0,class:"text-secondary",style:{"margin-left":"8px"}},Gt={class:"overview-section"},Yt={class:"progress-details"},Ht={class:"progress-stats"},Jt={class:"configurations-section"},Wt={key:0,class:"model-info"},Xt={key:0},Qt={class:"prompt-section"},Zt={key:0,class:"variables-section"},ea=t({__name:"TrialDetailModal",props:{trial:{}},emits:["close","updated"],setup(t){const s=t,o=[{title:"Model",key:"model",width:200},{title:"Parameters",key:"params",width:300},{title:"Cost/Call",key:"cost",width:100,align:"right"}],c=i(()=>0===s.trial.progress.total?0:Math.round(s.trial.progress.completed/s.trial.progress.total*100));function d(e){const t=Object.entries(e).map(([e,t])=>`${e}: ${t}`).join(", ");return t.length>50?t.substring(0,50)+"...":t}function m(){const e=s.trial.variableSnapshots;return e&&0!==e.length?e.map(e=>({variable:e.variableName,listName:e.originalListName,count:e.data.itemCount})):[]}return(t,s)=>{const i=v("a-button"),f=v("a-tag"),b=v("a-descriptions-item"),_=v("a-descriptions"),k=v("a-progress"),w=v("a-typography-text"),x=v("a-table"),S=v("a-typography-paragraph"),I=v("a-list-item-meta"),P=v("a-list-item"),T=v("a-list");return n(),C(e,{"model-value":!0,title:t.trial.name,size:"full","onUpdate:modelValue":s[1]||(s[1]=e=>t.$emit("close"))},{footer:p(()=>[u(i,{onClick:s[0]||(s[0]=e=>t.$emit("close")),size:"large","data-testid":"btn-close-trial-detail","aria-label":"Close trial details"},{default:p(()=>s[2]||(s[2]=[h(" Close ")])),_:1,__:[2]})]),default:p(()=>[r("div",zt,[r("div",Bt,[s[3]||(s[3]=r("h3",null,"Trial Information",-1)),u(_,{column:2,size:"small",bordered:""},{default:p(()=>[u(b,{label:"Status"},{default:p(()=>{return[u(f,{color:(e=t.trial.status,{completed:"success",failed:"error",running:"processing",cancelled:"default",draft:"default",pending:"processing",paused:"warning"}[e]||"default"),"data-testid":"tag-trial-status","data-status":t.trial.status,"aria-label":`Trial status: ${t.trial.status}`},{default:p(()=>[h(y(t.trial.status.toUpperCase()),1)]),_:1},8,["color","data-status","aria-label"])];var e}),_:1}),u(b,{label:"Design"},{default:p(()=>[h(y(t.trial.designSnapshot.originalName),1)]),_:1}),u(b,{label:"Created"},{default:p(()=>{return[h(y((e=t.trial.created,new Date(e).toLocaleString())),1)];var e}),_:1}),u(b,{label:"Estimated Cost"},{default:p(()=>[r("span",Vt,"$"+y(t.trial.estimatedCost.toFixed(3)),1)]),_:1}),t.trial.repeatConfig?.callsPerPrompt&&t.trial.repeatConfig.callsPerPrompt>1?(n(),C(b,{key:0,label:"Repeat Configuration"},{default:p(()=>[u(f,{color:"purple"},{default:p(()=>[h(y(t.trial.repeatConfig.callsPerPrompt)+"× repeat",1)]),_:1}),t.trial.repeatConfig.delayBetweenRepeats?(n(),a("span",Kt,y(t.trial.repeatConfig.delayBetweenRepeats)+"ms delay ",1)):l("",!0)]),_:1})):l("",!0)]),_:1})]),r("div",Gt,[s[4]||(s[4]=r("h3",null,"Progress",-1)),r("div",Yt,[u(k,{percent:c.value,status:"failed"===t.trial.status?"exception":"active",size:"small","data-testid":"progress-trial-completion","aria-label":`Trial progress: ${c.value}% complete`},null,8,["percent","status","aria-label"]),r("div",Ht,[u(f,{"data-testid":"tag-progress-completed","aria-label":`${t.trial.progress.completed} of ${t.trial.progress.total} calls completed`},{default:p(()=>[h(y(t.trial.progress.completed)+" / "+y(t.trial.progress.total)+" completed",1)]),_:1},8,["aria-label"]),t.trial.progress.networkErrors>0?(n(),C(f,{key:0,color:"error","data-testid":"tag-network-errors","aria-label":`${t.trial.progress.networkErrors} network errors occurred`},{default:p(()=>[h(y(t.trial.progress.networkErrors)+" network errors ",1)]),_:1},8,["aria-label"])):l("",!0)])])])]),r("div",Jt,[r("h3",null,"Configurations ("+y(t.trial.configurationSnapshots.length)+")",1),u(x,{columns:o,"data-source":t.trial.configurationSnapshots,pagination:!1,size:"small",scroll:{y:300},"row-key":"id"},{bodyCell:p(({column:e,record:t})=>["model"===e.key?(n(),a("div",Wt,[r("strong",null,y(t.provider),1),r("small",null,y(t.modelId),1)])):l("",!0),"params"===e.key?(n(),C(w,{key:1,code:"",class:"params-preview"},{default:p(()=>[h(y(d(t.parameters)),1)]),_:2},1024)):l("",!0),"cost"===e.key?(n(),a(g,{key:2},[(n(),a("span",Xt," $"+y(.001.toFixed(4)),1))],64)):l("",!0)]),_:1},8,["data-source"])]),r("div",Qt,[s[5]||(s[5]=r("h3",null,"Prompt Template",-1)),u(S,{code:"",class:"prompt-template"},{default:p(()=>[h(y(t.trial.designSnapshot.promptTemplate),1)]),_:1})]),t.trial.variableSnapshots?.length?(n(),a("div",Zt,[s[6]||(s[6]=r("h3",null,"Variables",-1)),u(T,{"data-source":m(),size:"small",split:!1},{renderItem:p(({item:e})=>[u(P,null,{default:p(()=>[u(I,null,{title:p(()=>[u(f,{color:"blue"},{default:p(()=>[h(y(e.variable),1)]),_:2},1024)]),description:p(()=>[r("span",null,y(e.listName)+" ("+y(e.count)+" values)",1)]),_:2},1024)]),_:2},1024)]),_:1},8,["data-source"])])):l("",!0)]),_:1},8,["title"])}}});class ta{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=new B({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),a=this.extractUniqueVariables(t),n=e.configurationSnapshots.map(e=>({provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:e.parameters})),l=new Set(n.map(e=>e.provider)),r={};for(const s of l){const e=j.getProvider(s);e&&(r[s]=this.buildProviderConfig(s,e))}return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:a},models:n,providerConfigs:r}}static extractUniqueVariables(e){const t={};for(const n of e)for(const[e,a]of Object.entries(n.variables))t[e]||(t[e]=new Set),t[e].add(a);const a={};for(const[n,l]of Object.entries(t))a[n]=Array.from(l).sort();return a}static buildProviderConfig(e,t){const a=t.requestTransform||{},n=t.auth||{type:"none"};let l="direct";"messages"===a.promptKey&&a.wrapPrompt?l="messages":"input"===a.promptKey&&(l="input");let r,s,o="root";"ollama-chat"===e?(o="options",r={max_tokens:"num_predict",max_completion_tokens:"num_predict"}):"ollama-generate"===e&&(o="mixed",s={root:["model","prompt","stream","format","raw"],options:["temperature","num_predict","top_k","top_p"]},r={max_tokens:"num_predict",max_completion_tokens:"num_predict"});const i=Object.values(t.responseModes||{})[0],c=this.parseResponsePath(i?.responseTransform?.contentPath),d=i?.responseTransform?.fallbackPaths?.map(e=>this.parseResponsePath(e)),u=t.api.baseUrl+(t.api.endpoints.chat||t.api.endpoints.generate||"");return{name:t.name,endpoint:u,auth:{type:n.type,header:n.header,prefix:"bearer"===n.type?"Bearer":void 0},headers:t.headers,request:{modelPrefixStrip:!0,promptFormat:l,messageRole:a.messageRole,paramLocation:o,paramRenames:r,mixedParams:s},response:{successPath:c,fallbackPaths:d,errorPath:["error","message"]}}}static parseResponsePath(e){return e?e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const t=parseInt(e);return isNaN(t)?e:t}):["content"]}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=JSON.stringify(e.providerConfigs,null,4);return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Simple Mode\n=====================================\nGenerated by Auditomatic Lite v${V.short} on ${a}\n\nThis script reproduces your experiment by generating API calls from variables.\nPerfect for understanding, modifying, and extending your experiments.\n\nOriginal trial: ${t}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${Object.keys(e.providerConfigs).map(e=>{const t=e.split("-")[0].toUpperCase();return`    "${e}": os.environ.get("${t}_API_KEY", ""),`}).join("\n")}\n}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Provider configurations (how to talk to each API)\nPROVIDER_CONFIGS = ${r}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef make_api_call(provider_id: str, model: str, prompt: str, params: dict) -> dict:\n    """\n    Universal API caller that handles all provider quirks.\n    \n    Returns dict with 'success', 'content', 'error', and timing info.\n    """\n    config = PROVIDER_CONFIGS[provider_id]\n    \n    # Build headers\n    headers = {"Content-Type": "application/json"}\n    \n    # Add authentication\n    auth = config["auth"]\n    if auth["type"] == "bearer":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = f"{auth['prefix']} {api_key}"\n    elif auth["type"] == "header":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = api_key\n    \n    # Add provider-specific headers\n    if config.get("headers"):\n        headers.update(config["headers"])\n    \n    # Build request body\n    request = config["request"]\n    \n    # Strip provider prefix from model\n    if request.get("modelPrefixStrip"):\n        model = model.split(":", 1)[-1]\n    \n    body = {"model": model}\n    \n    # Format prompt\n    if request["promptFormat"] == "messages":\n        body["messages"] = [{"role": request.get("messageRole", "user"), "content": prompt}]\n    elif request["promptFormat"] == "direct":\n        body["prompt"] = prompt\n    elif request["promptFormat"] == "input":\n        body["input"] = prompt\n    \n    # Handle parameters\n    processed_params = params.copy()\n    \n    # Apply renames\n    if request.get("paramRenames"):\n        for old_key, new_key in request["paramRenames"].items():\n            if old_key in processed_params:\n                processed_params[new_key] = processed_params.pop(old_key)\n    \n    # Place parameters\n    if request["paramLocation"] == "root":\n        body.update(processed_params)\n    elif request["paramLocation"] == "options":\n        body["options"] = processed_params\n    elif request.get("mixedParams"):\n        mixed = request["mixedParams"]\n        for key, value in processed_params.items():\n            if key in mixed.get("root", []):\n                body[key] = value\n            else:\n                if "options" not in body:\n                    body["options"] = {}\n                body["options"][key] = value\n    \n    # Make request\n    start_time = time.time()\n    try:\n        response = requests.post(\n            config["endpoint"],\n            headers=headers,\n            json=body,\n            timeout=30\n        )\n        latency_ms = (time.time() - start_time) * 1000\n        \n        if response.ok:\n            data = response.json()\n            content = extract_from_path(data, config["response"]["successPath"])\n            \n            # Try fallback paths\n            if content is None and config["response"].get("fallbackPaths"):\n                for path in config["response"]["fallbackPaths"]:\n                    content = extract_from_path(data, path)\n                    if content is not None:\n                        break\n            \n            return {\n                "success": True,\n                "content": content or "",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n        else:\n            return {\n                "success": False,\n                "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n            \n    except Exception as e:\n        return {\n            "success": False,\n            "error": str(e),\n            "latency_ms": (time.time() - start_time) * 1000\n        }\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(\n                model_config["provider"],\n                model_config["modelId"],\n                prompt,\n                model_config["parameters"]\n            )\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": result.get("content", ""),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                "status_code": result.get("status_code", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {result['content'][:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_results_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider not in API_KEYS or not API_KEYS[provider]:\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(set(missing_keys)))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns:\n            print(f"Avg latency: {df['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class aa{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=[],a=new Y,n=new B({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),l=K(e);let r=0;for(const o of e.configurationSnapshots){const i=j.getProvider(o.provider);if(i)for(const c of n){const n=l>1?G():void 0;let d=e.designSnapshot.promptTemplate;for(const[e,t]of Object.entries(c.variables))d=d.replace(new RegExp(`{{${e}}}`,"g"),t);for(let e=0;e<l;e++){r++;try{const s={id:"export-config",name:o.name,provider:o.provider,model:o.modelId,params:o.parameters,created_at:new Date},u=a.buildAPIRequest(s,d),p={};for(const[e,t]of Object.entries(u.headers))"Authorization"===e&&t.startsWith("Bearer ")?p[e]=`Bearer $${o.provider.split("-")[0].toUpperCase()}_API_KEY`:e===i.auth.header&&"header"===i.auth.type?p[e]=`$${o.provider.split("-")[0].toUpperCase()}_API_KEY`:p[e]=t;const m=this.parseResponsePath(this.getDefaultResponsePath(o.provider));t.push({id:`call_${String(r).padStart(3,"0")}`,provider:o.provider,endpoint:u.url,headers:p,body:u.body,responsePath:m,metadata:{variables:c.variables,modelName:o.modelId,configName:o.name,...l>1&&{repeatIndex:e,repeatGroupId:n}}})}catch(s){$.warn("Failed to build API call for config",{configName:o.name,error:s})}}}}return{apiCalls:t,...e.repeatConfig&&{repeatConfig:{callsPerPrompt:e.repeatConfig.callsPerPrompt,delayBetweenRepeats:e.repeatConfig.delayBetweenRepeats}}}}static parseResponsePath(e){return e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const t=parseInt(e);return isNaN(t)?e:t})}static getDefaultResponsePath(e){switch(e){case"openai-chat":case"openrouter":return"choices[0].message.content";case"openai-responses":return"output[0].content[0].text";case"anthropic":return"content[0].text";case"ollama-chat":return"message.content";case"ollama-generate":return"response";default:return"content"}}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.apiCalls,null,4),l=[...new Set(e.apiCalls.map(e=>e.provider))],r=e.repeatConfig?`\nRepeat configuration: ${e.repeatConfig.callsPerPrompt} calls per prompt${e.repeatConfig.delayBetweenRepeats?`, ${e.repeatConfig.delayBetweenRepeats}ms delay`:""}`:"";return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Literal Mode\n======================================\nGenerated by Auditomatic Lite v${V.short} on ${a}\n\nThis script contains the EXACT API calls from your experiment.\nPerfect for bit-for-bit reproduction, debugging, and comparing results.\n\nOriginal trial: ${t}\nTotal API calls: ${e.apiCalls.length}${r}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${l.map(e=>{const t=e.split("-")[0].toUpperCase();return`    "${t}": os.environ.get("${t}_API_KEY", ""),`}).join("\n")}\n}\n\n# Pre-computed API calls from your experiment\nAPI_CALLS = ${n}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef execute_literal_calls():\n    """Execute pre-serialized API calls exactly as specified"""\n    results = []\n    total = len(API_CALLS)\n    \n    print(f"Executing {total} pre-computed API calls...")\n    print("=" * 60)\n    \n    for i, call in enumerate(API_CALLS):\n        print(f"[{i+1}/{total}] {call['metadata']['configName']} - ", end="")\n        \n        # Replace API key placeholders in headers\n        headers = {}\n        for key, value in call["headers"].items():\n            if "\\$" in str(value):\n                # Extract provider name from placeholder\n                for provider_key, api_key in API_KEYS.items():\n                    placeholder = f"\\\${provider_key}_API_KEY"\n                    if placeholder in value:\n                        headers[key] = value.replace(placeholder, api_key)\n                        break\n                else:\n                    headers[key] = value\n            else:\n                headers[key] = value\n        \n        # Check if we have required API key\n        provider_base = call["provider"].split("-")[0].upper()\n        if provider_base in ["OPENAI", "ANTHROPIC", "OPENROUTER"] and not API_KEYS.get(provider_base):\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": f"No API key for {provider_base}",\n                "latency_ms": 0,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ No API key")\n            continue\n        \n        # Make the exact API call\n        start_time = time.time()\n        try:\n            response = requests.post(\n                call["endpoint"],\n                headers=headers,\n                json=call["body"],\n                timeout=30\n            )\n            latency_ms = (time.time() - start_time) * 1000\n            \n            if response.ok:\n                data = response.json()\n                content = extract_from_path(data, call["responsePath"])\n                \n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": content or "",\n                    "success": True,\n                    "error": "",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    "full_response": json.dumps(data)[:500],  # First 500 chars\n                    **call["metadata"]["variables"]\n                })\n                print(f"✓ {(content or '')[:30]}")\n            else:\n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": "",\n                    "success": False,\n                    "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    **call["metadata"]["variables"]\n                })\n                print(f"✗ HTTP {response.status_code}")\n                \n        except Exception as e:\n            latency_ms = (time.time() - start_time) * 1000\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": str(e)[:200],\n                "latency_ms": latency_ms,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ {str(e)[:30]}")\n        \n        # Handle repeat delays if configured\n        if "repeatIndex" in call["metadata"] and call["metadata"]["repeatIndex"] > 0:\n            # Check if there's a repeat delay configured\n            delay_ms = ${e.repeatConfig?.delayBetweenRepeats||0}\n            if delay_ms > 0:\n                time.sleep(delay_ms / 1000.0)\n        \n        # Rate limiting\n        time.sleep(0.1)\n    \n    return results\n\ndef extract_prompt_from_body(body: dict) -> str:\n    """Extract the prompt from various request body formats"""\n    # Messages format (OpenAI, Anthropic, etc)\n    if "messages" in body and isinstance(body["messages"], list):\n        for msg in body["messages"]:\n            if msg.get("role") == "user":\n                return msg.get("content", "")\n    \n    # Direct prompt format (Ollama generate)\n    if "prompt" in body:\n        return body["prompt"]\n    \n    # Input format (OpenAI responses)\n    if "input" in body:\n        return body["input"]\n    \n    return ""\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    # Drop full_response column for cleaner output (except JSON)\n    if format != "json" and "full_response" in df.columns:\n        df = df.drop(columns=["full_response"])\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_literal_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    required_providers = set(call["provider"].split("-")[0].upper() for call in API_CALLS)\n    missing_keys = []\n    for provider in required_providers:\n        if provider not in ["OLLAMA"] and not API_KEYS.get(provider):\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(missing_keys))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Execute all calls\n    results = execute_literal_calls()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if df['success'].any():\n            print(f"Avg latency (successful): {df[df['success']]['latency_ms'].mean():.1f}ms")\n        \n        # Group by model\n        print(f"\\nBy Model:")\n        model_summary = df.groupby('config_name')['success'].agg(['count', 'sum', 'mean'])\n        model_summary.columns = ['total', 'successful', 'success_rate']\n        print(model_summary)\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class na{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=new B({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),a=this.extractUniqueVariables(t),n=e.configurationSnapshots.map(e=>{let t,a="text";return e.parameters.response_format?(a="json_mode",t={response_format:e.parameters.response_format}):e.parameters.tools&&(a="function_calling",t={tools:e.parameters.tools,tool_choice:e.parameters.tool_choice}),{provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:this.filterCoreParams(e.parameters),responseMode:a,responseModeParams:t}}),l=new Set(n.map(e=>e.provider)),r={"openai-chat":"openai","openai-responses":"openai",anthropic:"anthropic",openrouter:"openai","ollama-chat":"ollama","ollama-generate":"ollama"},s=[...new Set(Array.from(l).map(e=>r[e]).filter(Boolean))],o={"openai-chat":"OPENAI","openai-responses":"OPENAI",anthropic:"ANTHROPIC",openrouter:"OPENROUTER","ollama-chat":"","ollama-generate":""},i=[...new Set(Array.from(l).map(e=>o[e]).filter(Boolean))];return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:a},models:n,providerLibraries:{required:s,apiKeys:i}}}static extractUniqueVariables(e){const t={};for(const n of e)for(const[e,a]of Object.entries(n.variables))t[e]||(t[e]=new Set),t[e].add(a);const a={};for(const[n,l]of Object.entries(t))a[n]=Array.from(l).sort();return a}static filterCoreParams(e){const t={...e};return delete t.response_format,delete t.tools,delete t.tool_choice,t}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=["import os","import json","import time","import pandas as pd","from datetime import datetime"];return e.providerLibraries.required.includes("openai")&&r.push("from openai import OpenAI"),e.providerLibraries.required.includes("anthropic")&&r.push("from anthropic import Anthropic"),e.providerLibraries.required.includes("ollama")&&r.push("import ollama"),`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Native Mode\n=====================================\nGenerated by Auditomatic Lite v${V.short} on ${a}\n\nThis script uses native Python libraries for each provider.\nCleanest code, best for production use.\n\nOriginal trial: ${t}\nRequired packages: ${e.providerLibraries.required.join(", ")}\n"""\n\n${r.join("\n")}\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\n${e.providerLibraries.apiKeys.map(e=>`os.environ.setdefault("${e}_API_KEY", "")  # Set your ${e} API key`).join("\n")}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\n# Initialize clients\nclients = {}\n\ndef get_client(provider):\n    """Get or create client for provider"""\n    if provider not in clients:\n        if provider in ["openai-chat", "openai-responses"]:\n            clients[provider] = OpenAI()\n        elif provider == "anthropic":\n            clients[provider] = Anthropic()\n        elif provider == "openrouter":\n            clients[provider] = OpenAI(\n                api_key=os.environ.get("OPENROUTER_API_KEY"),\n                base_url="https://openrouter.ai/api/v1"\n            )\n        # Ollama doesn't need a client\n    return clients.get(provider)\n\ndef make_api_call(model_config: dict, prompt: str) -> dict:\n    """Make API call using native provider library"""\n    provider = model_config["provider"]\n    model = model_config["modelId"]\n    params = model_config["parameters"].copy()\n    \n    try:\n        start_time = time.time()\n        \n        if provider == "openai-chat" or provider == "openrouter":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["response_format"] = {"type": "json_object"}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.chat.completions.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content based on response mode\n            if model_config["responseMode"] == "function_calling" and response.choices[0].message.tool_calls:\n                content = response.choices[0].message.tool_calls[0].function.arguments\n                if isinstance(content, str):\n                    content = json.loads(content)\n            else:\n                content = response.choices[0].message.content\n            \n        elif provider == "openai-responses":\n            client = get_client(provider)\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["text"] = {"format": {"type": "json_object"}}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.responses.create(\n                model=model,\n                input=prompt,\n                **params\n            )\n            \n            # Extract content\n            output = response.output\n            if isinstance(output, list) and len(output) > 0:\n                if hasattr(output[0], 'content') and isinstance(output[0].content, list):\n                    content = output[0].content[0].text if hasattr(output[0].content[0], 'text') else str(output[0].content[0])\n                else:\n                    content = str(output[0])\n            else:\n                content = str(output)\n            \n        elif provider == "anthropic":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.messages.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content\n            if model_config["responseMode"] == "function_calling" and hasattr(response.content[0], 'input'):\n                content = response.content[0].input\n            else:\n                content = response.content[0].text\n            \n        elif provider == "ollama-chat":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.chat(\n                model=model,\n                messages=[{"role": "user", "content": prompt}],\n                **params\n            )\n            \n            # Extract content\n            content = response["message"]["content"]\n            \n        elif provider == "ollama-generate":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.generate(\n                model=model,\n                prompt=prompt,\n                **params\n            )\n            \n            # Extract content\n            content = response["response"]\n        \n        else:\n            raise ValueError(f"Unknown provider: {provider}")\n        \n        latency_ms = (time.time() - start_time) * 1000\n        \n        return {\n            "success": True,\n            "content": content,\n            "latency_ms": latency_ms\n        }\n        \n    except Exception as e:\n        latency_ms = (time.time() - start_time) * 1000\n        return {\n            "success": False,\n            "content": "",\n            "error": str(e),\n            "latency_ms": latency_ms\n        }\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(model_config, prompt)\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": str(result.get("content", "")),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {str(result['content'])[:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: list, format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_native_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for required packages\n    required = ${JSON.stringify(e.providerLibraries.required)}\n    missing = []\n    for lib in required:\n        try:\n            __import__(lib)\n        except ImportError:\n            missing.append(lib)\n    \n    if missing:\n        print(f"ERROR: Missing required packages: {', '.join(missing)}")\n        print(f"Install with: pip install {' '.join(missing)}")\n        return\n    \n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider in ["openai-chat", "openai-responses"] and not os.environ.get("OPENAI_API_KEY"):\n            missing_keys.append("OPENAI_API_KEY")\n        elif provider == "anthropic" and not os.environ.get("ANTHROPIC_API_KEY"):\n            missing_keys.append("ANTHROPIC_API_KEY")\n        elif provider == "openrouter" and not os.environ.get("OPENROUTER_API_KEY"):\n            missing_keys.append("OPENROUTER_API_KEY")\n    \n    if missing_keys:\n        print(f"WARNING: Missing API keys: {', '.join(set(missing_keys))}")\n        print("Set them in the script or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns and df['success'].any():\n            print(f"Avg latency: {df[df['success']]['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class la{static async generatePythonScript(e,t){try{const a=t||this.getDefaultOptions(),n=this.validateTrialForExport(e);if(!n.valid)throw new Error(`Trial validation failed: ${n.errors.join(", ")}`);switch(a.mode){case"simple":return ta.generate(e);case"literal":return aa.generate(e);case"native":return na.generate(e);default:throw new Error(`Unknown export mode: ${a.mode}`)}}catch(a){throw new Error(`Failed to generate Python export: ${a instanceof Error?a.message:String(a)}`)}}static async downloadPythonScript(e,t){const a=await this.generatePythonScript(e,t),n=t||this.getDefaultOptions(),l=new Blob([a],{type:"text/x-python"}),r=URL.createObjectURL(l),s=document.createElement("a");s.href=r,s.download=this.generateFilename(e,n.mode),document.body.appendChild(s),s.click(),document.body.removeChild(s),URL.revokeObjectURL(r)}static validateTrialForExport(e){const t=[];return e.designSnapshot?e.designSnapshot.promptTemplate||t.push("Design missing prompt template"):t.push("Trial missing design snapshot"),e.configurationSnapshots&&0!==e.configurationSnapshots.length?e.configurationSnapshots.forEach((e,a)=>{e.provider||t.push(`Configuration ${a+1} missing provider`),e.modelId||t.push(`Configuration ${a+1} missing model`),e.parameters||t.push(`Configuration ${a+1} missing parameters`)}):t.push("Trial missing model configurations"),e.variableSnapshots||t.push("Trial missing variable snapshots"),{valid:0===t.length,errors:t}}static getExportSummary(e){const t=new Set(e.configurationSnapshots.map(e=>e.provider)),a=e.totalCombinations||0;return{apiCallCount:e.configurationSnapshots.length*a,providersUsed:Array.from(t),variableCombinations:a,configurations:e.configurationSnapshots.length}}static getDefaultOptions(){return{mode:"simple"}}static generateFilename(e,t){const a=e.name||`trial_${e.id}`,n=(new Date).toISOString().split("T")[0];return`${a.toLowerCase().replace(/[^a-z0-9]/g,"_")}_${t}_${n}.py`}}const ra=Object.freeze(Object.defineProperty({__proto__:null,PythonExportService:la},Symbol.toStringTag,{value:"Module"})),sa={class:"trial-info"},oa={class:"trial-stats"},ia={class:"export-section"},ca={class:"mode-content"},da={class:"mode-content"},ua={class:"mode-content"},pa={class:"export-section"},ma={class:"preview-content"},fa={class:"preview-info"},va=t({__name:"PythonExportModal",props:{trial:{}},emits:["close","exported"],setup(t,{emit:a}){const l=t,s=a,c=o("simple"),d=o(!1),m=i(()=>l.trial.progress.total),f=i(()=>l.trial.configurationSnapshots?.length||0),g=i(()=>l.trial.totalCombinations||0),b=i(()=>{const e=.05*g.value+.3*f.value;return Math.round(15+e)}),_=i(()=>{const e=.5*m.value;return Math.round(10+e)}),k=i(()=>{const e=.05*g.value+.2*f.value;return Math.round(12+e)}),w=i(()=>{const e=l.trial.name.toLowerCase().replace(/\s+/g,"_"),t=(new Date).toISOString().split("T")[0];return`${e}_${c.value}_${t}.py`}),x=i(()=>{if("simple"===c.value){return 300+(g.value+10*f.value)}if("native"===c.value){return 250+(g.value+8*f.value)}return 200+15*m.value});async function S(){d.value=!0;try{const e={mode:c.value};await la.downloadPythonScript(l.trial,e),s("exported",w.value),s("close")}catch(e){$.error("Export failed",e),alert("Export failed: "+(e instanceof Error?e.message:"Unknown error"))}finally{d.value=!1}}return(t,a)=>{const l=v("a-button"),s=v("a-tag"),o=v("a-radio"),i=v("a-radio-group"),I=v("a-typography-text");return n(),C(e,{"model-value":!0,title:"Export Python Script",size:"full","onUpdate:modelValue":a[2]||(a[2]=e=>t.$emit("close"))},{footer:p(()=>[u(l,{onClick:a[0]||(a[0]=e=>t.$emit("close")),size:"large","data-testid":"btn-cancel-python-export","aria-label":"Cancel Python export"},{default:p(()=>a[3]||(a[3]=[h(" Cancel ")])),_:1,__:[3]}),u(l,{type:"primary",onClick:S,loading:d.value,size:"large","data-testid":"btn-confirm-python-export","data-mode":c.value,"aria-label":`Export Python script in ${c.value} mode`},{default:p(()=>a[4]||(a[4]=[h(" Export Script ")])),_:1,__:[4]},8,["loading","data-mode","aria-label"])]),default:p(()=>[r("div",sa,[r("h3",null,y(t.trial.name),1),r("div",oa,[u(s,null,{default:p(()=>[h(y(m.value)+" API calls",1)]),_:1}),u(s,null,{default:p(()=>[h(y(f.value)+" configurations",1)]),_:1}),u(s,null,{default:p(()=>[h(y(g.value)+" variable combinations",1)]),_:1})])]),r("div",ia,[a[11]||(a[11]=r("h4",null,"Export Mode",-1)),u(i,{value:c.value,"onUpdate:value":a[1]||(a[1]=e=>c.value=e),class:"mode-options","data-testid":"radiogroup-export-mode","aria-label":"Select Python export mode"},{default:p(()=>[u(o,{value:"simple",class:"mode-radio","data-testid":"radio-mode-simple","aria-label":"Simple script mode"},{default:p(()=>[r("div",ca,[a[5]||(a[5]=r("div",{class:"mode-title"},"Simple Script",-1)),a[6]||(a[6]=r("div",{class:"mode-description"}," Educational script with variables as lists. Easy to understand, modify, and extend. Perfect for learning how AI APIs work. ",-1)),u(s,{color:"blue",size:"small"},{default:p(()=>[h("~"+y(b.value)+"KB",1)]),_:1})])]),_:1}),u(o,{value:"literal",class:"mode-radio","data-testid":"radio-mode-literal","aria-label":"Literal reproduction mode"},{default:p(()=>[r("div",da,[a[7]||(a[7]=r("div",{class:"mode-title"},"Literal Reproduction",-1)),a[8]||(a[8]=r("div",{class:"mode-description"}," Exact API calls pre-computed. Bit-for-bit reproduction of your experiment. Best for debugging and comparing results. ",-1)),u(s,{color:"blue",size:"small"},{default:p(()=>[h("~"+y(_.value)+"KB",1)]),_:1})])]),_:1}),u(o,{value:"native",class:"mode-radio","data-testid":"radio-mode-native","aria-label":"Native libraries mode"},{default:p(()=>[r("div",ua,[a[9]||(a[9]=r("div",{class:"mode-title"},"Native Libraries",-1)),a[10]||(a[10]=r("div",{class:"mode-description"}," Uses official Python SDKs (openai, anthropic, ollama). Cleanest code, best for production use. Requires: pip install openai anthropic ollama ",-1)),u(s,{color:"green",size:"small"},{default:p(()=>[h("~"+y(k.value)+"KB",1)]),_:1})])]),_:1})]),_:1},8,["value"])]),a[13]||(a[13]=r("div",{class:"export-section"},[r("h4",null,"Output Format"),r("div",{class:"format-info"},[r("p",null,"Both scripts save results using pandas in your choice of format:"),r("ul",null,[r("li",null,[r("strong",null,"CSV"),h(" - Universal format, opens in Excel/Google Sheets")]),r("li",null,[r("strong",null,"Excel"),h(" - Native Excel format")]),r("li",null,[r("strong",null,"JSON"),h(" - For programmatic access")]),r("li",null,[r("strong",null,"Parquet"),h(" - Efficient compressed format")]),r("li",null,[r("strong",null,"HTML"),h(" - For web viewing")]),r("li",null,[r("strong",null,"Markdown"),h(" - For documentation")]),r("li",null,[r("strong",null,"Stata"),h(" - For statistical analysis")]),r("li",null,[r("strong",null,"Pickle"),h(" - Python native format")])])])],-1)),r("div",pa,[a[12]||(a[12]=r("h4",null,"Script Preview",-1)),r("div",ma,[u(I,{code:"",class:"preview-filename"},{default:p(()=>[h(y(w.value),1)]),_:1}),r("div",fa,[u(s,{size:"small"},{default:p(()=>[h(y(x.value)+" lines",1)]),_:1}),u(s,{size:"small"},{default:p(()=>[h(y(c.value)+" mode",1)]),_:1})])])])]),_:1,__:[13]})}}}),ga={class:"api-call-modal"},ba={class:"modal-header"},ha={class:"modal-content"},ya={class:"section"},_a={class:"info-grid"},Ca={class:"info-item"},ka={class:"call-id"},wa={class:"info-item"},xa={class:"info-item"},Sa={class:"info-item"},Ia={key:0,class:"info-item"},Pa={key:1,class:"info-item"},Ta={key:2,class:"info-item"},Ea={class:"section"},Ma={class:"variables-detail"},Aa={class:"variable-value"},Na={key:0,class:"attributes-section"},$a={class:"attribute-items"},Fa={class:"section"},Oa={class:"prompt-display"},Ra={key:0,class:"section"},Da={key:0,class:"response-info"},ja={class:"info-grid"},qa={class:"info-item"},La={class:"info-item"},Ua={key:1,class:"result-content"},za={key:0,class:"error-result"},Ba={class:"error-message"},Va={key:0,class:"error-raw"},Ka={class:"error-response"},Ga={key:1,class:"content-result"},Ya={class:"content-display"},Ha={class:"section"},Ja={class:"raw-data"},Wa={key:1,class:"section"},Xa={class:"raw-data"},Qa={class:"modal-footer"},Za=N(t({__name:"APICallDetailModal",props:{apiCall:{},trial:{}},emits:["close"],setup(e){const t=e,s=i(()=>{if(!t.apiCall.request)return"No request data";const e=JSON.parse(JSON.stringify(t.apiCall.request));return e.headers&&Object.keys(e.headers).forEach(t=>{const a=t.toLowerCase();(a.includes("authorization")||a.includes("api-key")||a.includes("x-api-key")||a.includes("bearer"))&&(e.headers[t]="[REDACTED]")}),JSON.stringify(e,null,2)});function o(){return t.trial&&t.trial.configurationSnapshots[t.apiCall.configurationIndex]&&t.trial.configurationSnapshots[t.apiCall.configurationIndex].name||`Configuration ${t.apiCall.configurationIndex+1}`}function c(e){const t="string"==typeof e?new Date(e):e;return isNaN(t.getTime())?"Invalid date":t.toLocaleString()}async function d(){const e={id:t.apiCall.id,status:t.apiCall.status,configuration:o(),variables:t.apiCall.variables,variableAttributes:t.apiCall.variableAttributes,prompt:t.apiCall.prompt,request:JSON.parse(s.value),response:t.apiCall.response,result:t.apiCall.result,created:t.apiCall.created,completed:t.apiCall.completed},a=JSON.stringify(e,null,2);try{if(navigator.clipboard&&navigator.clipboard.writeText)return await navigator.clipboard.writeText(a),void q.success("Details copied to clipboard!");const e=document.createElement("textarea");e.value=a,e.style.position="fixed",e.style.left="-999999px",e.style.top="-999999px",document.body.appendChild(e),e.focus(),e.select();const t=document.execCommand("copy");if(document.body.removeChild(e),!t)throw new Error("execCommand failed");q.success("Details copied to clipboard!")}catch(n){$.error("Failed to copy to clipboard",n),prompt("Copy this text manually:",a)}}return(e,t)=>{const i=v("a-button");return n(),a("div",{class:"modal-overlay",onClick:t[2]||(t[2]=x(t=>e.$emit("close"),["self"]))},[r("div",ga,[r("div",ba,[t[3]||(t[3]=r("h2",null,"API Call Details",-1)),r("button",{class:"close-btn",onClick:t[0]||(t[0]=t=>e.$emit("close")),"data-testid":"btn-close-api-call-modal","aria-label":"Close API call details"},"×")]),r("div",ha,[r("div",ya,[t[11]||(t[11]=r("h3",null,"Overview",-1)),r("div",_a,[r("div",Ca,[t[4]||(t[4]=r("label",null,"Call ID:",-1)),r("span",ka,y(e.apiCall.id),1)]),r("div",wa,[t[5]||(t[5]=r("label",null,"Status:",-1)),r("span",{class:S(["status-badge",e.apiCall.status])},y(e.apiCall.status),3)]),r("div",xa,[t[6]||(t[6]=r("label",null,"Configuration:",-1)),r("span",null,y(o()),1)]),r("div",Sa,[t[7]||(t[7]=r("label",null,"Created:",-1)),r("span",null,y(c(e.apiCall.created)),1)]),e.apiCall.completed?(n(),a("div",Ia,[t[8]||(t[8]=r("label",null,"Completed:",-1)),r("span",null,y(c(e.apiCall.completed)),1)])):l("",!0),e.apiCall.completed?(n(),a("div",Pa,[t[9]||(t[9]=r("label",null,"Duration:",-1)),r("span",null,y((m=e.apiCall.completed.getTime()-e.apiCall.created.getTime(),m<1e3?`${m}ms`:`${(m/1e3).toFixed(1)}s`)),1)])):l("",!0),e.apiCall.response?.latencyMs?(n(),a("div",Ta,[t[10]||(t[10]=r("label",null,"API Latency:",-1)),r("span",null,y(e.apiCall.response.latencyMs)+"ms",1)])):l("",!0)])]),r("div",Ea,[t[13]||(t[13]=r("h3",null,"Variables",-1)),r("div",Ma,[(n(!0),a(g,null,b(Object.entries(e.apiCall.variables),([e,t])=>(n(),a("div",{key:e,class:"variable-item"},[r("label",null,y(e)+":",1),r("span",Aa,y(t),1)]))),128))]),e.apiCall.variableAttributes&&Object.keys(e.apiCall.variableAttributes).length>0?(n(),a("div",Na,[t[12]||(t[12]=r("h4",null,"Variable Attributes",-1)),(n(!0),a(g,null,b(Object.entries(e.apiCall.variableAttributes),([e,t])=>(n(),a("div",{key:e,class:"attribute-group"},[r("h5",null,y(e),1),r("div",$a,[(n(!0),a(g,null,b(Object.entries(t),([e,t])=>(n(),a("div",{key:e,class:"attribute-item"},[r("label",null,y(e)+":",1),r("span",null,y(t),1)]))),128))])]))),128))])):l("",!0)]),r("div",Fa,[t[14]||(t[14]=r("h3",null,"Resolved Prompt",-1)),r("div",Oa,y(e.apiCall.prompt),1)]),e.apiCall.response||e.apiCall.result?(n(),a("div",Ra,[t[20]||(t[20]=r("h3",null,"Response",-1)),e.apiCall.response?(n(),a("div",Da,[r("div",ja,[r("div",qa,[t[15]||(t[15]=r("label",null,"HTTP Status:",-1)),r("span",null,y(e.apiCall.response.status),1)]),r("div",La,[t[16]||(t[16]=r("label",null,"Latency:",-1)),r("span",null,y(e.apiCall.response.latencyMs)+"ms",1)])])])):l("",!0),e.apiCall.result?(n(),a("div",Ua,[!1===e.apiCall.result.success?(n(),a("div",za,[t[18]||(t[18]=r("h4",null,"Error",-1)),r("div",Ba,y(e.apiCall.result.error),1),e.apiCall.response?(n(),a("div",Va,[t[17]||(t[17]=r("h5",null,"Raw Response:",-1)),r("pre",Ka,y(JSON.stringify(e.apiCall.response,null,2)),1)])):l("",!0)])):l("",!0),e.apiCall.result.content?(n(),a("div",Ga,[t[19]||(t[19]=r("h4",null,"Content",-1)),r("div",Ya,y(e.apiCall.result.content),1)])):l("",!0)])):l("",!0)])):l("",!0),r("div",Ha,[t[21]||(t[21]=r("h3",null,"Raw Request",-1)),r("pre",Ja,y(s.value),1)]),e.apiCall.response?(n(),a("div",Wa,[t[22]||(t[22]=r("h3",null,"Raw Response",-1)),r("pre",Xa,y(JSON.stringify(e.apiCall.response,null,2)),1)])):l("",!0)]),r("div",Qa,[u(i,{onClick:t[1]||(t[1]=t=>e.$emit("close")),size:"large",class:"footer-button","data-testid":"btn-close-modal-footer","aria-label":"Close modal"},{default:p(()=>t[23]||(t[23]=[h(" Close ")])),_:1,__:[23]}),u(i,{type:"primary",onClick:d,size:"large",class:"footer-button footer-button-primary","data-testid":"btn-copy-api-call-details","aria-label":"Copy API call details to clipboard"},{default:p(()=>t[24]||(t[24]=[h(" Copy Details ")])),_:1,__:[24]})])])]);var m}}}),[["__scopeId","data-v-d79e18d5"]]);function en(e,t){const a=new Set,n=new Set,l=new Set;e.forEach(e=>{e.variables&&Object.keys(e.variables).forEach(e=>a.add(e)),e.variableAttributes&&Object.values(e.variableAttributes).forEach(e=>{e&&Object.keys(e).forEach(e=>n.add(e))})});const r=Array.from(a).sort(),s=Array.from(n).sort(),o=Array.from(l).sort(),i=[];t?.designSnapshot?.extractPattern&&i.push("extracted_value");const c=["success","refused",...i,...o];return{categorical:[...r,...s,"model","status","error_type"],numeric:["response_time","total_tokens","prompt_tokens","completion_tokens","extracted_value",...i].sort(),extracted:c}}function tn(e,t,a){switch(t){case"model":if(a&&e.configurationIndex<a.configurationSnapshots.length){return a.configurationSnapshots[e.configurationIndex].modelId||"Unknown"}return"Unknown";case"status":return e.status;case"response_time":return e.response?.latencyMs||0;case"total_tokens":if(e.response?.body?.usage){const t=e.response.body.usage;return t.total_tokens||t.prompt_tokens+t.completion_tokens||0}return 0;case"prompt_tokens":return e.response?.body?.usage?.prompt_tokens||e.response?.body?.usage?.input_tokens||0;case"completion_tokens":return e.response?.body?.usage?.completion_tokens||e.response?.body?.usage?.output_tokens||0;case"error_type":return e.result?.errorType||(!1===e.result?.success?"api_error":"success");case"success":return e.result?.success?1:0;case"refused":return e.result?.refused?1:0;case"extracted_value":if(e.result?.success&&void 0!==e.result?.content){const t=String(e.result.content),a=parseFloat(t);return isNaN(a)||t.trim()!==String(a)?t:a}return null}if(void 0!==e.variables?.[t])return e.variables[t];if(e.variableAttributes)for(const n of Object.keys(e.variableAttributes)){const a=e.variableAttributes[n];if(a&&void 0!==a[t])return a[t]}return null}const an={count:{label:"Count",calculate:e=>e.length,format:e=>e.toString(),needsNumeric:!1},sum:{label:"Sum",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?t.reduce((e,t)=>e+t,0):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mean:{label:"Mean",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?t.reduce((e,t)=>e+t,0)/t.length:null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},median:{label:"Median",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(0===t.length)return null;const a=[...t].sort((e,t)=>e-t),n=Math.floor(a.length/2);return a.length%2==0?(a[n-1]+a[n])/2:a[n]},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mode:{label:"Mode",calculate:e=>{if(0===e.length)return null;const t=new Map;e.forEach(e=>t.set(e,(t.get(e)||0)+1));let a=0,n=null;return t.forEach((e,t)=>{e>a&&(a=e,n=t)}),{value:n,count:a,total:e.length}},format:e=>e?`${e.value} (${e.count}/${e.total})`:"-",needsNumeric:!1},variance:{label:"Variance",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(t.length<=1)return null;const a=t.reduce((e,t)=>e+t,0)/t.length;return t.reduce((e,t)=>e+Math.pow(t-a,2),0)/(t.length-1)},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},std_dev:{label:"Std Dev",calculate:e=>{const t=an.variance.calculate(e);return null!==t?Math.sqrt(t):null},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},min:{label:"Min",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?Math.min(...t):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},max:{label:"Max",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?Math.max(...t):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},success_rate:{label:"Success Rate",calculate:(e,t)=>{const a=t.filter(e=>e.result?.success).length;return t.length>0?a/t.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},refusal_rate:{label:"Refusal Rate",calculate:(e,t)=>{const a=t.filter(e=>e.result?.refused).length;return t.length>0?a/t.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},avg_time:{label:"Avg Time (ms)",calculate:(e,t)=>{const a=t.filter(e=>e.response?.latencyMs).map(e=>e.response.latencyMs);return a.length>0?a.reduce((e,t)=>e+t,0)/a.length:null},format:e=>e?`${Math.round(e)}ms`:"-",needsNumeric:!1,usesApiCalls:!0}};function nn(e,t){if(!e||null===e.value)return"-";return an[t].format(e.value)}const ln={"blue-subtle":{name:"Blue (Subtle)",colors:["rgba(59, 130, 246, 0.1)","rgba(59, 130, 246, 0.3)","rgba(59, 130, 246, 0.7)"]},"green-red":{name:"Green-Red",colors:["#dc2626","#fbbf24","#10b981"]},"blue-yellow":{name:"Blue-Yellow",colors:["#1e40af","#3b82f6","#fbbf24"]},"purple-orange":{name:"Purple-Orange",colors:["#7c3aed","#a855f7","#ff9500"]},grayscale:{name:"Grayscale",colors:["#f3f4f6","#9ca3af","#374151"]},viridis:{name:"Viridis",colors:["#440154","#482878","#3e4989","#31688e","#26828e","#1f9e89","#35b779","#6ece58","#b5de2b","#fde725"]},inferno:{name:"Inferno",colors:["#000004","#1b0c41","#4a0c6b","#781c6d","#a52c60","#cf4446","#ed6925","#fb9b06","#f7d13d","#fcffa4"]},magma:{name:"Magma",colors:["#000004","#180f3d","#440f76","#721f81","#9e2f7f","#cd4071","#f1605d","#fd9668","#feca8d","#fcfdbf"]},plasma:{name:"Plasma",colors:["#0d0887","#46039f","#7201a8","#9c179e","#bd3786","#d8576b","#ed7953","#fb9f3a","#fdca26","#f0f921"]}};function rn(e,t){if(0===t.length)return"transparent";if(1===t.length)return t[0];e=Math.max(0,Math.min(1,e));const a=1/(t.length-1),n=Math.floor(e/a),l=e%a/a;return sn(t[Math.min(n,t.length-1)],t[Math.min(n+1,t.length-1)],l)}function sn(e,t,a){if(e.startsWith("rgba")&&t.startsWith("rgba")){const n=e=>{const t=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);return t?{r:parseInt(t[1]),g:parseInt(t[2]),b:parseInt(t[3]),a:t[4]?parseFloat(t[4]):1}:null},l=n(e),r=n(t);if(l&&r){return`rgba(${Math.round(l.r+(r.r-l.r)*a)}, ${Math.round(l.g+(r.g-l.g)*a)}, ${Math.round(l.b+(r.b-l.b)*a)}, ${(l.a+(r.a-l.a)*a).toFixed(2)})`}}if(e.startsWith("rgba")||t.startsWith("rgba"))return a<.5?e:t;const n=e.replace("#",""),l=t.replace("#",""),r=parseInt(n.substr(0,2),16),s=parseInt(n.substr(2,2),16),o=parseInt(n.substr(4,2),16),i=parseInt(l.substr(0,2),16),c=parseInt(l.substr(2,2),16),d=parseInt(l.substr(4,2),16),u=Math.round(r+(i-r)*a),p=Math.round(s+(c-s)*a),m=Math.round(o+(d-o)*a);return`#${u.toString(16).padStart(2,"0")}${p.toString(16).padStart(2,"0")}${m.toString(16).padStart(2,"0")}`}function on(e){let t,a,n;if(e.startsWith("rgba")){const l=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);if(!l)return!1;t=parseInt(l[1]),a=parseInt(l[2]),n=parseInt(l[3])}else{const l="#"===e.charAt(0)?e.substring(1,7):e;t=parseInt(l.substring(0,2),16),a=parseInt(l.substring(2,4),16),n=parseInt(l.substring(4,6),16)}const l=[t/255,a/255,n/255].map(e=>e<=.03928?e/12.92:Math.pow((e+.055)/1.055,2.4));return.2126*l[0]+.7152*l[1]+.0722*l[2]<=.179}function cn(e){return on(e)?"#FFFFFF":"#000000"}function dn(e,t,a){const{colorScales:n,interpolateColor:l,getContrastColor:r}={colorScales:ln,interpolateColor:rn,interpolateBetweenColors:sn,colorIsDarkAdvanced:on,getContrastColor:cn};function s(e){if("number"==typeof e)return e;if("string"==typeof e){const t=parseFloat(e);return isNaN(t)?null:t}return null}return{getCellStyle:function(o,i,c){if(!o||null===o.value||"number"!=typeof o.value)return{};const d=n[t.value];if(!d)return{};const u=function(t,n,l){const r=s(t.value);if(null===r)return.5;if("global"===a.value){const t=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(t.length>0){const e=Math.min(...t),a=Math.max(...t);if(a!==e)return(r-e)/(a-e)}}else if("column"===a.value){const t=e.value.rows.map(e=>e.cells[l]).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(t.length>0){const e=Math.min(...t),a=Math.max(...t);if(a!==e)return(r-e)/(a-e)}}else if("row"===a.value){const t=e.value.rows.find(e=>e.label===n);if(t){const e=t.cells.filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(e.length>0){const t=Math.min(...e),a=Math.max(...e);if(a!==t)return(r-t)/(a-t)}}}return.5}(o,i,c),p=l(u,d.colors);return{backgroundColor:`${p} !important`,color:`${r(p)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},getSummaryStyle:function(a){if(!a||null===a.value||"number"!=typeof a.value)return{};const o=n[t.value];if(!o)return{};let i=.5;const c=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(c.length>0){const e=Math.min(...c),t=Math.max(...c),n=s(a.value);null!==n&&(i=t!==e?(n-e)/(t-e):.5)}const d=l(i,o.colors);return{backgroundColor:`${d} !important`,color:`${r(d)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},styleKey:i(()=>`${t.value}-${a.value}`)}}const un={class:"pivot-config"},pn={class:"config-row"},mn={class:"config-group"},fn=["value","aria-label"],vn={label:"Categorical"},gn=["value"],bn={class:"config-group"},hn=["value","aria-label"],yn={label:"Categorical"},_n=["value"],Cn={class:"config-group"},kn=["value","aria-label"],wn={label:"Extracted Values"},xn=["value"],Sn={label:"Numeric Fields"},In=["value"],Pn={class:"config-group"},Tn=["value","aria-label"],En=N(t({__name:"PivotConfiguration",props:{config:{},availableFields:{}},emits:["update-config"],setup(e,{emit:t}){const l=t;function s(e,t){l("update-config",e,t)}function o(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}return(e,t)=>(n(),a("div",un,[r("div",pn,[r("div",mn,[t[4]||(t[4]=r("label",{for:"pivot-row-field"},"Rows (Group by):",-1)),r("select",{id:"pivot-row-field",value:e.config.rowField,"aria-label":"Group rows by "+o(e.config.rowField),onChange:t[0]||(t[0]=e=>s("rowField",e.target.value))},[r("optgroup",vn,[(n(!0),a(g,null,b(e.availableFields.categorical,e=>(n(),a("option",{key:e,value:e},y(o(e)),9,gn))),128))])],40,fn)]),r("div",bn,[t[5]||(t[5]=r("label",{for:"pivot-column-field"},"Columns (Group by):",-1)),r("select",{id:"pivot-column-field",value:e.config.columnField,"aria-label":"Group columns by "+o(e.config.columnField),onChange:t[1]||(t[1]=e=>s("columnField",e.target.value))},[r("optgroup",yn,[(n(!0),a(g,null,b(e.availableFields.categorical,e=>(n(),a("option",{key:e,value:e},y(o(e)),9,_n))),128))])],40,hn)]),r("div",Cn,[t[6]||(t[6]=r("label",{for:"pivot-value-field"},"Values (Aggregate):",-1)),r("select",{id:"pivot-value-field",value:e.config.valueField,"aria-label":"Aggregate "+e.config.valueField+" values",onChange:t[2]||(t[2]=e=>s("valueField",e.target.value))},[r("optgroup",wn,[(n(!0),a(g,null,b(e.availableFields.extracted,e=>(n(),a("option",{key:e,value:e},y(e),9,xn))),128))]),r("optgroup",Sn,[(n(!0),a(g,null,b(e.availableFields.numeric,e=>(n(),a("option",{key:e,value:e},y(o(e)),9,In))),128))])],40,kn)]),r("div",Pn,[t[8]||(t[8]=r("label",{for:"pivot-aggregation"},"Aggregation:",-1)),r("select",{id:"pivot-aggregation",value:e.config.aggregation,"aria-label":"Aggregation method: "+e.config.aggregation,onChange:t[3]||(t[3]=e=>s("aggregation",e.target.value))},t[7]||(t[7]=[_('<optgroup label="Statistical" data-v-efb8a7c2><option value="mean" data-v-efb8a7c2>Mean</option><option value="median" data-v-efb8a7c2>Median</option><option value="variance" data-v-efb8a7c2>Variance</option><option value="std_dev" data-v-efb8a7c2>Std Dev</option><option value="min" data-v-efb8a7c2>Min</option><option value="max" data-v-efb8a7c2>Max</option></optgroup><optgroup label="Frequency" data-v-efb8a7c2><option value="count" data-v-efb8a7c2>Count</option><option value="mode" data-v-efb8a7c2>Mode</option></optgroup><optgroup label="Performance" data-v-efb8a7c2><option value="success_rate" data-v-efb8a7c2>Success Rate</option><option value="refusal_rate" data-v-efb8a7c2>Refusal Rate</option><option value="avg_time" data-v-efb8a7c2>Avg Time</option></optgroup>',3)]),40,Tn)])])]))}}),[["__scopeId","data-v-efb8a7c2"]]),Mn={class:"heatmap-controls"},An={class:"color-scale-selector"},Nn=["value","aria-label"],$n={class:"gradient-mode-selector"},Fn={class:"gradient-toggle",role:"group","aria-label":"Gradient mode selector"},On=["aria-pressed"],Rn=["aria-pressed"],Dn=["aria-pressed"],jn=["title","aria-label"],qn=N(t({__name:"PivotHeatmapControls",props:{selectedColorScale:{},gradientMode:{},isFullscreen:{type:Boolean}},emits:["update-color-scale","update-gradient-mode","toggle-fullscreen"],setup(e,{emit:t}){const l=t;function s(e){const t=e.target.value;l("update-color-scale",t)}function o(e){l("update-gradient-mode",e)}return(e,t)=>(n(),a("div",Mn,[r("div",An,[t[5]||(t[5]=r("label",{for:"heatmap-color-scale"},"Color Scale:",-1)),r("select",{id:"heatmap-color-scale",value:e.selectedColorScale,"aria-label":"Color scale: "+e.selectedColorScale,onChange:s},t[4]||(t[4]=[_('<option value="blue-subtle" data-v-4b4f9d62>Blue (Subtle)</option><option value="green-red" data-v-4b4f9d62>Green-Red (Success)</option><option value="blue-yellow" data-v-4b4f9d62>Blue-Yellow (Performance)</option><option value="purple-orange" data-v-4b4f9d62>Purple-Orange (General)</option><option value="viridis" data-v-4b4f9d62>Viridis</option><option value="inferno" data-v-4b4f9d62>Inferno</option><option value="magma" data-v-4b4f9d62>Magma</option><option value="plasma" data-v-4b4f9d62>Plasma</option><option value="grayscale" data-v-4b4f9d62>Grayscale</option>',9)]),40,Nn)]),r("div",$n,[t[6]||(t[6]=r("label",null,"Gradient Mode:",-1)),r("div",Fn,[r("button",{type:"button",class:S(["toggle-btn",{active:"global"===e.gradientMode}]),"aria-pressed":"global"===e.gradientMode,onClick:t[0]||(t[0]=e=>o("global"))}," Global ",10,On),r("button",{type:"button",class:S(["toggle-btn",{active:"column"===e.gradientMode}]),"aria-pressed":"column"===e.gradientMode,onClick:t[1]||(t[1]=e=>o("column"))}," Per Column ",10,Rn),r("button",{type:"button",class:S(["toggle-btn",{active:"row"===e.gradientMode}]),"aria-pressed":"row"===e.gradientMode,onClick:t[2]||(t[2]=e=>o("row"))}," Per Row ",10,Dn)])]),r("button",{type:"button",class:"fullscreen-btn",title:e.isFullscreen?"Exit Fullscreen":"Enter Fullscreen","aria-label":e.isFullscreen?"Exit fullscreen mode":"Enter fullscreen mode",onClick:t[3]||(t[3]=t=>e.$emit("toggle-fullscreen"))},y(e.isFullscreen?"⊟":"⊞"),9,jn)]))}}),[["__scopeId","data-v-4b4f9d62"]]),Ln={class:"filters-row"},Un={key:0,class:"filter-group"},zn=["value"],Bn=["for"],Vn=["id","onUpdate:modelValue","aria-label"],Kn={value:""},Gn=["value"],Yn={key:1,class:"filter-group"},Hn=["value"],Jn={class:"table-view"},Wn={key:0,class:"empty-state","data-testid":"empty-data-message"},Xn={key:1,class:"error-state","data-testid":"invalid-aggregation-error"},Qn={key:2,class:"pivot-table-container"},Zn={class:"pivot-table-grid responsive-table",role:"table"},el={role:"row"},tl={class:"corner-cell",role:"columnheader"},al={key:0,class:"total-header",role:"columnheader"},nl={class:"row-header",role:"rowheader"},ll=["data-testid","title","aria-label","role","onClick","onKeydown"],rl={key:0,class:"cell-content"},sl=["title"],ol={class:"cell-value"},il={class:"error-message"},cl={key:1},dl=N(t({__name:"PivotTableCore",props:{apiCalls:{},trial:{default:null},config:{},maxTableRows:{default:1e4},showTotals:{type:Boolean,default:!0}},emits:["config-change","cell-click"],setup(e,{emit:t}){const s=e,c=t,p=o(!1),m=o("viridis"),v=o("global"),h=o({rowField:s.config?.rowField||"",columnField:s.config?.columnField||"",valueField:s.config?.valueField||"",aggregation:s.config?.aggregation||"mean"});w(()=>s.config,e=>{e&&Object.assign(h.value,e)},{deep:!0});const _=o({}),C=o([]),k=i(()=>Object.values(_.value).some(e=>""!==e)),N=I(en(s.apiCalls,s.trial));let F=0;w(()=>s.apiCalls,e=>{if(0===e.length||0===F||e.length-F>=10){const t=C.value.length>0||k.value?C.value:e;N.value=en(t,s.trial),F=e.length}},{immediate:!0});const O=I({});let R=0;w(()=>s.apiCalls.length,e=>{(0===e||0===R||e-R>=5)&&((()=>{if(0===s.apiCalls.length)return void(O.value={});const e={};s.apiCalls.forEach(t=>{if(s.trial&&t.configurationIndex<s.trial.configurationSnapshots.length){const a=s.trial.configurationSnapshots[t.configurationIndex].modelId||"Unknown";e.model||(e.model=new Set),e.model.add(a)}t.status&&(e.status||(e.status=new Set),e.status.add(t.status)),t.variables&&Object.entries(t.variables).forEach(([t,a])=>{a&&String(a).trim()&&(e[t]||(e[t]=new Set),e[t].add(String(a)))})});const t={};Object.entries(e).forEach(([e,a])=>{t[e]=Array.from(a).sort()}),O.value=t})(),R=e)},{immediate:!0});const D=i(()=>{const{model:e,status:t,...a}=O.value;return a});function j(){C.value=s.apiCalls.filter(e=>{if(_.value.model&&""!==_.value.model){if(!s.trial||e.configurationIndex>=s.trial.configurationSnapshots.length)return!1;if((s.trial.configurationSnapshots[e.configurationIndex].modelId||"Unknown")!==_.value.model)return!1}if(_.value.status&&""!==_.value.status&&e.status!==_.value.status)return!1;for(const[t,a]of Object.entries(_.value))if(a&&""!==a&&"model"!==t&&"status"!==t){const n=e.variables?.[t];if(n!==a)return!1}return!0})}function q(){_.value={},j()}w(()=>s.apiCalls,()=>{k.value?j():C.value=s.apiCalls},{immediate:!0});const L=i(()=>{const e=C.value.length>0||k.value?C.value:s.apiCalls;return 0===e.length?{rows:[],columns:[],totals:[],grandTotal:{value:0,count:0,apiCalls:[],rawValues:[]}}:function(e,t,a){const n=new Map,l=new Set,r=new Set;e.forEach(e=>{const s=String(tn(e,t.rowField,a)||"Unknown"),o=String(tn(e,t.columnField,a)||"Unknown");l.add(s),r.add(o),n.has(s)||n.set(s,new Map),n.get(s).has(o)||n.get(s).set(o,[]),n.get(s).get(o).push(e)});const s=e=>e.every(e=>!isNaN(Number(e))&&""!==e.trim())?e.sort((e,t)=>Number(e)-Number(t)):e.sort(),o=s(Array.from(l)),i=s(Array.from(r)),c=an[t.aggregation];function d(e){const n=e.map(e=>tn(e,t.valueField,a));if(!c||"function"!=typeof c.calculate)return $.error("Invalid aggregation function:",t.aggregation,c),{value:null,count:e.length,apiCalls:e,rawValues:n,error:"Invalid aggregation function"};const l={nonNumeric:0,nullUndefined:0};return c.needsNumeric&&(l.nonNumeric=n.filter(e=>"number"!=typeof e).length),l.nullUndefined=n.filter(e=>null==e).length,{value:c.usesApiCalls?c.calculate(n,e):c.calculate(n),count:e.length,apiCalls:e,rawValues:n,excludedCounts:l}}const u=o.map(e=>{const t=[],a=[];return i.forEach(l=>{const r=n.get(e)?.get(l)||[];t.push(r.length>0?d(r):null),a.push(...r)}),{label:e,cells:t,total:d(a)}}),p=i.map(e=>{const t=[];return o.forEach(a=>{const l=n.get(a)?.get(e)||[];t.push(...l)}),d(t)});return{rows:u,columns:i,totals:p,grandTotal:d(e)}}(e,h.value,s.trial)}),U=i(()=>L.value.rows),{getCellStyle:z,getSummaryStyle:B,styleKey:V}=dn(L,m,v);function K(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}function G(e,t,a){if(!a)return`${e} × ${t}: No data`;let n=`${e} × ${t}: ${nn(a,h.value.aggregation)} (${a.count} calls)`;if(a.excludedCounts){const e=[];a.excludedCounts.nonNumeric>0&&e.push(`${a.excludedCounts.nonNumeric} non-numeric responses excluded`),a.excludedCounts.nullUndefined>0&&e.push(`${a.excludedCounts.nullUndefined} null/empty responses`),e.length>0&&(n+=` | ${e.join(", ")}`)}return a.error&&(n+=` - ERROR: ${a.error}`),n}function Y(e,t,a){if(!a)return`${e} by ${t}: No data`;const n=nn(a,h.value.aggregation);return a.error?`${e} by ${t}: ${n} with data integrity error: ${a.error}`:`${e} by ${t}: ${n} from ${a.count} API calls`}function H(e,t){"rowField"!==e&&"columnField"!==e&&"valueField"!==e&&"aggregation"!==e||(h.value[e]=t),c("config-change",{...h.value})}function J(e,t,a){a&&c("cell-click",{row:e,column:t,cell:a})}function W(){p.value=!p.value,p.value?document.body.style.overflow="hidden":document.body.style.overflow=""}return d(()=>{p.value&&(document.body.style.overflow="")}),w([N,()=>s.apiCalls.length],([e])=>{if(s.apiCalls.length>0&&(!h.value.rowField||""===h.value.rowField)&&e.categorical.length>0){if(h.value.rowField=e.categorical.find(e=>"model"!==e&&"status"!==e&&"error_type"!==e)||e.categorical[0]||"model",h.value.columnField=h.value.columnField||"model",h.value.valueField=h.value.valueField||"extracted_value",!h.value.aggregation||""===h.value.aggregation){const e=s.apiCalls.slice(0,3).map(e=>tn(e,h.value.valueField,s.trial)).filter(e=>null!=e),t=e.length>0&&e.every(e=>"number"==typeof e);h.value.aggregation=t?"mean":"mode"}c("config-change",{...h.value})}},{immediate:!0}),(e,t)=>(n(),a("div",{class:S(["pivot-table-core",{fullscreen:p.value}])},[P([N.value,h.value],()=>(n(),a("div",null,[u(En,{config:h.value,"available-fields":N.value,onUpdateConfig:H},null,8,["config","available-fields"])])),t,0),u(qn,{"selected-color-scale":m.value,"gradient-mode":v.value,"is-fullscreen":p.value,onUpdateColorScale:t[1]||(t[1]=e=>m.value=e),onUpdateGradientMode:t[2]||(t[2]=e=>v.value=e),onToggleFullscreen:W},null,8,["selected-color-scale","gradient-mode","is-fullscreen"]),Object.keys(O.value).length>0?P([O.value,_.value],()=>(n(),a("div",{key:0,class:"data-filters"},[r("div",Ln,[O.value.model&&O.value.model.length>1?(n(),a("div",Un,[t[7]||(t[7]=r("label",{for:"filter-model",class:"filter-label"},"Model:",-1)),M(r("select",{id:"filter-model","onUpdate:modelValue":t[3]||(t[3]=e=>_.value.model=e),class:"filter-select","aria-label":"Filter by model",onChange:j},[t[6]||(t[6]=r("option",{value:""},"All Models",-1)),(n(!0),a(g,null,b(O.value.model,e=>(n(),a("option",{key:e,value:e},y(e),9,zn))),128))],544),[[A,_.value.model]])])):l("",!0),(n(!0),a(g,null,b(D.value,(e,t)=>(n(),a("div",{key:t,class:"filter-group"},[r("label",{for:`filter-${t}`,class:"filter-label"},y(K(String(t)))+": ",9,Bn),M(r("select",{id:`filter-${t}`,"onUpdate:modelValue":e=>_.value[t]=e,class:"filter-select","aria-label":`Filter by ${K(String(t))}`,onChange:j},[r("option",Kn,"All "+y(K(String(t))),1),(n(!0),a(g,null,b(e,e=>(n(),a("option",{key:e,value:e},y(e),9,Gn))),128))],40,Vn),[[A,_.value[t]]])]))),128)),O.value.status&&O.value.status.length>1?(n(),a("div",Yn,[t[9]||(t[9]=r("label",{for:"filter-status",class:"filter-label"},"Status:",-1)),M(r("select",{id:"filter-status","onUpdate:modelValue":t[4]||(t[4]=e=>_.value.status=e),class:"filter-select","aria-label":"Filter by status",onChange:j},[t[8]||(t[8]=r("option",{value:""},"All Statuses",-1)),(n(!0),a(g,null,b(O.value.status,e=>(n(),a("option",{key:e,value:e},y(e),9,Hn))),128))],544),[[A,_.value.status]])])):l("",!0),k.value?(n(),a("button",{key:2,type:"button",class:"clear-filters-btn",title:"Clear all filters","aria-label":"Clear all filters",onClick:q}," Clear Filters ")):l("",!0)])])),t,5):l("",!0),r("div",Jn,[0===s.apiCalls.length?(n(),a("div",Wn,t[10]||(t[10]=[r("p",null,"No data available for pivot table analysis.",-1)]))):h.value.aggregation in f(an)?(n(),a("div",Qn,[r("table",Zn,[r("thead",null,[r("tr",el,[r("th",tl,y(K(h.value.rowField)||"Items")+" / "+y(K(h.value.columnField)||"Aggregated"),1),(n(!0),a(g,null,b(L.value.columns,e=>(n(),a("th",{key:e,class:"column-header",role:"columnheader"},y(e),1))),128)),h.value.columnField&&e.showTotals?(n(),a("th",al," Total ")):l("",!0)])]),r("tbody",null,[(n(!0),a(g,null,b(U.value,t=>(n(),a("tr",{key:`${t.label}-${f(V)}`,class:"data-row",role:"row"},[r("td",nl,y(t.label),1),(n(!0),a(g,null,b(t.cells,(e,l)=>(n(),a("td",{key:`${l}-${f(V)}`,class:S(["data-cell",{"error-cell":e?.error}]),"data-testid":e?.error?"pivot-cell-error":"pivot-cell",style:E(f(z)(e,t.label,l)),title:G(t.label,L.value.columns[l],e),"aria-label":Y(t.label,L.value.columns[l],e),role:e?.error?"alert":"cell",tabindex:"0",onClick:a=>J(t.label,L.value.columns[l],e),onKeydown:[T(a=>J(t.label,L.value.columns[l],e),["enter"]),T(x(a=>J(t.label,L.value.columns[l],e),["prevent"]),["space"])]},[e?.error?(n(),a("div",rl,[r("span",{class:"error-indicator",title:e.error},"⚠️",8,sl),r("span",ol,y(e?f(nn)(e,h.value.aggregation):"-"),1),r("div",il,y(e.error),1)])):(n(),a("span",cl,y(e?f(nn)(e,h.value.aggregation):"-"),1))],46,ll))),128)),h.value.columnField&&e.showTotals?(n(),a("td",{key:0,class:"total-cell",style:E(f(B)(t.total)),role:"cell"},y(f(nn)(t.total,h.value.aggregation)),5)):l("",!0)]))),128)),h.value.rowField&&e.showTotals?(n(),a("tr",{key:`totals-${f(V)}`,class:"total-row",role:"row"},[t[12]||(t[12]=r("td",{class:"row-header",role:"rowheader"},"Total",-1)),(n(!0),a(g,null,b(L.value.totals,(e,t)=>(n(),a("td",{key:`total-${t}-${f(V)}`,class:"total-cell",style:E(f(B)(e)),role:"cell"},y(f(nn)(e,h.value.aggregation)),5))),128)),h.value.columnField?(n(),a("td",{key:0,class:"grand-total-cell",style:E(f(B)(L.value.grandTotal)),role:"cell"},y(f(nn)(L.value.grandTotal,h.value.aggregation)),5)):l("",!0)])):l("",!0)])])])):(n(),a("div",Xn,[r("p",null,"Invalid aggregation function: "+y(h.value.aggregation),1),t[11]||(t[11]=r("p",null,"Please select a valid aggregation method.",-1))]))])],2))}}),[["__scopeId","data-v-6da58b58"]]);export{Za as A,dl as P,Ut as T,ea as _,va as a,ra as p};
