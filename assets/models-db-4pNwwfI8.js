var e=Object.defineProperty,o=(o,t,a)=>((o,t,a)=>t in o?e(o,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):o[t]=a)(o,"symbol"!=typeof t?t+"":t,a);import{S as t,f as a,c as s}from"./vendor-BARfHmiz.js";import{l as r}from"./db-CL8uhZCz.js";import{p as i,l as n,o as l,m as u}from"./index-CiDH-VjL.js";class c{constructor(){o(this,"id","litellm"),o(this,"name","LiteLLM"),o(this,"LITELLM_URL","https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json")}async discover(){const e=await fetch(this.LITELLM_URL);if(!e.ok)throw new Error(`LiteLLM fetch failed: HTTP ${e.status}`);const o=await e.json();return this.processLiteLLMData(o)}processLiteLLMData(e){const o=[],t=new Date,a={openai:["openai-chat","openai-responses"],anthropic:["anthropic"]};for(const[s,r]of Object.entries(e)){const e=r.litellm_provider;if(e&&a[e])for(const l of a[e]){if(("openai-chat"===l||"openai-responses"===l)&&s.match(/(ft|image|dall|embedding|moderation|whisper|tts|transcribe|audio|realtime|search)/i))continue;const e=i.getProvider(l);if(!e)continue;const a=e.modelRules.find(e=>new RegExp(e.pattern).test(s));if(!a)continue;const u=this.extractCapabilities(s,r),c="anthropic"===l&&s.toLowerCase().includes("instant");c&&n.info("LiteLLM: Importing Anthropic instant model as disabled",{modelId:s}),o.push({id:`${l}:${s}`,provider:l,modelId:s,displayName:s,enabled:!c,source:"litellm",discoveredAt:t,modifiedAt:t,capabilities:u,parameterRules:a?{allows:"*",requires:a.requiredParams||[],forbids:a.forbidden||[],defaults:{}}:void 0,userModified:!1})}}return o}extractCapabilities(e,o){return{contextWindow:o.max_input_tokens||o.max_tokens,maxTokens:o.max_output_tokens||o.max_tokens,inputCostPerToken:o.input_cost_per_token?parseFloat(o.input_cost_per_token):0,outputCostPerToken:o.output_cost_per_token?parseFloat(o.output_cost_per_token):0,supportsFunctionCalling:o.supports_function_calling||!1,supportsJsonMode:this.inferJsonModeSupport(e,o),supportsStreaming:"bedrock"!==o.litellm_provider}}inferJsonModeSupport(e,o){return"openai"===o.litellm_provider&&(e.includes("gpt-4")||e.includes("gpt-3.5-turbo"))}}const d=["amazon/nova-lite-v1","amazon/nova-micro-v1","amazon/nova-pro-v1","anthropic/claude-3-haiku","anthropic/claude-3.5-haiku","anthropic/claude-3.5-sonnet","anthropic/claude-3.7-sonnet","anthropic/claude-3.7-sonnet:thinking","anthropic/claude-opus-4","anthropic/claude-sonnet-4","cohere/command-a","cohere/command-r","cohere/command-r-plus","deepseek/deepseek-chat","deepseek/deepseek-r1","google/gemini-2.0-flash-001","google/gemini-2.0-flash-lite-001","google/gemini-2.5-flash","google/gemini-2.5-flash-preview","google/gemini-2.5-flash-preview:thinking","google/gemini-2.5-pro","google/gemini-2.5-pro-preview","google/gemini-flash-1.5","google/gemini-flash-1.5-8b","google/gemini-pro-1.5","google/gemma-2-27b-it","google/gemma-2-9b-it","google/gemma-3-12b-it","google/gemma-3-27b-it","google/gemma-3-4b-it","meta-llama/llama-3-70b-instruct","meta-llama/llama-3-8b-instruct","meta-llama/llama-3.1-405b-instruct","meta-llama/llama-3.1-70b-instruct","meta-llama/llama-3.1-8b-instruct","meta-llama/llama-3.2-1b-instruct","meta-llama/llama-3.2-3b-instruct","meta-llama/llama-3.3-70b-instruct","meta-llama/llama-4-maverick","meta-llama/llama-4-scout","microsoft/phi-3-medium-128k-instruct","microsoft/phi-3-mini-128k-instruct","microsoft/phi-3.5-mini-128k-instruct","microsoft/phi-4","microsoft/phi-4-reasoning-plus","microsoft/wizardlm-2-8x22b","mistralai/ministral-3b","mistralai/ministral-8b","mistralai/mistral-7b-instruct-v0.3","mistralai/mistral-large","mistralai/mistral-large-2407","mistralai/mistral-large-2411","mistralai/mistral-small-24b-instruct-2501","mistralai/mistral-small-3.1-24b-instruct","mistralai/mistral-small-3.2-24b-instruct","mistralai/mistral-tiny","mistralai/mixtral-8x22b-instruct","mistralai/mixtral-8x7b-instruct","nvidia/llama-3.1-nemotron-70b-instruct","nvidia/llama-3.1-nemotron-ultra-253b-v1","nvidia/llama-3.3-nemotron-super-49b-v1","openai/gpt-3.5-turbo-0613","openai/gpt-4-0314","openai/gpt-4-1106-preview","openai/gpt-4.1","openai/gpt-4.1-mini","openai/gpt-4.1-nano","openai/gpt-4.5-preview","openai/gpt-4o-2024-05-13","openai/gpt-4o-2024-08-06","openai/gpt-4o-2024-11-20","openai/gpt-4o-mini-2024-07-18","openai/o1-mini-2024-09-12","openai/o1-preview-2024-09-12","openai/o1-pro","openai/o3","openai/o3-mini","openai/o3-mini-high","openai/o3-pro","openai/o4-mini","openai/o4-mini-high","perplexity/r1-1776","perplexity/sonar","perplexity/sonar-deep-research","perplexity/sonar-pro","perplexity/sonar-reasoning","perplexity/sonar-reasoning-pro","qwen/qwen-2-72b-instruct","qwen/qwen-2.5-72b-instruct","qwen/qwen-2.5-7b-instruct","qwen/qwen-2.5-vl-7b-instruct","qwen/qwen-max","qwen/qwen-plus","qwen/qwen-turbo","qwen/qwen3-14b","qwen/qwen3-235b-a22b","qwen/qwen3-32b","qwen/qwen3-8b","qwen/qwq-32b","x-ai/grok-2-1212","x-ai/grok-3","x-ai/grok-3-beta","x-ai/grok-3-mini","x-ai/grok-3-mini-beta","x-ai/grok-4"],m={defaultEnabledModels:d},p=Object.freeze(Object.defineProperty({__proto__:null,default:m,defaultEnabledModels:d},Symbol.toStringTag,{value:"Module"}));class f{constructor(){o(this,"id","openrouter"),o(this,"name","OpenRouter"),o(this,"defaultEnabledModels",new Set(m.defaultEnabledModels))}async discover(){const e=await fetch("https://openrouter.ai/api/v1/models");if(!e.ok)throw new Error(`OpenRouter fetch failed: HTTP ${e.status}`);const o=await e.json();return this.processOpenRouterData(o)}processOpenRouterData(e){const o=[],t=new Date,a=i.getProvider("openrouter");if(!a)throw new Error("OpenRouter provider not found in registry");for(const s of e.data||[]){const e=a.modelRules.find(e=>new RegExp(e.pattern).test(s.id)),r=parseFloat(s.pricing?.prompt||"0"),i=parseFloat(s.pricing?.completion||"0"),n=this.defaultEnabledModels.has(s.id);o.push({id:`openrouter:${s.id}`,provider:"openrouter",modelId:s.id,displayName:s.id,enabled:n,source:"openrouter",discoveredAt:t,modifiedAt:t,capabilities:{contextWindow:s.context_length||4096,maxTokens:s.top_provider?.max_completion_tokens,inputCostPerToken:r,outputCostPerToken:i,supportsJsonMode:s.supported_parameters?.includes("response_format")||!1,supportsFunctionCalling:s.supported_parameters?.includes("tools")||!1,supportsStreaming:!0},parameterRules:e?{allows:"*",requires:e.requiredParams||[],forbids:e.forbidden||[],defaults:{}}:void 0,userModified:!1})}return o}}class h{constructor(){o(this,"id","ollama"),o(this,"name","Ollama")}async discover(){const e=await l.settings.get("main"),o=e?.customBaseUrls["ollama-chat"]||"http://localhost:11434",t=await fetch(`${o}/api/tags`,{signal:AbortSignal.timeout(3e3)});if(!t.ok)throw new Error(`Ollama not available: HTTP ${t.status}`);const a=await t.json();return this.processOllamaData(a)}processOllamaData(e){const o=[],t=new Date;for(const a of e.models||[])for(const e of["ollama-chat","ollama-generate"]){const s=i.getProvider(e);if(!s)continue;const r=s.modelRules.find(e=>new RegExp(e.pattern).test(a.name));o.push({id:`${e}:${a.name}`,provider:e,modelId:a.name,displayName:a.name,enabled:!0,source:"ollama",discoveredAt:t,modifiedAt:t,parameterRules:r?{allows:"*",requires:r.requiredParams||[],forbids:r.forbidden||[],defaults:{}}:void 0,capabilities:{inputCostPerToken:0,outputCostPerToken:0,supportsStreaming:!0},userModified:!1})}return o}}const g=new class{constructor(){o(this,"sources"),o(this,"sourceStatus"),o(this,"discoveryPromise",null),this.sources=new Map([["litellm",new c],["openrouter",new f],["ollama",new h]]),this.sourceStatus=new Map;for(const[e]of this.sources)this.sourceStatus.set(e,{id:e,status:"idle"})}async discoverModels(e={}){if(this.discoveryPromise)return this.discoveryPromise;this.discoveryPromise=this.performDiscovery(e);try{return await this.discoveryPromise}finally{this.discoveryPromise=null}}async performDiscovery(e){const{sources:o=["litellm","openrouter","ollama"],forceRefresh:t=!1,onProgress:a}=e,s=[];let r=0;if(!t){const e=await l.models.count();if(e>0)return n.info("Skipping discovery: models already exist",{existingCount:e}),{sources:Array.from(this.sourceStatus.values()),totalModels:e,errors:[]}}for(const n of o)this.updateSourceStatus(n,"loading"),a?.({source:n,status:"loading",message:`Discovering ${n} models...`});const i=o.map(e=>this.discoverFromSource(e)),u=await Promise.allSettled(i),c=[],d=[];let m=!1;if(u.forEach((e,t)=>{const r=o[t];if("fulfilled"===e.status){const o=e.value;c.push(...o),"ollama"===r&&d.push(...o),this.updateSourceStatus(r,"success",void 0,o.length),a?.({source:r,status:"success",message:`Discovered ${o.length} models from ${r}`})}else{const o=e.reason?.message||"Unknown error";s.push(`${r}: ${o}`),"ollama"===r&&(m=!0),this.updateSourceStatus(r,"error",o),a?.({source:r,status:"error",error:o})}}),o.includes("ollama")){const e=w();if(m)await e.disableModelsBySource("ollama"),n.info("Disabled all Ollama models due to server unavailability");else if(d.length>=0){const o=d.map(e=>e.id);await e.disableModelsBySource("ollama",o),n.info("Updated Ollama models availability",{available:d.length})}}return c.length>0&&(await l.models.bulkPut(c),r=c.length),{sources:Array.from(this.sourceStatus.values()),totalModels:r,errors:s}}async discoverFromSource(e){const o=this.sources.get(e);if(!o)throw new Error(`Unknown source: ${e}`);try{return await o.discover()}catch(t){throw"ollama"===e&&t instanceof Error?n.info("Ollama not available",{message:t.message}):n.error("Failed to discover from source",t,{sourceId:e}),t}}updateSourceStatus(e,o,t,a){const s=this.sourceStatus.get(e);s&&this.sourceStatus.set(e,{...s,status:o,error:t,modelCount:a,lastUpdated:new Date})}getSourceStatus(){return Array.from(this.sourceStatus.values())}async refreshSource(e){if("ollama"===e)try{const e=this.sources.get("ollama");if(!e)throw new Error("Ollama source not found");const o=await e.discover();o.length>0&&await l.models.bulkPut(o);const t=w(),a=o.map(e=>e.id);await t.disableModelsBySource("ollama",a),this.updateSourceStatus("ollama","success",void 0,o.length),n.info("Ollama refresh successful",{modelCount:o.length})}catch(o){const e=w();await e.disableModelsBySource("ollama");const t=o instanceof Error?o.message:"Unknown error";throw this.updateSourceStatus("ollama","error",t),n.info("Ollama refresh failed - disabled all Ollama models",{error:t}),o}else await this.discoverModels({sources:[e],forceRefresh:!0})}async enableOpenRouterFavorites(){const e=await u(()=>Promise.resolve().then(()=>p),void 0,import.meta.url),o=new Set(e.default.defaultEnabledModels),t=(await l.models.where("provider").equals("openrouter").toArray()).map(e=>({key:e.id,changes:{enabled:o.has(e.modelId),modifiedAt:new Date}}));await l.models.bulkUpdate(t)}async retryFailedSources(e=3){const o=Array.from(this.sourceStatus.values()).filter(e=>"error"===e.status).map(e=>e.id);if(0===o.length)return{sources:this.getSourceStatus(),totalModels:await l.models.count(),errors:[]};let t=0,a=1e3;for(;t<e&&o.length>0;){t++,n.info("Retry attempt for failed sources",{attempt:t,failedSources:o}),await new Promise(e=>setTimeout(e,a)),a*=2;const e=await this.discoverModels({sources:o,forceRefresh:!0});o.length=0,e.sources.forEach(e=>{"error"===e.status&&o.push(e.id)})}return{sources:this.getSourceStatus(),totalModels:await l.models.count(),errors:o.map(e=>`${e}: Max retries exceeded`)}}},w=t("models",()=>{const e=a([]),o=a(!0),t=a([]),i=a([]);let u=null;const c=s(()=>e.value),d=s(()=>{const o={};for(const t of e.value)o[t.provider]||(o[t.provider]=[]),o[t.provider].push(t);for(const e in o)o[e].sort((e,o)=>e.enabled!==o.enabled?e.enabled?-1:1:e.displayName.localeCompare(o.displayName));return o}),m=s(()=>e.value.filter(e=>e.enabled)),p=s(()=>e=>d.value[e]||[]),f=s(()=>(o,t)=>e.value.find(e=>e.id===`${o}:${t}`));async function h(e,o){await l.models.update(e,{...o,modifiedAt:new Date})}async function w(e=!1){o.value=!0,i.value=[];try{const o=await g.discoverModels({forceRefresh:e,onProgress:e=>{n.info("Discovery progress",{source:e.source,status:e.status,message:e.message||e.error})}});return t.value=o.sources,i.value=o.errors,o}catch(a){throw n.error("Model discovery failed",a),a}finally{o.value=!1}}async function b(){if(0===await l.models.where("enabled").equals(1).count()){n.info("No models enabled, enabling defaults");0===await l.models.count()?await w():await g.enableOpenRouterFavorites()}}return async function(){await l.open(),u=r(()=>l.models.toArray()).subscribe({next:t=>{e.value=t,o.value=!1},error:e=>{n.error("Models subscription error",e),o.value=!1}})}().then(()=>{b()}),{models:s(()=>e.value),isLoading:s(()=>o.value),discoveryStatus:s(()=>t.value),discoveryErrors:s(()=>i.value),allModels:c,modelsByProvider:d,enabledModels:m,getModelsForProvider:p,getModel:f,addModel:async function(e){const o=new Date,t={...e,discoveredAt:o,modifiedAt:o};await l.models.put(t)},addModels:async function(e){const o=new Date,t=e.map(e=>({...e,discoveredAt:o,modifiedAt:o}));await l.models.bulkPut(t)},updateModel:h,toggleModel:async function(e,o){await h(e,{enabled:o})},toggleProvider:async function(o,t){const a=e.value.filter(e=>e.provider===o).map(e=>({key:e.id,changes:{enabled:t,modifiedAt:new Date}}));await l.models.bulkUpdate(a)},deleteModel:async function(e){const o=await l.models.get(e);if(!o||"user"!==o.source)throw new Error("Can only delete user-created models");await l.models.delete(e)},disableModelsBySource:async function(o,t){const a=e.value.filter(e=>e.source===o&&e.enabled&&(!t||!t.includes(e.id)));if(a.length>0){const e=a.map(e=>({key:e.id,changes:{enabled:!1,modifiedAt:new Date}}));await l.models.bulkUpdate(e),n.info(`Disabled ${a.length} models from source: ${o}`)}},clearModels:async function(){await l.models.clear()},discoverModels:w,refreshSource:async function(e){try{await g.refreshSource(e),t.value=g.getSourceStatus()}catch(o){throw n.error("Failed to refresh source",o,{sourceId:e}),o}},enableDefaultModels:b,ensureDefaultsEnabled:b,cleanup:function(){u?.unsubscribe()}}});export{g as m,w as u};
