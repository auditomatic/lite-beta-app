import{d as e,a6 as t,Y as a,a1 as n,_ as l,ag as r,f as s,c as o,o as i,b as c,k as d,Z as u,u as p,H as m,W as f,G as v,F as g,a8 as b,a0 as h,V as _,a7 as y,n as C,z as k,a9 as w,B as x,aa as S,w as I,s as P,aj as T,ae as A,ac as M,q as E,ah as N}from"./vendor-AtAbR8ZE.js";import{_ as $}from"./BaseModal.vue_vue_type_style_index_0_lang-Dt0u-Isl.js";import{_ as O,l as F,z as R,o as j,a as D,u as q,p as L,e as U,E as B,G as z,A as V,H as K,J as G,K as Y}from"./index-CUKeN6v3.js";import{G as H}from"./GenericModelSelectorModal-DO51gLSO.js";import{u as J}from"./designs-db-DRTwaT6B.js";import{u as W}from"./variables-db-w0s2OEpK.js";import{u as X}from"./models-db-otj6c6HH.js";import{u as Q}from"./EnvironmentalCostSummary-Bfbp4R2h.js";import{a as Z}from"./cost-formatting-Bv_drrqY.js";const ee={class:"modal-footer"},te={key:0,class:"footer-left"},ae={class:"footer-actions"},ne=O(e({__name:"ModalFooter",setup:e=>(e,s)=>(a(),t("div",ee,[e.$slots.left?(a(),t("div",te,[r(e.$slots,"left",{},void 0,!0)])):n("",!0),l("div",ae,[r(e.$slots,"default",{},void 0,!0)])]))}),[["__scopeId","data-v-3a3879d0"]]);function le(){const e=J(),t=W(),a=s(""),n=s(0);let l=null;const r=o(()=>{const t=e.designs;if(F.info("Designs available",{count:t.length}),!a.value)return t;const n=a.value.toLowerCase();return t.filter(e=>e.name.toLowerCase().includes(n)||e.promptTemplate.toLowerCase().includes(n))});function d(e){return e.replace(/\n+/g," ").replace(/\s+/g," ").trim()}function u(e){if(!e.variableBindings)return[{}];const a=[];for(const[r,s]of Object.entries(e.variableBindings))if("direct"===s.type&&s.values)a.push({name:r,values:s.values});else if("list"===s.type&&s.listId){const e=t.lists.find(e=>e.id===s.listId);if(e){let t=[];t="simple"===e.category&&e.values?e.values:"attributed"===e.category&&e.items?e.items.map(e=>e.value):[`${r}_sample`],a.push({name:r,values:t})}}if(0===a.length)return[{}];const n=a.map(e=>e.values);const l=[...n.reduce((e,t)=>e.flatMap(e=>t.map(t=>[...e,t])),[[]])];for(let t=l.length-1;t>0;t--){const e=Math.floor(Math.random()*(t+1));[l[t],l[e]]=[l[e],l[t]]}return l.map(e=>{const t={};return a.forEach((a,n)=>{t[a.name]=e[n]}),t})}function p(e){const t=document.createElement("div");return t.textContent=e,t.innerHTML}function m(){l||(l=setInterval(()=>{n.value++},1e3))}function f(){l&&(clearInterval(l),l=null)}return i(()=>{m()}),c(()=>{f()}),{designSearch:a,previewCycleIndex:n,filteredDesigns:r,countVariables:function(e){return Object.keys(e.variableBindings).length},truncateTemplate:d,formatLastEditDate:function(e){const t=new Date,a=t.getTime()-e.getTime(),n=Math.floor(a/864e5);if(0===n)return"Today";if(1===n)return"Yesterday";if(n<7)return`${n} days ago`;if(n<30){const e=Math.floor(n/7);return`${e} week${e>1?"s":""} ago`}return e.toLocaleDateString("en-US",{month:"short",day:"numeric",year:e.getFullYear()!==t.getFullYear()?"numeric":void 0})},getOutputTypeColor:function(e){return{text:"blue",number:"green",boolean:"purple",json:"orange"}[e]||"default"},getCombinationCount:function(e){if(!e.variableBindings)return"1";let a=1;for(const n of Object.values(e.variableBindings))if("direct"===n.type&&n.values)a*=n.values.length;else if("list"===n.type&&n.listId){const e=t.lists.find(e=>e.id===n.listId);a*=e?.itemCount||1}return a>1e3?`${(a/1e3).toFixed(1)}k`:a.toString()},generateVariableCombinations:u,getPreviewTemplateHTML:function(e){const t=u(e);if(t.length<=1)return p(d(e.promptTemplate));const a=t[n.value%t.length],l=["variable-highlight-blue","variable-highlight-green","variable-highlight-purple","variable-highlight-orange","variable-highlight-pink","variable-highlight-teal"];let r=e.promptTemplate;Object.keys(e.variableBindings||{}).forEach((e,t)=>{if(void 0!==a[e]){const n=new RegExp(`\\{\\{\\s*${e}\\s*\\}\\}`,"g"),s=`<span class="${l[t%l.length]}">${p(String(a[e]))}</span>`;r=r.replace(n,s)}});let s=p(r);return l.forEach(e=>{s=s.replace(new RegExp(`&lt;span class="${e}"&gt;`,"g"),`<span class="${e}">`).replace(/&lt;\/span&gt;/g,"</span>")}),d(s)},escapeHtml:p,startCycling:m,stopCycling:f}}const re={class:"design-selection-step"},se={class:"step-body"},oe={class:"design-selector","data-testid":"design-selector"},ie={key:0,class:"no-designs-state"},ce={class:"no-designs-content"},de={key:1,class:"design-list","data-testid":"design-list"},ue=["data-design-id","data-design-name","onClick"],pe={class:"design-header"},me={class:"design-title-section"},fe={class:"design-name"},ve={key:0,class:"design-inline-description"},ge={class:"design-date"},be=["innerHTML"],he={class:"design-stats"},_e={class:"stat-item"},ye={class:"stat-value"},Ce={class:"stat-item"},ke={class:"stat-value"},we={class:"stat-item"},xe={class:"stat-value"},Se=O(e({__name:"DesignSelectionStep",emits:["select","create-new"],setup(e){const r=J(),{designSearch:s,filteredDesigns:o,countVariables:i,formatLastEditDate:c,getOutputTypeColor:_,getCombinationCount:y,getPreviewTemplateHTML:C}=le();return(e,k)=>{const w=f("a-input"),x=f("a-button"),S=f("a-tag");return a(),t("div",re,[k[11]||(k[11]=l("div",{class:"step-header"},[l("h3",null,"What are you testing?")],-1)),l("div",se,[l("div",oe,[d(w,{value:p(s),"onUpdate:value":k[0]||(k[0]=e=>m(s)?s.value=e:null),placeholder:"Search designs...",size:"large",class:"design-search","data-testid":"input-design-search",allowClear:""},{prefix:u(()=>[d(p(R))]),_:1},8,["value"]),0===p(o).length?(a(),t("div",ie,[l("div",ce,[k[4]||(k[4]=l("p",null,"No designs found",-1)),d(x,{onClick:k[1]||(k[1]=()=>p(r).initialize())},{default:u(()=>k[3]||(k[3]=[v("Refresh Designs")])),_:1,__:[3]})])])):(a(),t("div",de,[(a(!0),t(g,null,b(p(o),r=>(a(),t("div",{key:r.id,class:"design-item","data-testid":"design-item","data-design-id":r.id,"data-design-name":r.name,onClick:t=>e.$emit("select",r)},[l("div",pe,[l("div",me,[l("h4",fe,[v(h(r.name)+" ",1),r.description?(a(),t("span",ve,"- "+h(r.description),1)):n("",!0)])]),l("span",ge,h(p(c)(r.updated)),1)]),l("p",{class:"design-description",innerHTML:p(C)(r)},null,8,be),l("div",he,[d(S,{size:"small",color:p(_)(r.outputType),class:"output-type-tag"},{default:u(()=>[v(h(r.outputType||"text"),1)]),_:2},1032,["color"]),l("span",_e,[l("span",ye,h(p(i)(r)),1),k[5]||(k[5]=l("span",{class:"stat-label"},"vars",-1))]),k[8]||(k[8]=l("span",{class:"stat-divider"},"•",-1)),l("span",Ce,[l("span",ke,h(p(y)(r)),1),k[6]||(k[6]=l("span",{class:"stat-label"},"combos",-1))]),k[9]||(k[9]=l("span",{class:"stat-divider"},"•",-1)),l("span",we,[l("span",xe,h(r.tokenEstimate?.avgTokens||"?"),1),k[7]||(k[7]=l("span",{class:"stat-label"},"tokens",-1))])])],8,ue))),128)),l("div",{class:"design-card design-card-create","data-testid":"btn-create-design",onClick:k[2]||(k[2]=t=>e.$emit("create-new"))},[d(p(j),{style:{"font-size":"24px"}}),k[10]||(k[10]=l("span",null,"Create New Design",-1))])]))])])])}}}),[["__scopeId","data-v-355d68e6"]]),Ie={class:"trial-metadata-form"},Pe={class:"form-section"},Te={class:"trial-name-section"},Ae={class:"repeat-section"},Me={class:"form-stats"},Ee={class:"stat-item"},Ne={class:"stat-value"},$e={class:"stat-item"},Oe={class:"stat-value"},Fe=O(e({__name:"TrialMetadataForm",props:{modelValue:{},totalCombinations:{}},emits:["update:modelValue"],setup(e,{emit:n}){const r=e,s=n;function o(e){s("update:modelValue",{...r.modelValue,trialName:e})}function i(e){s("update:modelValue",{...r.modelValue,repeatCount:e||1})}return(e,n)=>{const r=f("a-input"),s=f("a-input-number");return a(),t("div",Ie,[l("div",Pe,[l("div",Te,[n[0]||(n[0]=l("label",{class:"form-label"},"Trial Name:",-1)),d(r,{value:e.modelValue.trialName,"onUpdate:value":o,placeholder:"Enter trial name (optional)",class:"trial-name-input","data-testid":"input-trial-name",size:"large"},null,8,["value"])]),l("div",Ae,[n[1]||(n[1]=l("label",{class:"form-label"},"Repeat Each Prompt:",-1)),d(s,{value:e.modelValue.repeatCount,"onUpdate:value":i,min:1,max:10,size:"large",class:"repeat-count-input"},null,8,["value"]),n[2]||(n[2]=l("span",{class:"repeat-suffix"},"times",-1))])]),l("div",Me,[l("div",Ee,[n[3]||(n[3]=l("span",{class:"stat-label"},"Total Combinations:",-1)),l("span",Ne,h(e.totalCombinations),1)]),l("div",$e,[n[4]||(n[4]=l("span",{class:"stat-label"},"API Calls per Model:",-1)),l("span",Oe,h(e.totalCombinations*e.modelValue.repeatCount),1)])])])}}}),[["__scopeId","data-v-540c5b26"]]),Re={class:"model-configuration-section"},je={class:"quick-add-row"},De={class:"quick-add-section"},qe={class:"quick-add-buttons"},Le={key:0,class:"quick-cost"},Ue={key:0,class:"config-table","data-testid":"model-config-table"},Be=["data-config-index","data-provider","data-model"],ze={class:"col-model"},Ve={class:"model-name"},Ke={class:"model-provider"},Ge={class:"col-params"},Ye={class:"params-text"},He={class:"col-calls"},Je={class:"calls-breakdown"},We={class:"calls-value"},Xe={class:"col-cost"},Qe={class:"cost-breakdown"},Ze={key:0,class:"cost-value"},et={key:1,class:"env-cost"},tt={class:"col-total"},at={class:"cost-breakdown"},nt={key:0,class:"cost-value total-cost"},lt={key:1,class:"env-cost"},rt={class:"col-actions"},st={key:0,class:"table-summary-row"},ot={class:"col-model"},it={class:"summary-label"},ct={class:"col-calls"},dt={class:"summary-calls"},ut={class:"col-total"},pt={key:0,class:"summary-cost"},mt={key:1,class:"empty-config-state"},ft=O(e({__name:"ModelConfigurationSection",props:{configurations:{},design:{},totalCombinations:{},repeatCount:{}},emits:["show-model-selector","add","remove"],setup(e,{emit:r}){const s=e,i=r,c=X(),m=D(),k=q(),{hasDataForModel:w}=Q(),x=o(()=>m.financialCostsEnabled),S=o(()=>m.environmentalCostsEnabled),I=o(()=>s.totalCombinations*s.configurations.length*s.repeatCount),P=o(()=>{let e=0;for(const t of s.configurations)e+=N(t)*s.totalCombinations*s.repeatCount;return e}),T=o(()=>{const e=e=>m.hasApiKey(e),t=(e,t)=>!!c.enabledModels.find(a=>a.provider===e&&a.modelId===t&&a.enabled),a=[],n=new Set,l=[...k.trials].sort((e,t)=>new Date(t.created).getTime()-new Date(e.created).getTime());for(const c of l){if(a.length>=5)break;for(const l of c.configurationSnapshots||[]){if(a.length>=5)break;const r=`${l.provider}:${l.modelId}:${JSON.stringify(l.parameters)}`;if(!n.has(r)&&e(l.provider)&&t(l.provider,l.modelId)){const e=L.getParametersForModel(l.provider,l.modelId);if(!e)continue;if(Object.keys(l.parameters).some(t=>!(t in e)))continue;n.add(r),a.push({provider:l.provider,modelId:l.modelId,displayName:l.modelId,parameters:l.parameters,outputType:"text"})}}}const r=(e,t)=>{const a=L.getParametersForModel(e,t),n={},l=(e,t)=>{Object.entries(e).forEach(([e,a])=>{"object"===a.type&&a.properties?(t[e]={},l(a.properties,t[e])):void 0!==a.default&&(t[e]=a.default)})};l(a,n),n.temperature||!n.options||n.options.temperature||(n.options?n.options.temperature=0:n.temperature=0);const r=(e,t)=>{for(const[a,n]of Object.entries(e))"object"===n.type&&n.properties?(t[a]||(t[a]={}),r(n.properties,t[a])):n.is_output_length&&void 0===t[a]&&(t[a]=128)};return r(a,n),n},s=[{provider:"openai-chat",modelId:"gpt-4.1-nano",displayName:"gpt-4.1-nano",parameters:r("openai-chat","gpt-4.1-nano"),outputType:"text"},{provider:"anthropic",modelId:"claude-3-haiku-20240307",displayName:"claude-3-haiku-20240307",parameters:r("anthropic","claude-3-haiku-20240307"),outputType:"text"}],o=new Set(a.map(e=>`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`));for(const c of s){const n=`${c.provider}:${c.modelId}:${JSON.stringify(c.parameters)}`;!o.has(n)&&e(c.provider)&&t(c.provider,c.modelId)&&a.push(c)}const i=[],d=new Set;for(const c of a){const e=`${c.provider}:${c.modelId}`;d.has(e)||(d.add(e),i.push(c))}return i.slice(0,7)});function A(e){const t=[];for(const[a,n]of Object.entries(e))null!=n&&t.push(`${a}=${n}`);return t.join(", ")||"Default settings"}function M(e){return s.configurations.some(t=>t.provider===e.provider&&t.modelId===e.modelId&&JSON.stringify(t.parameters)===JSON.stringify(e.parameters))}function E(e){const t=c.enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t||!s.design)return 0;const a=s.design.tokenEstimate?.avgTokens||0,n=L.getParametersForModel(e.provider,e.modelId);let l=0;for(const[r,s]of Object.entries(n))if(s.is_output_length&&e.parameters[r]){l=e.parameters[r];break}if(0===a||0===l)return 0;return((t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*l)*s.totalCombinations*s.repeatCount}function N(e){const t=c.enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t||!s.design)return 0;const a=s.design.tokenEstimate?.avgTokens||0,n=L.getParametersForModel(e.provider,e.modelId);let l=0;for(const[r,s]of Object.entries(n))if(s.is_output_length&&e.parameters[r]){l=e.parameters[r];break}if(0===a||0===l)return 0;return(t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*l}function $(e){return N(e)*s.totalCombinations*s.repeatCount}function O(e){return w(e.provider,e.modelId)}function F(e,t){return"per-call"===t?"<1mg CO₂e":"~10mg CO₂e"}return(e,r)=>{const s=f("a-button");return a(),t("div",Re,[l("div",je,[d(s,{onClick:r[0]||(r[0]=t=>e.$emit("show-model-selector")),type:"primary",size:"large",class:"big-add-model-btn","data-testid":"btn-add-model","aria-label":"Add Model Configuration"},{default:u(()=>[d(p(j)),r[1]||(r[1]=v(" Add Model "))]),_:1,__:[1]}),r[3]||(r[3]=l("div",{class:"separator-bar"},null,-1)),l("div",De,[r[2]||(r[2]=l("div",{class:"quick-add-label"},"Quick add recent/popular models (with default temperature=0, max response length = 128):",-1)),l("div",qe,[(a(!0),t(g,null,b(T.value,e=>(a(),_(s,{key:`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`,onClick:t=>function(e){M(e)||(i("add",{name:e.displayName,provider:e.provider,modelId:e.modelId,parameters:e.parameters}),C(()=>{const e=document.querySelector(".ant-modal-body");e&&e.scrollTo({top:e.scrollHeight,behavior:"smooth"})}))}(e),size:"small",class:"quick-preset-btn",disabled:M(e),"data-testid":"quick-add-model","data-provider":e.provider,"data-model":e.modelId,"aria-label":`Quick add ${e.displayName} model`},{default:u(()=>[v(h(e.displayName)+" ",1),x.value?(a(),t("span",Le,h(p(Z)(E(e))),1)):n("",!0)]),_:2},1032,["onClick","disabled","data-provider","data-model","aria-label"]))),128))])])]),e.configurations.length>0?(a(),t("div",Ue,[r[8]||(r[8]=y('<div class="table-header" data-v-82ddd342><div class="col-model" data-v-82ddd342>Model</div><div class="col-params" data-v-82ddd342>Parameters</div><div class="col-calls" data-v-82ddd342>API Calls</div><div class="col-cost" data-v-82ddd342>Cost per Call</div><div class="col-total" data-v-82ddd342>Total Cost</div><div class="col-actions" data-v-82ddd342>Actions</div></div>',1)),(a(!0),t(g,null,b(e.configurations,(o,i)=>(a(),t("div",{key:i,class:"table-row","data-testid":"model-config-row","data-config-index":i,"data-provider":o.provider,"data-model":o.modelId},[l("div",ze,[l("div",Ve,h(o.provider)+":"+h(o.modelId),1),l("div",Ke,h(o.provider),1)]),l("div",Ge,[l("span",Ye,h(A(o.parameters)),1)]),l("div",He,[l("span",Je,h(e.totalCombinations)+" × "+h(e.repeatCount)+" = ",1),l("span",We,h(e.totalCombinations*e.repeatCount),1)]),l("div",Xe,[l("div",Qe,[x.value?(a(),t("span",Ze,h(p(Z)(N(o))),1)):n("",!0),S.value&&O(o)?(a(),t("small",et,h(F(0,"per-call")),1)):n("",!0)])]),l("div",tt,[l("div",at,[x.value?(a(),t("span",nt,h(p(Z)($(o))),1)):n("",!0),S.value&&O(o)?(a(),t("small",lt,h(F(0,"total")),1)):n("",!0)])]),l("div",rt,[d(s,{type:"text",size:"small",danger:"",onClick:t=>e.$emit("remove",i),class:"remove-btn","data-testid":"remove-model-config","data-config-index":i,"aria-label":`Remove ${o.provider} ${o.modelId} configuration`},{default:u(()=>r[4]||(r[4]=[v("Remove")])),_:2,__:[4]},1032,["onClick","data-config-index","aria-label"])])],8,Be))),128)),e.configurations.length>1?(a(),t("div",st,[l("div",ot,[l("div",it,"TOTAL ("+h(e.configurations.length)+" models)",1)]),r[5]||(r[5]=l("div",{class:"col-params"},null,-1)),l("div",ct,[l("span",dt,h(I.value),1)]),r[6]||(r[6]=l("div",{class:"col-cost"},null,-1)),l("div",ut,[x.value?(a(),t("span",pt,h(p(Z)(P.value)),1)):n("",!0)]),r[7]||(r[7]=l("div",{class:"col-actions"},null,-1))])):n("",!0)])):(a(),t("div",mt,r[9]||(r[9]=[l("p",null,"No models configured yet. Add at least one model to continue.",-1)])))])}}}),[["__scopeId","data-v-82ddd342"]]);const vt={class:"streamlined-content"},gt={class:"content-section"},bt={class:"section-header"},ht={class:"section-body"},_t={key:1,class:"selected-design-with-template"},yt={class:"unified-header"},Ct={class:"combinations-count"},kt={class:"header-controls"},wt=["innerHTML"],xt={key:0,class:"content-section","data-testid":"trial-config-section"},St={class:"section-body"},It={class:"model-section"},Pt=O(e({__name:"TrialCreationModalNew",props:{initialDesignId:{},trialToDuplicate:{},isEditMode:{type:Boolean}},emits:["close","created","created-and-started","export-trial"],setup(e,{emit:r}){const c=e,m=r,g=w(),b=o(()=>({type:c.isEditMode?"edit":c.trialToDuplicate?"duplicate":"create",initialDesignId:c.initialDesignId,sourceTrial:c.trialToDuplicate})),{selectedDesign:y,trialName:C,repeatCount:x,configurations:S,creating:I,showModelSelector:P,liveUpdatePaused:T,showPlaceholders:A,totalCombinations:M,canProceed:E,selectDesign:N,addConfiguration:O,removeConfiguration:R,createDraftTrial:j,createAndStartTrial:z,createAndExportTrial:V,initialize:K}=function(e){const t=J(),a=W(),n=X(),l=q(),r=D(),i=s(null),c=s(""),d=s(1),u=s([]),p=s(!1),m=s(!1),f=s(!1),v=s(!1),g=o(()=>{if(!i.value)return 0;let e=1;for(const t of Object.values(i.value.variableBindings))if("direct"===t.type)e*=t.values?.length||1;else if(t.listId){const n=a.lists.find(e=>e.id===t.listId);e*=n?.itemCount||1}return e}),b=o(()=>g.value*u.value.length*d.value),h=o(()=>{let e=0;for(const t of u.value)e+=k(t)*g.value*d.value;return e}),_=o(()=>null!==i.value&&u.value.length>0);function y(e){i.value=e,c.value=C(e),f.value=!0}function C(e){return e||i.value?`${e?.name||i.value?.name||"Trial"} - ${(new Date).toLocaleString("en-US",{month:"short",day:"numeric",hour:"2-digit",minute:"2-digit"})}`:"New Trial"}function k(e){const t=n.enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t)return 0;const a=i.value?.tokenEstimate?.avgTokens||0,l=L.getParametersForModel(e.provider,e.modelId);let r=0;for(const[n,s]of Object.entries(l))if(s.is_output_length&&e.parameters[n]){r=e.parameters[n];break}return 0===a||0===r?0:(t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*r}return{selectedDesign:i,trialName:c,repeatCount:d,configurations:u,creating:p,showModelSelector:m,liveUpdatePaused:f,showPlaceholders:v,totalCombinations:g,totalExperiments:b,totalCost:h,canProceed:_,selectDesign:y,generateTrialName:C,addConfiguration:function(e){u.value.push(e)},removeConfiguration:function(e){u.value.splice(e,1)},getConfigCostPerCall:k,createDraftTrial:async function(){if(i.value&&0!==u.value.length){p.value="draft";try{const e=await l.createTrial({name:c.value||C(),designId:i.value.id,configurations:u.value.map(e=>({name:e.name,provider:e.provider,modelId:e.modelId,parameters:{...e.parameters}})),repeatConfig:d.value>1?{callsPerPrompt:d.value,strategy:"sequential"}:void 0});return U.success("Trial created as draft!"),e}catch(e){throw F.error("Failed to create draft trial",e),U.error("Failed to create draft trial"),e}finally{p.value=!1}}},createAndStartTrial:async function(){if(i.value&&0!==u.value.length){p.value="start";try{const e=await l.createTrial({name:c.value||C(),designId:i.value.id,configurations:u.value.map(e=>({name:e.name,provider:e.provider,modelId:e.modelId,parameters:{...e.parameters}})),repeatConfig:d.value>1?{callsPerPrompt:d.value,strategy:"sequential"}:void 0});return U.success("Trial created! Starting execution..."),setTimeout(async()=>{try{await l.executeTrial(e)}catch(t){F.error("Failed to start trial",t),U.error("Failed to start trial execution")}},100),e}catch(e){throw F.error("Failed to create trial",e),U.error("Failed to create trial"),e}finally{p.value=!1}}},createAndExportTrial:async function(){if(i.value&&0!==u.value.length){p.value="export";try{const e=await l.createTrial({name:c.value||C(),designId:i.value.id,configurations:u.value.map(e=>({name:e.name,provider:e.provider,modelId:e.modelId,parameters:{...e.parameters}})),repeatConfig:d.value>1?{callsPerPrompt:d.value,strategy:"sequential"}:void 0}),t=await l.getTrial(e);if(!t)throw new Error("Trial not found after creation");return U.success("Trial created! Opening export options..."),t}catch(e){throw F.error("Failed to create trial for export",e),U.error("Failed to create trial for export"),e}finally{p.value=!1}}},initialize:async function(){await Promise.all([t.initialize(),a.initialize(),l.initialize()]);const n=e.value;if(n.initialDesignId){const e=t.designs.find(e=>e.id===n.initialDesignId);e&&y(e)}if(n.sourceTrial){const e=n.sourceTrial,a=t.designs.find(t=>t.id===e.designSnapshot.originalId);a&&(i.value=a,c.value="edit"===n.type?e.name:`Copy of ${e.name}`,e.repeatConfig?.callsPerPrompt&&(d.value=e.repeatConfig.callsPerPrompt),e.configurationSnapshots&&e.configurationSnapshots.length>0&&(u.value=e.configurationSnapshots.map(e=>({name:e.name||e.modelId,provider:e.provider,modelId:e.modelId,parameters:e.parameters||{}}))),f.value=!0)}},designsStore:t,variableListsStore:a,modelsStore:n,settingsStore:r}}(k(()=>b.value));function G(e){N(e),ee()}const{getPreviewTemplateHTML:Y,escapeHtml:Q,startCycling:Z,stopCycling:ee}=le(),te=o(()=>c.isEditMode?"Edit Trial":c.trialToDuplicate?"Duplicate Trial":"Create New Trial");function ae(){y.value=null,S.value=[],T.value=!1,Z()}function re(){m("close"),g.push({name:"designs",query:{create:"true"}})}function se(e){C.value=e.trialName,x.value=e.repeatCount}function oe(e){O(e),P.value=!1}function ie(){T.value=!T.value,T.value?ee():Z()}function ce(){A.value=!A.value}async function de(){try{const e=await j();m("created",e),m("close")}catch(e){}}async function ue(){try{const e=await z();m("created-and-started",e),m("close")}catch(e){}}async function pe(){try{const e=await V();m("export-trial",e),m("created",e.id),m("close")}catch(e){}}return i(()=>{K()}),(e,r)=>{const s=f("a-button");return a(),_($,{"model-value":!0,title:te.value,size:"full","data-testid":"modal-trial-creation","onUpdate:modelValue":r[2]||(r[2]=t=>e.$emit("close"))},{footer:u(()=>[d(ne,null,{default:u(()=>[d(s,{size:"large",onClick:de,loading:"draft"===p(I),disabled:!p(E),"data-testid":"btn-create-draft","aria-label":"Create trial as draft"},{default:u(()=>r[7]||(r[7]=[v(" Create as Draft ")])),_:1,__:[7]},8,["loading","disabled"]),d(s,{size:"large",onClick:pe,loading:"export"===p(I),disabled:!p(E),"data-testid":"btn-export-python","aria-label":"Export trial to Python"},{default:u(()=>r[8]||(r[8]=[v(" Export to Python ")])),_:1,__:[8]},8,["loading","disabled"]),d(s,{type:"primary",size:"large",onClick:ue,loading:"start"===p(I),disabled:!p(E),"data-testid":"btn-create-and-start","aria-label":"Create and start trial execution"},{default:u(()=>[d(p(B)),r[9]||(r[9]=v(" Create and Start "))]),_:1,__:[9]},8,["loading","disabled"])]),_:1})]),default:u(()=>[l("div",vt,[l("section",gt,[l("div",bt,[r[4]||(r[4]=l("h3",null,"What are you testing?",-1)),p(y)?(a(),_(s,{key:0,onClick:ae,size:"small",class:"back-button",style:{"margin-left":"2em"}},{default:u(()=>r[3]||(r[3]=[v(" ← Back to Select Design ")])),_:1,__:[3]})):n("",!0)]),l("div",ht,[p(y)?(a(),t("div",_t,[l("div",yt,[l("h4",null,h(p(y).name),1),l("span",Ct,h(p(M))+" combinations",1),l("div",kt,[d(s,{onClick:ie,size:"small",type:p(T)?"default":"primary",class:"pause-btn"},{default:u(()=>[v(h(p(T)?"Start Variable Substitution":"Pause Variable Substitution"),1)]),_:1},8,["type"]),d(s,{onClick:ce,size:"small",type:p(A)?"primary":"default",class:"placeholders-btn"},{default:u(()=>[v(h(p(A)?"Show Live":"Show Raw Template"),1)]),_:1},8,["type"])])]),l("div",{class:"live-template-preview",innerHTML:p(A)?p(Q)(p(y).promptTemplate):p(Y)(p(y))},null,8,wt)])):(a(),_(Se,{key:0,onSelect:G,onCreateNew:re}))])]),p(y)?(a(),t("section",xt,[r[6]||(r[6]=l("h3",null,"Trial Configuration",-1)),l("div",St,[d(Fe,{"model-value":{trialName:p(C),repeatCount:p(x)},"total-combinations":p(M),"onUpdate:modelValue":se},null,8,["model-value","total-combinations"]),l("div",It,[r[5]||(r[5]=l("h4",null,"Model Configuration",-1)),d(ft,{configurations:p(S),design:p(y),"total-combinations":p(M),"repeat-count":p(x),onShowModelSelector:r[0]||(r[0]=e=>P.value=!0),onAdd:p(O),onRemove:p(R)},null,8,["configurations","design","total-combinations","repeat-count","onAdd","onRemove"])])])])):n("",!0)]),d(H,{open:p(P)&&!!p(y),mode:"trial",design:p(y)||void 0,"existing-configurations":p(S),onClose:r[1]||(r[1]=e=>P.value=!1),onAddConfiguration:oe},null,8,["open","design","existing-configurations"])]),_:1},8,["title"])}}}),[["__scopeId","data-v-aecde108"]]),Tt={class:"trial-overview"},At={class:"overview-section"},Mt={class:"cost-value"},Et={key:0,class:"text-secondary",style:{"margin-left":"8px"}},Nt={class:"overview-section"},$t={class:"progress-details"},Ot={class:"progress-stats"},Ft={class:"configurations-section"},Rt={key:0,class:"model-info"},jt={key:0},Dt={class:"prompt-section"},qt={key:0,class:"variables-section"},Lt=e({__name:"TrialDetailModal",props:{trial:{}},emits:["close","updated"],setup(e){const r=e,s=[{title:"Model",key:"model",width:200},{title:"Parameters",key:"params",width:300},{title:"Cost/Call",key:"cost",width:100,align:"right"}],i=o(()=>0===r.trial.progress.total?0:Math.round(r.trial.progress.completed/r.trial.progress.total*100));function c(e){const t=Object.entries(e).map(([e,t])=>`${e}: ${t}`).join(", ");return t.length>50?t.substring(0,50)+"...":t}function p(){const e=r.trial.variableSnapshots;return e&&0!==e.length?e.map(e=>({variable:e.variableName,listName:e.originalListName,count:e.data.itemCount})):[]}return(e,r)=>{const o=f("a-button"),m=f("a-tag"),b=f("a-descriptions-item"),y=f("a-descriptions"),C=f("a-progress"),k=f("a-typography-text"),w=f("a-table"),x=f("a-typography-paragraph"),S=f("a-list-item-meta"),I=f("a-list-item"),P=f("a-list");return a(),_($,{"model-value":!0,title:e.trial.name,size:"full","onUpdate:modelValue":r[1]||(r[1]=t=>e.$emit("close"))},{footer:u(()=>[d(o,{onClick:r[0]||(r[0]=t=>e.$emit("close")),size:"large","data-testid":"btn-close-trial-detail","aria-label":"Close trial details"},{default:u(()=>r[2]||(r[2]=[v(" Close ")])),_:1,__:[2]})]),default:u(()=>[l("div",Tt,[l("div",At,[r[3]||(r[3]=l("h3",null,"Trial Information",-1)),d(y,{column:2,size:"small",bordered:""},{default:u(()=>[d(b,{label:"Status"},{default:u(()=>{return[d(m,{color:(t=e.trial.status,{completed:"success",failed:"error",running:"processing",cancelled:"default",draft:"default",pending:"processing",paused:"warning"}[t]||"default"),"data-testid":"tag-trial-status","data-status":e.trial.status,"aria-label":`Trial status: ${e.trial.status}`},{default:u(()=>[v(h(e.trial.status.toUpperCase()),1)]),_:1},8,["color","data-status","aria-label"])];var t}),_:1}),d(b,{label:"Design"},{default:u(()=>[v(h(e.trial.designSnapshot.originalName),1)]),_:1}),d(b,{label:"Created"},{default:u(()=>{return[v(h((t=e.trial.created,new Date(t).toLocaleString())),1)];var t}),_:1}),d(b,{label:"Estimated Cost"},{default:u(()=>[l("span",Mt,"$"+h(e.trial.estimatedCost.toFixed(3)),1)]),_:1}),e.trial.repeatConfig?.callsPerPrompt&&e.trial.repeatConfig.callsPerPrompt>1?(a(),_(b,{key:0,label:"Repeat Configuration"},{default:u(()=>[d(m,{color:"purple"},{default:u(()=>[v(h(e.trial.repeatConfig.callsPerPrompt)+"× repeat",1)]),_:1}),e.trial.repeatConfig.delayBetweenRepeats?(a(),t("span",Et,h(e.trial.repeatConfig.delayBetweenRepeats)+"ms delay ",1)):n("",!0)]),_:1})):n("",!0)]),_:1})]),l("div",Nt,[r[4]||(r[4]=l("h3",null,"Progress",-1)),l("div",$t,[d(C,{percent:i.value,status:"failed"===e.trial.status?"exception":"active",size:"small","data-testid":"progress-trial-completion","aria-label":`Trial progress: ${i.value}% complete`},null,8,["percent","status","aria-label"]),l("div",Ot,[d(m,{"data-testid":"tag-progress-completed","aria-label":`${e.trial.progress.completed} of ${e.trial.progress.total} calls completed`},{default:u(()=>[v(h(e.trial.progress.completed)+" / "+h(e.trial.progress.total)+" completed",1)]),_:1},8,["aria-label"]),e.trial.progress.networkErrors>0?(a(),_(m,{key:0,color:"error","data-testid":"tag-network-errors","aria-label":`${e.trial.progress.networkErrors} network errors occurred`},{default:u(()=>[v(h(e.trial.progress.networkErrors)+" network errors ",1)]),_:1},8,["aria-label"])):n("",!0)])])])]),l("div",Ft,[l("h3",null,"Configurations ("+h(e.trial.configurationSnapshots.length)+")",1),d(w,{columns:s,"data-source":e.trial.configurationSnapshots,pagination:!1,size:"small",scroll:{y:300},"row-key":"id"},{bodyCell:u(({column:e,record:r})=>["model"===e.key?(a(),t("div",Rt,[l("strong",null,h(r.provider),1),l("small",null,h(r.modelId),1)])):n("",!0),"params"===e.key?(a(),_(k,{key:1,code:"",class:"params-preview"},{default:u(()=>[v(h(c(r.parameters)),1)]),_:2},1024)):n("",!0),"cost"===e.key?(a(),t(g,{key:2},[(a(),t("span",jt," $"+h(.001.toFixed(4)),1))],64)):n("",!0)]),_:1},8,["data-source"])]),l("div",Dt,[r[5]||(r[5]=l("h3",null,"Prompt Template",-1)),d(x,{code:"",class:"prompt-template"},{default:u(()=>[v(h(e.trial.designSnapshot.promptTemplate),1)]),_:1})]),e.trial.variableSnapshots?.length?(a(),t("div",qt,[r[6]||(r[6]=l("h3",null,"Variables",-1)),d(P,{"data-source":p(),size:"small",split:!1},{renderItem:u(({item:e})=>[d(I,null,{default:u(()=>[d(S,null,{title:u(()=>[d(m,{color:"blue"},{default:u(()=>[v(h(e.variable),1)]),_:2},1024)]),description:u(()=>[l("span",null,h(e.listName)+" ("+h(e.count)+" values)",1)]),_:2},1024)]),_:2},1024)]),_:1},8,["data-source"])])):n("",!0)]),_:1},8,["title"])}}});class Ut{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=new z({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),a=this.extractUniqueVariables(t),n=e.configurationSnapshots.map(e=>({provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:e.parameters})),l=new Set(n.map(e=>e.provider)),r={};for(const s of l){const e=L.getProvider(s);e&&(r[s]=this.buildProviderConfig(s,e))}return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:a},models:n,providerConfigs:r}}static extractUniqueVariables(e){const t={};for(const n of e)for(const[e,a]of Object.entries(n.variables))t[e]||(t[e]=new Set),t[e].add(a);const a={};for(const[n,l]of Object.entries(t))a[n]=Array.from(l).sort();return a}static buildProviderConfig(e,t){const a=t.requestTransform||{},n=t.auth||{type:"none"};let l="direct";"messages"===a.promptKey&&a.wrapPrompt?l="messages":"input"===a.promptKey&&(l="input");let r,s,o="root";"ollama-chat"===e?(o="options",r={max_tokens:"num_predict",max_completion_tokens:"num_predict"}):"ollama-generate"===e&&(o="mixed",s={root:["model","prompt","stream","format","raw"],options:["temperature","num_predict","top_k","top_p"]},r={max_tokens:"num_predict",max_completion_tokens:"num_predict"});const i=Object.values(t.responseModes||{})[0],c=this.parseResponsePath(i?.responseTransform?.contentPath),d=i?.responseTransform?.fallbackPaths?.map(e=>this.parseResponsePath(e)),u=t.api.baseUrl+(t.api.endpoints.chat||t.api.endpoints.generate||"");return{name:t.name,endpoint:u,auth:{type:n.type,header:n.header,prefix:"bearer"===n.type?"Bearer":void 0},headers:t.headers,request:{modelPrefixStrip:!0,promptFormat:l,messageRole:a.messageRole,paramLocation:o,paramRenames:r,mixedParams:s},response:{successPath:c,fallbackPaths:d,errorPath:["error","message"]}}}static parseResponsePath(e){return e?e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const t=parseInt(e);return isNaN(t)?e:t}):["content"]}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=JSON.stringify(e.providerConfigs,null,4);return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Simple Mode\n=====================================\nGenerated by Auditomatic Lite v${V.short} on ${a}\n\nThis script reproduces your experiment by generating API calls from variables.\nPerfect for understanding, modifying, and extending your experiments.\n\nOriginal trial: ${t}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${Object.keys(e.providerConfigs).map(e=>{const t=e.split("-")[0].toUpperCase();return`    "${e}": os.environ.get("${t}_API_KEY", ""),`}).join("\n")}\n}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Provider configurations (how to talk to each API)\nPROVIDER_CONFIGS = ${r}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef make_api_call(provider_id: str, model: str, prompt: str, params: dict) -> dict:\n    """\n    Universal API caller that handles all provider quirks.\n    \n    Returns dict with 'success', 'content', 'error', and timing info.\n    """\n    config = PROVIDER_CONFIGS[provider_id]\n    \n    # Build headers\n    headers = {"Content-Type": "application/json"}\n    \n    # Add authentication\n    auth = config["auth"]\n    if auth["type"] == "bearer":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = f"{auth['prefix']} {api_key}"\n    elif auth["type"] == "header":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = api_key\n    \n    # Add provider-specific headers\n    if config.get("headers"):\n        headers.update(config["headers"])\n    \n    # Build request body\n    request = config["request"]\n    \n    # Strip provider prefix from model\n    if request.get("modelPrefixStrip"):\n        model = model.split(":", 1)[-1]\n    \n    body = {"model": model}\n    \n    # Format prompt\n    if request["promptFormat"] == "messages":\n        body["messages"] = [{"role": request.get("messageRole", "user"), "content": prompt}]\n    elif request["promptFormat"] == "direct":\n        body["prompt"] = prompt\n    elif request["promptFormat"] == "input":\n        body["input"] = prompt\n    \n    # Handle parameters\n    processed_params = params.copy()\n    \n    # Apply renames\n    if request.get("paramRenames"):\n        for old_key, new_key in request["paramRenames"].items():\n            if old_key in processed_params:\n                processed_params[new_key] = processed_params.pop(old_key)\n    \n    # Place parameters\n    if request["paramLocation"] == "root":\n        body.update(processed_params)\n    elif request["paramLocation"] == "options":\n        body["options"] = processed_params\n    elif request.get("mixedParams"):\n        mixed = request["mixedParams"]\n        for key, value in processed_params.items():\n            if key in mixed.get("root", []):\n                body[key] = value\n            else:\n                if "options" not in body:\n                    body["options"] = {}\n                body["options"][key] = value\n    \n    # Make request\n    start_time = time.time()\n    try:\n        response = requests.post(\n            config["endpoint"],\n            headers=headers,\n            json=body,\n            timeout=30\n        )\n        latency_ms = (time.time() - start_time) * 1000\n        \n        if response.ok:\n            data = response.json()\n            content = extract_from_path(data, config["response"]["successPath"])\n            \n            # Try fallback paths\n            if content is None and config["response"].get("fallbackPaths"):\n                for path in config["response"]["fallbackPaths"]:\n                    content = extract_from_path(data, path)\n                    if content is not None:\n                        break\n            \n            return {\n                "success": True,\n                "content": content or "",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n        else:\n            return {\n                "success": False,\n                "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n            \n    except Exception as e:\n        return {\n            "success": False,\n            "error": str(e),\n            "latency_ms": (time.time() - start_time) * 1000\n        }\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(\n                model_config["provider"],\n                model_config["modelId"],\n                prompt,\n                model_config["parameters"]\n            )\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": result.get("content", ""),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                "status_code": result.get("status_code", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {result['content'][:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_results_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider not in API_KEYS or not API_KEYS[provider]:\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(set(missing_keys)))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns:\n            print(f"Avg latency: {df['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class Bt{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=[],a=new Y,n=new z({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),l=K(e);let r=0;for(const o of e.configurationSnapshots){const i=L.getProvider(o.provider);if(i)for(const c of n){const n=l>1?G():void 0;let d=e.designSnapshot.promptTemplate;for(const[e,t]of Object.entries(c.variables))d=d.replace(new RegExp(`{{${e}}}`,"g"),t);for(let e=0;e<l;e++){r++;try{const s={id:"export-config",name:o.name,provider:o.provider,model:o.modelId,params:o.parameters,created_at:new Date},u=a.buildAPIRequest(s,d),p={};for(const[e,t]of Object.entries(u.headers))"Authorization"===e&&t.startsWith("Bearer ")?p[e]=`Bearer $${o.provider.split("-")[0].toUpperCase()}_API_KEY`:e===i.auth.header&&"header"===i.auth.type?p[e]=`$${o.provider.split("-")[0].toUpperCase()}_API_KEY`:p[e]=t;const m=this.parseResponsePath(this.getDefaultResponsePath(o.provider));t.push({id:`call_${String(r).padStart(3,"0")}`,provider:o.provider,endpoint:u.url,headers:p,body:u.body,responsePath:m,metadata:{variables:c.variables,modelName:o.modelId,configName:o.name,...l>1&&{repeatIndex:e,repeatGroupId:n}}})}catch(s){F.warn("Failed to build API call for config",{configName:o.name,error:s})}}}}return{apiCalls:t,...e.repeatConfig&&{repeatConfig:{callsPerPrompt:e.repeatConfig.callsPerPrompt,delayBetweenRepeats:e.repeatConfig.delayBetweenRepeats}}}}static parseResponsePath(e){return e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const t=parseInt(e);return isNaN(t)?e:t})}static getDefaultResponsePath(e){switch(e){case"openai-chat":case"openrouter":return"choices[0].message.content";case"openai-responses":return"output[0].content[0].text";case"anthropic":return"content[0].text";case"ollama-chat":return"message.content";case"ollama-generate":return"response";default:return"content"}}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.apiCalls,null,4),l=[...new Set(e.apiCalls.map(e=>e.provider))],r=e.repeatConfig?`\nRepeat configuration: ${e.repeatConfig.callsPerPrompt} calls per prompt${e.repeatConfig.delayBetweenRepeats?`, ${e.repeatConfig.delayBetweenRepeats}ms delay`:""}`:"";return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Literal Mode\n======================================\nGenerated by Auditomatic Lite v${V.short} on ${a}\n\nThis script contains the EXACT API calls from your experiment.\nPerfect for bit-for-bit reproduction, debugging, and comparing results.\n\nOriginal trial: ${t}\nTotal API calls: ${e.apiCalls.length}${r}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${l.map(e=>{const t=e.split("-")[0].toUpperCase();return`    "${t}": os.environ.get("${t}_API_KEY", ""),`}).join("\n")}\n}\n\n# Pre-computed API calls from your experiment\nAPI_CALLS = ${n}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef execute_literal_calls():\n    """Execute pre-serialized API calls exactly as specified"""\n    results = []\n    total = len(API_CALLS)\n    \n    print(f"Executing {total} pre-computed API calls...")\n    print("=" * 60)\n    \n    for i, call in enumerate(API_CALLS):\n        print(f"[{i+1}/{total}] {call['metadata']['configName']} - ", end="")\n        \n        # Replace API key placeholders in headers\n        headers = {}\n        for key, value in call["headers"].items():\n            if "\\$" in str(value):\n                # Extract provider name from placeholder\n                for provider_key, api_key in API_KEYS.items():\n                    placeholder = f"\\\${provider_key}_API_KEY"\n                    if placeholder in value:\n                        headers[key] = value.replace(placeholder, api_key)\n                        break\n                else:\n                    headers[key] = value\n            else:\n                headers[key] = value\n        \n        # Check if we have required API key\n        provider_base = call["provider"].split("-")[0].upper()\n        if provider_base in ["OPENAI", "ANTHROPIC", "OPENROUTER"] and not API_KEYS.get(provider_base):\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": f"No API key for {provider_base}",\n                "latency_ms": 0,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ No API key")\n            continue\n        \n        # Make the exact API call\n        start_time = time.time()\n        try:\n            response = requests.post(\n                call["endpoint"],\n                headers=headers,\n                json=call["body"],\n                timeout=30\n            )\n            latency_ms = (time.time() - start_time) * 1000\n            \n            if response.ok:\n                data = response.json()\n                content = extract_from_path(data, call["responsePath"])\n                \n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": content or "",\n                    "success": True,\n                    "error": "",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    "full_response": json.dumps(data)[:500],  # First 500 chars\n                    **call["metadata"]["variables"]\n                })\n                print(f"✓ {(content or '')[:30]}")\n            else:\n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": "",\n                    "success": False,\n                    "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    **call["metadata"]["variables"]\n                })\n                print(f"✗ HTTP {response.status_code}")\n                \n        except Exception as e:\n            latency_ms = (time.time() - start_time) * 1000\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": str(e)[:200],\n                "latency_ms": latency_ms,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ {str(e)[:30]}")\n        \n        # Handle repeat delays if configured\n        if "repeatIndex" in call["metadata"] and call["metadata"]["repeatIndex"] > 0:\n            # Check if there's a repeat delay configured\n            delay_ms = ${e.repeatConfig?.delayBetweenRepeats||0}\n            if delay_ms > 0:\n                time.sleep(delay_ms / 1000.0)\n        \n        # Rate limiting\n        time.sleep(0.1)\n    \n    return results\n\ndef extract_prompt_from_body(body: dict) -> str:\n    """Extract the prompt from various request body formats"""\n    # Messages format (OpenAI, Anthropic, etc)\n    if "messages" in body and isinstance(body["messages"], list):\n        for msg in body["messages"]:\n            if msg.get("role") == "user":\n                return msg.get("content", "")\n    \n    # Direct prompt format (Ollama generate)\n    if "prompt" in body:\n        return body["prompt"]\n    \n    # Input format (OpenAI responses)\n    if "input" in body:\n        return body["input"]\n    \n    return ""\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    # Drop full_response column for cleaner output (except JSON)\n    if format != "json" and "full_response" in df.columns:\n        df = df.drop(columns=["full_response"])\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_literal_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    required_providers = set(call["provider"].split("-")[0].upper() for call in API_CALLS)\n    missing_keys = []\n    for provider in required_providers:\n        if provider not in ["OLLAMA"] and not API_KEYS.get(provider):\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(missing_keys))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Execute all calls\n    results = execute_literal_calls()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if df['success'].any():\n            print(f"Avg latency (successful): {df[df['success']]['latency_ms'].mean():.1f}ms")\n        \n        # Group by model\n        print(f"\\nBy Model:")\n        model_summary = df.groupby('config_name')['success'].agg(['count', 'sum', 'mean'])\n        model_summary.columns = ['total', 'successful', 'success_rate']\n        print(model_summary)\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class zt{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=new z({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),a=this.extractUniqueVariables(t),n=e.configurationSnapshots.map(e=>{let t,a="text";return e.parameters.response_format?(a="json_mode",t={response_format:e.parameters.response_format}):e.parameters.tools&&(a="function_calling",t={tools:e.parameters.tools,tool_choice:e.parameters.tool_choice}),{provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:this.filterCoreParams(e.parameters),responseMode:a,responseModeParams:t}}),l=new Set(n.map(e=>e.provider)),r={"openai-chat":"openai","openai-responses":"openai",anthropic:"anthropic",openrouter:"openai","ollama-chat":"ollama","ollama-generate":"ollama"},s=[...new Set(Array.from(l).map(e=>r[e]).filter(Boolean))],o={"openai-chat":"OPENAI","openai-responses":"OPENAI",anthropic:"ANTHROPIC",openrouter:"OPENROUTER","ollama-chat":"","ollama-generate":""},i=[...new Set(Array.from(l).map(e=>o[e]).filter(Boolean))];return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:a},models:n,providerLibraries:{required:s,apiKeys:i}}}static extractUniqueVariables(e){const t={};for(const n of e)for(const[e,a]of Object.entries(n.variables))t[e]||(t[e]=new Set),t[e].add(a);const a={};for(const[n,l]of Object.entries(t))a[n]=Array.from(l).sort();return a}static filterCoreParams(e){const t={...e};return delete t.response_format,delete t.tools,delete t.tool_choice,t}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=["import os","import json","import time","import pandas as pd","from datetime import datetime"];return e.providerLibraries.required.includes("openai")&&r.push("from openai import OpenAI"),e.providerLibraries.required.includes("anthropic")&&r.push("from anthropic import Anthropic"),e.providerLibraries.required.includes("ollama")&&r.push("import ollama"),`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Native Mode\n=====================================\nGenerated by Auditomatic Lite v${V.short} on ${a}\n\nThis script uses native Python libraries for each provider.\nCleanest code, best for production use.\n\nOriginal trial: ${t}\nRequired packages: ${e.providerLibraries.required.join(", ")}\n"""\n\n${r.join("\n")}\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\n${e.providerLibraries.apiKeys.map(e=>`os.environ.setdefault("${e}_API_KEY", "")  # Set your ${e} API key`).join("\n")}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\n# Initialize clients\nclients = {}\n\ndef get_client(provider):\n    """Get or create client for provider"""\n    if provider not in clients:\n        if provider in ["openai-chat", "openai-responses"]:\n            clients[provider] = OpenAI()\n        elif provider == "anthropic":\n            clients[provider] = Anthropic()\n        elif provider == "openrouter":\n            clients[provider] = OpenAI(\n                api_key=os.environ.get("OPENROUTER_API_KEY"),\n                base_url="https://openrouter.ai/api/v1"\n            )\n        # Ollama doesn't need a client\n    return clients.get(provider)\n\ndef make_api_call(model_config: dict, prompt: str) -> dict:\n    """Make API call using native provider library"""\n    provider = model_config["provider"]\n    model = model_config["modelId"]\n    params = model_config["parameters"].copy()\n    \n    try:\n        start_time = time.time()\n        \n        if provider == "openai-chat" or provider == "openrouter":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["response_format"] = {"type": "json_object"}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.chat.completions.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content based on response mode\n            if model_config["responseMode"] == "function_calling" and response.choices[0].message.tool_calls:\n                content = response.choices[0].message.tool_calls[0].function.arguments\n                if isinstance(content, str):\n                    content = json.loads(content)\n            else:\n                content = response.choices[0].message.content\n            \n        elif provider == "openai-responses":\n            client = get_client(provider)\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["text"] = {"format": {"type": "json_object"}}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.responses.create(\n                model=model,\n                input=prompt,\n                **params\n            )\n            \n            # Extract content\n            output = response.output\n            if isinstance(output, list) and len(output) > 0:\n                if hasattr(output[0], 'content') and isinstance(output[0].content, list):\n                    content = output[0].content[0].text if hasattr(output[0].content[0], 'text') else str(output[0].content[0])\n                else:\n                    content = str(output[0])\n            else:\n                content = str(output)\n            \n        elif provider == "anthropic":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.messages.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content\n            if model_config["responseMode"] == "function_calling" and hasattr(response.content[0], 'input'):\n                content = response.content[0].input\n            else:\n                content = response.content[0].text\n            \n        elif provider == "ollama-chat":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.chat(\n                model=model,\n                messages=[{"role": "user", "content": prompt}],\n                **params\n            )\n            \n            # Extract content\n            content = response["message"]["content"]\n            \n        elif provider == "ollama-generate":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.generate(\n                model=model,\n                prompt=prompt,\n                **params\n            )\n            \n            # Extract content\n            content = response["response"]\n        \n        else:\n            raise ValueError(f"Unknown provider: {provider}")\n        \n        latency_ms = (time.time() - start_time) * 1000\n        \n        return {\n            "success": True,\n            "content": content,\n            "latency_ms": latency_ms\n        }\n        \n    except Exception as e:\n        latency_ms = (time.time() - start_time) * 1000\n        return {\n            "success": False,\n            "content": "",\n            "error": str(e),\n            "latency_ms": latency_ms\n        }\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(model_config, prompt)\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": str(result.get("content", "")),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {str(result['content'])[:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: list, format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_native_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for required packages\n    required = ${JSON.stringify(e.providerLibraries.required)}\n    missing = []\n    for lib in required:\n        try:\n            __import__(lib)\n        except ImportError:\n            missing.append(lib)\n    \n    if missing:\n        print(f"ERROR: Missing required packages: {', '.join(missing)}")\n        print(f"Install with: pip install {' '.join(missing)}")\n        return\n    \n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider in ["openai-chat", "openai-responses"] and not os.environ.get("OPENAI_API_KEY"):\n            missing_keys.append("OPENAI_API_KEY")\n        elif provider == "anthropic" and not os.environ.get("ANTHROPIC_API_KEY"):\n            missing_keys.append("ANTHROPIC_API_KEY")\n        elif provider == "openrouter" and not os.environ.get("OPENROUTER_API_KEY"):\n            missing_keys.append("OPENROUTER_API_KEY")\n    \n    if missing_keys:\n        print(f"WARNING: Missing API keys: {', '.join(set(missing_keys))}")\n        print("Set them in the script or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns and df['success'].any():\n            print(f"Avg latency: {df[df['success']]['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class Vt{static async generatePythonScript(e,t){try{const a=t||this.getDefaultOptions(),n=this.validateTrialForExport(e);if(!n.valid)throw new Error(`Trial validation failed: ${n.errors.join(", ")}`);switch(a.mode){case"simple":return Ut.generate(e);case"literal":return Bt.generate(e);case"native":return zt.generate(e);default:throw new Error(`Unknown export mode: ${a.mode}`)}}catch(a){throw new Error(`Failed to generate Python export: ${a instanceof Error?a.message:String(a)}`)}}static async downloadPythonScript(e,t){const a=await this.generatePythonScript(e,t),n=t||this.getDefaultOptions(),l=new Blob([a],{type:"text/x-python"}),r=URL.createObjectURL(l),s=document.createElement("a");s.href=r,s.download=this.generateFilename(e,n.mode),document.body.appendChild(s),s.click(),document.body.removeChild(s),URL.revokeObjectURL(r)}static validateTrialForExport(e){const t=[];return e.designSnapshot?e.designSnapshot.promptTemplate||t.push("Design missing prompt template"):t.push("Trial missing design snapshot"),e.configurationSnapshots&&0!==e.configurationSnapshots.length?e.configurationSnapshots.forEach((e,a)=>{e.provider||t.push(`Configuration ${a+1} missing provider`),e.modelId||t.push(`Configuration ${a+1} missing model`),e.parameters||t.push(`Configuration ${a+1} missing parameters`)}):t.push("Trial missing model configurations"),e.variableSnapshots||t.push("Trial missing variable snapshots"),{valid:0===t.length,errors:t}}static getExportSummary(e){const t=new Set(e.configurationSnapshots.map(e=>e.provider)),a=e.totalCombinations||0;return{apiCallCount:e.configurationSnapshots.length*a,providersUsed:Array.from(t),variableCombinations:a,configurations:e.configurationSnapshots.length}}static getDefaultOptions(){return{mode:"simple"}}static generateFilename(e,t){const a=e.name||`trial_${e.id}`,n=(new Date).toISOString().split("T")[0];return`${a.toLowerCase().replace(/[^a-z0-9]/g,"_")}_${t}_${n}.py`}}const Kt=Object.freeze(Object.defineProperty({__proto__:null,PythonExportService:Vt},Symbol.toStringTag,{value:"Module"})),Gt={class:"trial-info"},Yt={class:"trial-stats"},Ht={class:"export-section"},Jt={class:"mode-content"},Wt={class:"mode-content"},Xt={class:"mode-content"},Qt={class:"export-section"},Zt={class:"preview-content"},ea={class:"preview-info"},ta=e({__name:"PythonExportModal",props:{trial:{}},emits:["close","exported"],setup(e,{emit:t}){const n=e,r=t,i=s("simple"),c=s(!1),p=o(()=>n.trial.progress.total),m=o(()=>n.trial.configurationSnapshots?.length||0),g=o(()=>n.trial.totalCombinations||0),b=o(()=>{const e=.05*g.value+.3*m.value;return Math.round(15+e)}),y=o(()=>{const e=.5*p.value;return Math.round(10+e)}),C=o(()=>{const e=.05*g.value+.2*m.value;return Math.round(12+e)}),k=o(()=>{const e=n.trial.name.toLowerCase().replace(/\s+/g,"_"),t=(new Date).toISOString().split("T")[0];return`${e}_${i.value}_${t}.py`}),w=o(()=>{if("simple"===i.value){return 300+(g.value+10*m.value)}if("native"===i.value){return 250+(g.value+8*m.value)}return 200+15*p.value});async function x(){c.value=!0;try{const e={mode:i.value};await Vt.downloadPythonScript(n.trial,e),r("exported",k.value),r("close")}catch(e){F.error("Export failed",e),alert("Export failed: "+(e instanceof Error?e.message:"Unknown error"))}finally{c.value=!1}}return(e,t)=>{const n=f("a-button"),r=f("a-tag"),s=f("a-radio"),o=f("a-radio-group"),S=f("a-typography-text");return a(),_($,{"model-value":!0,title:"Export Python Script",size:"full","onUpdate:modelValue":t[2]||(t[2]=t=>e.$emit("close"))},{footer:u(()=>[d(n,{onClick:t[0]||(t[0]=t=>e.$emit("close")),size:"large","data-testid":"btn-cancel-python-export","aria-label":"Cancel Python export"},{default:u(()=>t[3]||(t[3]=[v(" Cancel ")])),_:1,__:[3]}),d(n,{type:"primary",onClick:x,loading:c.value,size:"large","data-testid":"btn-confirm-python-export","data-mode":i.value,"aria-label":`Export Python script in ${i.value} mode`},{default:u(()=>t[4]||(t[4]=[v(" Export Script ")])),_:1,__:[4]},8,["loading","data-mode","aria-label"])]),default:u(()=>[l("div",Gt,[l("h3",null,h(e.trial.name),1),l("div",Yt,[d(r,null,{default:u(()=>[v(h(p.value)+" API calls",1)]),_:1}),d(r,null,{default:u(()=>[v(h(m.value)+" configurations",1)]),_:1}),d(r,null,{default:u(()=>[v(h(g.value)+" variable combinations",1)]),_:1})])]),l("div",Ht,[t[11]||(t[11]=l("h4",null,"Export Mode",-1)),d(o,{value:i.value,"onUpdate:value":t[1]||(t[1]=e=>i.value=e),class:"mode-options","data-testid":"radiogroup-export-mode","aria-label":"Select Python export mode"},{default:u(()=>[d(s,{value:"simple",class:"mode-radio","data-testid":"radio-mode-simple","aria-label":"Simple script mode"},{default:u(()=>[l("div",Jt,[t[5]||(t[5]=l("div",{class:"mode-title"},"Simple Script",-1)),t[6]||(t[6]=l("div",{class:"mode-description"}," Educational script with variables as lists. Easy to understand, modify, and extend. Perfect for learning how AI APIs work. ",-1)),d(r,{color:"blue",size:"small"},{default:u(()=>[v("~"+h(b.value)+"KB",1)]),_:1})])]),_:1}),d(s,{value:"literal",class:"mode-radio","data-testid":"radio-mode-literal","aria-label":"Literal reproduction mode"},{default:u(()=>[l("div",Wt,[t[7]||(t[7]=l("div",{class:"mode-title"},"Literal Reproduction",-1)),t[8]||(t[8]=l("div",{class:"mode-description"}," Exact API calls pre-computed. Bit-for-bit reproduction of your experiment. Best for debugging and comparing results. ",-1)),d(r,{color:"blue",size:"small"},{default:u(()=>[v("~"+h(y.value)+"KB",1)]),_:1})])]),_:1}),d(s,{value:"native",class:"mode-radio","data-testid":"radio-mode-native","aria-label":"Native libraries mode"},{default:u(()=>[l("div",Xt,[t[9]||(t[9]=l("div",{class:"mode-title"},"Native Libraries",-1)),t[10]||(t[10]=l("div",{class:"mode-description"}," Uses official Python SDKs (openai, anthropic, ollama). Cleanest code, best for production use. Requires: pip install openai anthropic ollama ",-1)),d(r,{color:"green",size:"small"},{default:u(()=>[v("~"+h(C.value)+"KB",1)]),_:1})])]),_:1})]),_:1},8,["value"])]),t[13]||(t[13]=l("div",{class:"export-section"},[l("h4",null,"Output Format"),l("div",{class:"format-info"},[l("p",null,"Both scripts save results using pandas in your choice of format:"),l("ul",null,[l("li",null,[l("strong",null,"CSV"),v(" - Universal format, opens in Excel/Google Sheets")]),l("li",null,[l("strong",null,"Excel"),v(" - Native Excel format")]),l("li",null,[l("strong",null,"JSON"),v(" - For programmatic access")]),l("li",null,[l("strong",null,"Parquet"),v(" - Efficient compressed format")]),l("li",null,[l("strong",null,"HTML"),v(" - For web viewing")]),l("li",null,[l("strong",null,"Markdown"),v(" - For documentation")]),l("li",null,[l("strong",null,"Stata"),v(" - For statistical analysis")]),l("li",null,[l("strong",null,"Pickle"),v(" - Python native format")])])])],-1)),l("div",Qt,[t[12]||(t[12]=l("h4",null,"Script Preview",-1)),l("div",Zt,[d(S,{code:"",class:"preview-filename"},{default:u(()=>[v(h(k.value),1)]),_:1}),l("div",ea,[d(r,{size:"small"},{default:u(()=>[v(h(w.value)+" lines",1)]),_:1}),d(r,{size:"small"},{default:u(()=>[v(h(i.value)+" mode",1)]),_:1})])])])]),_:1,__:[13]})}}}),aa={class:"api-call-modal"},na={class:"modal-header"},la={class:"modal-content"},ra={class:"section"},sa={class:"info-grid"},oa={class:"info-item"},ia={class:"call-id"},ca={class:"info-item"},da={class:"info-item"},ua={class:"info-item"},pa={key:0,class:"info-item"},ma={key:1,class:"info-item"},fa={key:2,class:"info-item"},va={class:"section"},ga={class:"variables-detail"},ba={class:"variable-value"},ha={key:0,class:"attributes-section"},_a={class:"attribute-items"},ya={class:"section"},Ca={class:"prompt-display"},ka={key:0,class:"section"},wa={key:0,class:"response-info"},xa={class:"info-grid"},Sa={class:"info-item"},Ia={class:"info-item"},Pa={key:1,class:"result-content"},Ta={key:0,class:"error-result"},Aa={class:"error-message"},Ma={key:0,class:"error-raw"},Ea={class:"error-response"},Na={key:1,class:"content-result"},$a={class:"content-display"},Oa={class:"section"},Fa={class:"raw-data"},Ra={key:1,class:"section"},ja={class:"raw-data"},Da={class:"modal-footer"},qa=O(e({__name:"APICallDetailModal",props:{apiCall:{},trial:{}},emits:["close"],setup(e){const r=e,s=o(()=>{if(!r.apiCall.request)return"No request data";const e=JSON.parse(JSON.stringify(r.apiCall.request));return e.headers&&Object.keys(e.headers).forEach(t=>{const a=t.toLowerCase();(a.includes("authorization")||a.includes("api-key")||a.includes("x-api-key")||a.includes("bearer"))&&(e.headers[t]="[REDACTED]")}),JSON.stringify(e,null,2)});function i(){return r.trial&&r.trial.configurationSnapshots[r.apiCall.configurationIndex]&&r.trial.configurationSnapshots[r.apiCall.configurationIndex].name||`Configuration ${r.apiCall.configurationIndex+1}`}function c(e){const t="string"==typeof e?new Date(e):e;return isNaN(t.getTime())?"Invalid date":t.toLocaleString()}async function p(){const e={id:r.apiCall.id,status:r.apiCall.status,configuration:i(),variables:r.apiCall.variables,variableAttributes:r.apiCall.variableAttributes,prompt:r.apiCall.prompt,request:JSON.parse(s.value),response:r.apiCall.response,result:r.apiCall.result,created:r.apiCall.created,completed:r.apiCall.completed},t=JSON.stringify(e,null,2);try{if(navigator.clipboard&&navigator.clipboard.writeText)return await navigator.clipboard.writeText(t),void U.success("Details copied to clipboard!");const e=document.createElement("textarea");e.value=t,e.style.position="fixed",e.style.left="-999999px",e.style.top="-999999px",document.body.appendChild(e),e.focus(),e.select();const a=document.execCommand("copy");if(document.body.removeChild(e),!a)throw new Error("execCommand failed");U.success("Details copied to clipboard!")}catch(a){F.error("Failed to copy to clipboard",a),prompt("Copy this text manually:",t)}}return(e,r)=>{const o=f("a-button");return a(),t("div",{class:"modal-overlay",onClick:r[2]||(r[2]=x(t=>e.$emit("close"),["self"]))},[l("div",aa,[l("div",na,[r[3]||(r[3]=l("h2",null,"API Call Details",-1)),l("button",{class:"close-btn",onClick:r[0]||(r[0]=t=>e.$emit("close")),"data-testid":"btn-close-api-call-modal","aria-label":"Close API call details"},"×")]),l("div",la,[l("div",ra,[r[11]||(r[11]=l("h3",null,"Overview",-1)),l("div",sa,[l("div",oa,[r[4]||(r[4]=l("label",null,"Call ID:",-1)),l("span",ia,h(e.apiCall.id),1)]),l("div",ca,[r[5]||(r[5]=l("label",null,"Status:",-1)),l("span",{class:S(["status-badge",e.apiCall.status])},h(e.apiCall.status),3)]),l("div",da,[r[6]||(r[6]=l("label",null,"Configuration:",-1)),l("span",null,h(i()),1)]),l("div",ua,[r[7]||(r[7]=l("label",null,"Created:",-1)),l("span",null,h(c(e.apiCall.created)),1)]),e.apiCall.completed?(a(),t("div",pa,[r[8]||(r[8]=l("label",null,"Completed:",-1)),l("span",null,h(c(e.apiCall.completed)),1)])):n("",!0),e.apiCall.completed?(a(),t("div",ma,[r[9]||(r[9]=l("label",null,"Duration:",-1)),l("span",null,h((m=e.apiCall.completed.getTime()-e.apiCall.created.getTime(),m<1e3?`${m}ms`:`${(m/1e3).toFixed(1)}s`)),1)])):n("",!0),e.apiCall.response?.latencyMs?(a(),t("div",fa,[r[10]||(r[10]=l("label",null,"API Latency:",-1)),l("span",null,h(e.apiCall.response.latencyMs)+"ms",1)])):n("",!0)])]),l("div",va,[r[13]||(r[13]=l("h3",null,"Variables",-1)),l("div",ga,[(a(!0),t(g,null,b(Object.entries(e.apiCall.variables),([e,n])=>(a(),t("div",{key:e,class:"variable-item"},[l("label",null,h(e)+":",1),l("span",ba,h(n),1)]))),128))]),e.apiCall.variableAttributes&&Object.keys(e.apiCall.variableAttributes).length>0?(a(),t("div",ha,[r[12]||(r[12]=l("h4",null,"Variable Attributes",-1)),(a(!0),t(g,null,b(Object.entries(e.apiCall.variableAttributes),([e,n])=>(a(),t("div",{key:e,class:"attribute-group"},[l("h5",null,h(e),1),l("div",_a,[(a(!0),t(g,null,b(Object.entries(n),([e,n])=>(a(),t("div",{key:e,class:"attribute-item"},[l("label",null,h(e)+":",1),l("span",null,h(n),1)]))),128))])]))),128))])):n("",!0)]),l("div",ya,[r[14]||(r[14]=l("h3",null,"Resolved Prompt",-1)),l("div",Ca,h(e.apiCall.prompt),1)]),e.apiCall.response||e.apiCall.result?(a(),t("div",ka,[r[20]||(r[20]=l("h3",null,"Response",-1)),e.apiCall.response?(a(),t("div",wa,[l("div",xa,[l("div",Sa,[r[15]||(r[15]=l("label",null,"HTTP Status:",-1)),l("span",null,h(e.apiCall.response.status),1)]),l("div",Ia,[r[16]||(r[16]=l("label",null,"Latency:",-1)),l("span",null,h(e.apiCall.response.latencyMs)+"ms",1)])])])):n("",!0),e.apiCall.result?(a(),t("div",Pa,[!1===e.apiCall.result.success?(a(),t("div",Ta,[r[18]||(r[18]=l("h4",null,"Error",-1)),l("div",Aa,h(e.apiCall.result.error),1),e.apiCall.response?(a(),t("div",Ma,[r[17]||(r[17]=l("h5",null,"Raw Response:",-1)),l("pre",Ea,h(JSON.stringify(e.apiCall.response,null,2)),1)])):n("",!0)])):n("",!0),e.apiCall.result.content?(a(),t("div",Na,[r[19]||(r[19]=l("h4",null,"Content",-1)),l("div",$a,h(e.apiCall.result.content),1)])):n("",!0)])):n("",!0)])):n("",!0),l("div",Oa,[r[21]||(r[21]=l("h3",null,"Raw Request",-1)),l("pre",Fa,h(s.value),1)]),e.apiCall.response?(a(),t("div",Ra,[r[22]||(r[22]=l("h3",null,"Raw Response",-1)),l("pre",ja,h(JSON.stringify(e.apiCall.response,null,2)),1)])):n("",!0)]),l("div",Da,[d(o,{onClick:r[1]||(r[1]=t=>e.$emit("close")),size:"large",class:"footer-button","data-testid":"btn-close-modal-footer","aria-label":"Close modal"},{default:u(()=>r[23]||(r[23]=[v(" Close ")])),_:1,__:[23]}),d(o,{type:"primary",onClick:p,size:"large",class:"footer-button footer-button-primary","data-testid":"btn-copy-api-call-details","aria-label":"Copy API call details to clipboard"},{default:u(()=>r[24]||(r[24]=[v(" Copy Details ")])),_:1,__:[24]})])])]);var m}}}),[["__scopeId","data-v-d79e18d5"]]);function La(e,t){const a=new Set,n=new Set,l=new Set;e.forEach(e=>{e.variables&&Object.keys(e.variables).forEach(e=>a.add(e)),e.variableAttributes&&Object.values(e.variableAttributes).forEach(e=>{e&&Object.keys(e).forEach(e=>n.add(e))})});const r=Array.from(a).sort(),s=Array.from(n).sort(),o=Array.from(l).sort(),i=[];t?.designSnapshot?.extractPattern&&i.push("extracted_value");const c=["success","refused",...i,...o];return{categorical:[...r,...s,"model","status","error_type"],numeric:["response_time","total_tokens","prompt_tokens","completion_tokens",...i].sort(),extracted:c}}function Ua(e,t,a){switch(t){case"model":if(a&&e.configurationIndex<a.configurationSnapshots.length){return a.configurationSnapshots[e.configurationIndex].modelId||"Unknown"}return"Unknown";case"status":return e.status;case"response_time":return e.response?.latencyMs||0;case"total_tokens":if(e.response?.body?.usage){const t=e.response.body.usage;return t.total_tokens||t.prompt_tokens+t.completion_tokens||0}return 0;case"prompt_tokens":return e.response?.body?.usage?.prompt_tokens||e.response?.body?.usage?.input_tokens||0;case"completion_tokens":return e.response?.body?.usage?.completion_tokens||e.response?.body?.usage?.output_tokens||0;case"error_type":return e.result?.errorType||(!1===e.result?.success?"api_error":"success");case"success":return e.result?.success?1:0;case"refused":return e.result?.refused?1:0;case"extracted_value":if(e.result?.success&&void 0!==e.result?.content){const t=String(e.result.content),a=parseFloat(t);return isNaN(a)?t:a}return null}if(void 0!==e.variables?.[t])return e.variables[t];if(e.variableAttributes)for(const n of Object.keys(e.variableAttributes)){const a=e.variableAttributes[n];if(a&&void 0!==a[t])return a[t]}return null}const Ba={count:{label:"Count",calculate:e=>e.length,format:e=>e.toString(),needsNumeric:!1},sum:{label:"Sum",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?t.reduce((e,t)=>e+t,0):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mean:{label:"Mean",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?t.reduce((e,t)=>e+t,0)/t.length:null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},median:{label:"Median",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(0===t.length)return null;const a=[...t].sort((e,t)=>e-t),n=Math.floor(a.length/2);return a.length%2==0?(a[n-1]+a[n])/2:a[n]},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mode:{label:"Mode",calculate:e=>{if(0===e.length)return null;const t=new Map;e.forEach(e=>t.set(e,(t.get(e)||0)+1));let a=0,n=null;return t.forEach((e,t)=>{e>a&&(a=e,n=t)}),{value:n,count:a,total:e.length}},format:e=>e?`${e.value} (${e.count}/${e.total})`:"-",needsNumeric:!1},variance:{label:"Variance",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(t.length<=1)return null;const a=t.reduce((e,t)=>e+t,0)/t.length;return t.reduce((e,t)=>e+Math.pow(t-a,2),0)/(t.length-1)},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},std_dev:{label:"Std Dev",calculate:e=>{const t=Ba.variance.calculate(e);return null!==t?Math.sqrt(t):null},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},min:{label:"Min",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?Math.min(...t):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},max:{label:"Max",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?Math.max(...t):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},success_rate:{label:"Success Rate",calculate:(e,t)=>{const a=t.filter(e=>e.result?.success).length;return t.length>0?a/t.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},refusal_rate:{label:"Refusal Rate",calculate:(e,t)=>{const a=t.filter(e=>e.result?.refused).length;return t.length>0?a/t.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},avg_time:{label:"Avg Time (ms)",calculate:(e,t)=>{const a=t.filter(e=>e.response?.latencyMs).map(e=>e.response.latencyMs);return a.length>0?a.reduce((e,t)=>e+t,0)/a.length:null},format:e=>e?`${Math.round(e)}ms`:"-",needsNumeric:!1,usesApiCalls:!0}};function za(e,t){if(!e||null===e.value)return"-";return Ba[t].format(e.value)}const Va={"blue-subtle":{name:"Blue (Subtle)",colors:["rgba(59, 130, 246, 0.1)","rgba(59, 130, 246, 0.3)","rgba(59, 130, 246, 0.7)"]},"green-red":{name:"Green-Red",colors:["#dc2626","#fbbf24","#10b981"]},"blue-yellow":{name:"Blue-Yellow",colors:["#1e40af","#3b82f6","#fbbf24"]},"purple-orange":{name:"Purple-Orange",colors:["#7c3aed","#a855f7","#ff9500"]},grayscale:{name:"Grayscale",colors:["#f3f4f6","#9ca3af","#374151"]},viridis:{name:"Viridis",colors:["#440154","#482878","#3e4989","#31688e","#26828e","#1f9e89","#35b779","#6ece58","#b5de2b","#fde725"]},inferno:{name:"Inferno",colors:["#000004","#1b0c41","#4a0c6b","#781c6d","#a52c60","#cf4446","#ed6925","#fb9b06","#f7d13d","#fcffa4"]},magma:{name:"Magma",colors:["#000004","#180f3d","#440f76","#721f81","#9e2f7f","#cd4071","#f1605d","#fd9668","#feca8d","#fcfdbf"]},plasma:{name:"Plasma",colors:["#0d0887","#46039f","#7201a8","#9c179e","#bd3786","#d8576b","#ed7953","#fb9f3a","#fdca26","#f0f921"]}};function Ka(e,t){if(0===t.length)return"transparent";if(1===t.length)return t[0];e=Math.max(0,Math.min(1,e));const a=1/(t.length-1),n=Math.floor(e/a),l=e%a/a;return Ga(t[Math.min(n,t.length-1)],t[Math.min(n+1,t.length-1)],l)}function Ga(e,t,a){if(e.startsWith("rgba")&&t.startsWith("rgba")){const n=e=>{const t=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);return t?{r:parseInt(t[1]),g:parseInt(t[2]),b:parseInt(t[3]),a:t[4]?parseFloat(t[4]):1}:null},l=n(e),r=n(t);if(l&&r){return`rgba(${Math.round(l.r+(r.r-l.r)*a)}, ${Math.round(l.g+(r.g-l.g)*a)}, ${Math.round(l.b+(r.b-l.b)*a)}, ${(l.a+(r.a-l.a)*a).toFixed(2)})`}}if(e.startsWith("rgba")||t.startsWith("rgba"))return a<.5?e:t;const n=e.replace("#",""),l=t.replace("#",""),r=parseInt(n.substr(0,2),16),s=parseInt(n.substr(2,2),16),o=parseInt(n.substr(4,2),16),i=parseInt(l.substr(0,2),16),c=parseInt(l.substr(2,2),16),d=parseInt(l.substr(4,2),16),u=Math.round(r+(i-r)*a),p=Math.round(s+(c-s)*a),m=Math.round(o+(d-o)*a);return`#${u.toString(16).padStart(2,"0")}${p.toString(16).padStart(2,"0")}${m.toString(16).padStart(2,"0")}`}function Ya(e){let t,a,n;if(e.startsWith("rgba")){const l=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);if(!l)return!1;t=parseInt(l[1]),a=parseInt(l[2]),n=parseInt(l[3])}else{const l="#"===e.charAt(0)?e.substring(1,7):e;t=parseInt(l.substring(0,2),16),a=parseInt(l.substring(2,4),16),n=parseInt(l.substring(4,6),16)}const l=[t/255,a/255,n/255].map(e=>e<=.03928?e/12.92:Math.pow((e+.055)/1.055,2.4));return.2126*l[0]+.7152*l[1]+.0722*l[2]<=.179}function Ha(e){return Ya(e)?"#FFFFFF":"#000000"}function Ja(e,t,a){const{colorScales:n,interpolateColor:l,getContrastColor:r}={colorScales:Va,interpolateColor:Ka,interpolateBetweenColors:Ga,colorIsDarkAdvanced:Ya,getContrastColor:Ha};function s(e){if("number"==typeof e)return e;if("string"==typeof e){const t=parseFloat(e);return isNaN(t)?null:t}return null}return{getCellStyle:function(o,i,c){if(!o||null===o.value||"number"!=typeof o.value)return{};const d=n[t.value];if(!d)return{};const u=function(t,n,l){const r=s(t.value);if(null===r)return.5;if("global"===a.value){const t=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(t.length>0){const e=Math.min(...t),a=Math.max(...t);if(a!==e)return(r-e)/(a-e)}}else if("column"===a.value){const t=e.value.rows.map(e=>e.cells[l]).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(t.length>0){const e=Math.min(...t),a=Math.max(...t);if(a!==e)return(r-e)/(a-e)}}else if("row"===a.value){const t=e.value.rows.find(e=>e.label===n);if(t){const e=t.cells.filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(e.length>0){const t=Math.min(...e),a=Math.max(...e);if(a!==t)return(r-t)/(a-t)}}}return.5}(o,i,c),p=l(u,d.colors);return{backgroundColor:`${p} !important`,color:`${r(p)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},getSummaryStyle:function(a){if(!a||null===a.value||"number"!=typeof a.value)return{};const o=n[t.value];if(!o)return{};let i=.5;const c=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(c.length>0){const e=Math.min(...c),t=Math.max(...c),n=s(a.value);null!==n&&(i=t!==e?(n-e)/(t-e):.5)}const d=l(i,o.colors);return{backgroundColor:`${d} !important`,color:`${r(d)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},styleKey:o(()=>`${t.value}-${a.value}`)}}const Wa={class:"pivot-config"},Xa={class:"config-row"},Qa={class:"config-group"},Za=["value","aria-label"],en={label:"Categorical"},tn=["value"],an={class:"config-group"},nn=["value","aria-label"],ln={label:"Categorical"},rn=["value"],sn={class:"config-group"},on=["value","aria-label"],cn={label:"Extracted Values"},dn=["value"],un={label:"Numeric Fields"},pn=["value"],mn={class:"config-group"},fn=["value","aria-label"],vn=O(e({__name:"PivotConfiguration",props:{config:{},availableFields:{}},emits:["update-config"],setup(e,{emit:n}){const r=n;function s(e,t){r("update-config",e,t)}function o(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}return(e,n)=>(a(),t("div",Wa,[l("div",Xa,[l("div",Qa,[n[4]||(n[4]=l("label",{for:"pivot-row-field"},"Rows (Group by):",-1)),l("select",{id:"pivot-row-field",value:e.config.rowField,"aria-label":"Group rows by "+o(e.config.rowField),onChange:n[0]||(n[0]=e=>s("rowField",e.target.value))},[l("optgroup",en,[(a(!0),t(g,null,b(e.availableFields.categorical,e=>(a(),t("option",{key:e,value:e},h(o(e)),9,tn))),128))])],40,Za)]),l("div",an,[n[5]||(n[5]=l("label",{for:"pivot-column-field"},"Columns (Group by):",-1)),l("select",{id:"pivot-column-field",value:e.config.columnField,"aria-label":"Group columns by "+o(e.config.columnField),onChange:n[1]||(n[1]=e=>s("columnField",e.target.value))},[l("optgroup",ln,[(a(!0),t(g,null,b(e.availableFields.categorical,e=>(a(),t("option",{key:e,value:e},h(o(e)),9,rn))),128))])],40,nn)]),l("div",sn,[n[6]||(n[6]=l("label",{for:"pivot-value-field"},"Values (Aggregate):",-1)),l("select",{id:"pivot-value-field",value:e.config.valueField,"aria-label":"Aggregate "+e.config.valueField+" values",onChange:n[2]||(n[2]=e=>s("valueField",e.target.value))},[l("optgroup",cn,[(a(!0),t(g,null,b(e.availableFields.extracted,e=>(a(),t("option",{key:e,value:e},h(e),9,dn))),128))]),l("optgroup",un,[(a(!0),t(g,null,b(e.availableFields.numeric,e=>(a(),t("option",{key:e,value:e},h(o(e)),9,pn))),128))])],40,on)]),l("div",mn,[n[8]||(n[8]=l("label",{for:"pivot-aggregation"},"Aggregation:",-1)),l("select",{id:"pivot-aggregation",value:e.config.aggregation,"aria-label":"Aggregation method: "+e.config.aggregation,onChange:n[3]||(n[3]=e=>s("aggregation",e.target.value))},n[7]||(n[7]=[y('<optgroup label="Statistical" data-v-efb8a7c2><option value="mean" data-v-efb8a7c2>Mean</option><option value="median" data-v-efb8a7c2>Median</option><option value="variance" data-v-efb8a7c2>Variance</option><option value="std_dev" data-v-efb8a7c2>Std Dev</option><option value="min" data-v-efb8a7c2>Min</option><option value="max" data-v-efb8a7c2>Max</option></optgroup><optgroup label="Frequency" data-v-efb8a7c2><option value="count" data-v-efb8a7c2>Count</option><option value="mode" data-v-efb8a7c2>Mode</option></optgroup><optgroup label="Performance" data-v-efb8a7c2><option value="success_rate" data-v-efb8a7c2>Success Rate</option><option value="refusal_rate" data-v-efb8a7c2>Refusal Rate</option><option value="avg_time" data-v-efb8a7c2>Avg Time</option></optgroup>',3)]),40,fn)])])]))}}),[["__scopeId","data-v-efb8a7c2"]]),gn={class:"heatmap-controls"},bn={class:"color-scale-selector"},hn=["value","aria-label"],_n={class:"gradient-mode-selector"},yn={class:"gradient-toggle",role:"group","aria-label":"Gradient mode selector"},Cn=["aria-pressed"],kn=["aria-pressed"],wn=["aria-pressed"],xn=["title","aria-label"],Sn=O(e({__name:"PivotHeatmapControls",props:{selectedColorScale:{},gradientMode:{},isFullscreen:{type:Boolean}},emits:["update-color-scale","update-gradient-mode","toggle-fullscreen"],setup(e,{emit:n}){const r=n;function s(e){const t=e.target.value;r("update-color-scale",t)}function o(e){r("update-gradient-mode",e)}return(e,n)=>(a(),t("div",gn,[l("div",bn,[n[5]||(n[5]=l("label",{for:"heatmap-color-scale"},"Color Scale:",-1)),l("select",{id:"heatmap-color-scale",value:e.selectedColorScale,"aria-label":"Color scale: "+e.selectedColorScale,onChange:s},n[4]||(n[4]=[y('<option value="blue-subtle" data-v-4b4f9d62>Blue (Subtle)</option><option value="green-red" data-v-4b4f9d62>Green-Red (Success)</option><option value="blue-yellow" data-v-4b4f9d62>Blue-Yellow (Performance)</option><option value="purple-orange" data-v-4b4f9d62>Purple-Orange (General)</option><option value="viridis" data-v-4b4f9d62>Viridis</option><option value="inferno" data-v-4b4f9d62>Inferno</option><option value="magma" data-v-4b4f9d62>Magma</option><option value="plasma" data-v-4b4f9d62>Plasma</option><option value="grayscale" data-v-4b4f9d62>Grayscale</option>',9)]),40,hn)]),l("div",_n,[n[6]||(n[6]=l("label",null,"Gradient Mode:",-1)),l("div",yn,[l("button",{type:"button",class:S(["toggle-btn",{active:"global"===e.gradientMode}]),"aria-pressed":"global"===e.gradientMode,onClick:n[0]||(n[0]=e=>o("global"))}," Global ",10,Cn),l("button",{type:"button",class:S(["toggle-btn",{active:"column"===e.gradientMode}]),"aria-pressed":"column"===e.gradientMode,onClick:n[1]||(n[1]=e=>o("column"))}," Per Column ",10,kn),l("button",{type:"button",class:S(["toggle-btn",{active:"row"===e.gradientMode}]),"aria-pressed":"row"===e.gradientMode,onClick:n[2]||(n[2]=e=>o("row"))}," Per Row ",10,wn)])]),l("button",{type:"button",class:"fullscreen-btn",title:e.isFullscreen?"Exit Fullscreen":"Enter Fullscreen","aria-label":e.isFullscreen?"Exit fullscreen mode":"Enter fullscreen mode",onClick:n[3]||(n[3]=t=>e.$emit("toggle-fullscreen"))},h(e.isFullscreen?"⊟":"⊞"),9,xn)]))}}),[["__scopeId","data-v-4b4f9d62"]]),In={class:"filters-row"},Pn={key:0,class:"filter-group"},Tn=["value"],An=["for"],Mn=["id","onUpdate:modelValue","aria-label"],En={value:""},Nn=["value"],$n={key:1,class:"filter-group"},On=["value"],Fn={class:"table-view"},Rn={key:0,class:"empty-state","data-testid":"empty-data-message"},jn={key:1,class:"error-state","data-testid":"invalid-aggregation-error"},Dn={key:2,class:"pivot-table-container"},qn={class:"pivot-table-grid responsive-table",role:"table"},Ln={role:"row"},Un={class:"corner-cell",role:"columnheader"},Bn={key:0,class:"total-header",role:"columnheader"},zn={class:"row-header",role:"rowheader"},Vn=["data-testid","title","aria-label","role","onClick","onKeydown"],Kn={key:0,class:"cell-content"},Gn=["title"],Yn={class:"cell-value"},Hn={class:"error-message"},Jn={key:1},Wn=O(e({__name:"PivotTableCore",props:{apiCalls:{},trial:{default:null},config:{},maxTableRows:{default:1e4},showTotals:{type:Boolean,default:!0}},emits:["config-change","cell-click"],setup(e,{emit:r}){const i=e,u=r,m=s(!1),f=s("viridis"),v=s("global"),_=s({rowField:i.config?.rowField||"",columnField:i.config?.columnField||"",valueField:i.config?.valueField||"",aggregation:i.config?.aggregation||"mean"});I(()=>i.config,e=>{e&&Object.assign(_.value,e)},{deep:!0});const y=s({}),C=s([]),k=o(()=>Object.values(y.value).some(e=>""!==e)),w=P(La(i.apiCalls,i.trial));let $=0;I(()=>i.apiCalls,e=>{if(0===e.length||0===$||e.length-$>=10){const t=C.value.length>0||k.value?C.value:e;w.value=La(t,i.trial),$=e.length}},{immediate:!0});const O=P({});let R=0;I(()=>i.apiCalls.length,e=>{(0===e||0===R||e-R>=5)&&((()=>{if(0===i.apiCalls.length)return void(O.value={});const e={};i.apiCalls.forEach(t=>{if(i.trial&&t.configurationIndex<i.trial.configurationSnapshots.length){const a=i.trial.configurationSnapshots[t.configurationIndex].modelId||"Unknown";e.model||(e.model=new Set),e.model.add(a)}t.status&&(e.status||(e.status=new Set),e.status.add(t.status)),t.variables&&Object.entries(t.variables).forEach(([t,a])=>{a&&String(a).trim()&&(e[t]||(e[t]=new Set),e[t].add(String(a)))})});const t={};Object.entries(e).forEach(([e,a])=>{t[e]=Array.from(a).sort()}),O.value=t})(),R=e)},{immediate:!0});const j=o(()=>{const{model:e,status:t,...a}=O.value;return a});function D(){C.value=i.apiCalls.filter(e=>{if(y.value.model&&""!==y.value.model){if(!i.trial||e.configurationIndex>=i.trial.configurationSnapshots.length)return!1;if((i.trial.configurationSnapshots[e.configurationIndex].modelId||"Unknown")!==y.value.model)return!1}if(y.value.status&&""!==y.value.status&&e.status!==y.value.status)return!1;for(const[t,a]of Object.entries(y.value))if(a&&""!==a&&"model"!==t&&"status"!==t){const n=e.variables?.[t];if(n!==a)return!1}return!0})}function q(){y.value={},D()}I(()=>i.apiCalls,()=>{k.value?D():C.value=i.apiCalls},{immediate:!0});const L=o(()=>{const e=C.value.length>0||k.value?C.value:i.apiCalls;return 0===e.length?{rows:[],columns:[],totals:[],grandTotal:{value:0,count:0,apiCalls:[],rawValues:[]}}:function(e,t,a){const n=new Map,l=new Set,r=new Set;e.forEach(e=>{const s=String(Ua(e,t.rowField,a)||"Unknown"),o=String(Ua(e,t.columnField,a)||"Unknown");l.add(s),r.add(o),n.has(s)||n.set(s,new Map),n.get(s).has(o)||n.get(s).set(o,[]),n.get(s).get(o).push(e)});const s=e=>e.every(e=>!isNaN(Number(e))&&""!==e.trim())?e.sort((e,t)=>Number(e)-Number(t)):e.sort(),o=s(Array.from(l)),i=s(Array.from(r)),c=Ba[t.aggregation];function d(e){const n=e.map(e=>Ua(e,t.valueField,a));if(!c||"function"!=typeof c.calculate)return F.error("Invalid aggregation function:",t.aggregation,c),{value:null,count:e.length,apiCalls:e,rawValues:n,error:"Invalid aggregation function"};const l={nonNumeric:0,nullUndefined:0};return c.needsNumeric&&(l.nonNumeric=n.filter(e=>"number"!=typeof e).length),l.nullUndefined=n.filter(e=>null==e).length,{value:c.usesApiCalls?c.calculate(n,e):c.calculate(n),count:e.length,apiCalls:e,rawValues:n,excludedCounts:l}}const u=o.map(e=>{const t=[],a=[];return i.forEach(l=>{const r=n.get(e)?.get(l)||[];t.push(r.length>0?d(r):null),a.push(...r)}),{label:e,cells:t,total:d(a)}}),p=i.map(e=>{const t=[];return o.forEach(a=>{const l=n.get(a)?.get(e)||[];t.push(...l)}),d(t)});return{rows:u,columns:i,totals:p,grandTotal:d(e)}}(e,_.value,i.trial)}),U=o(()=>L.value.rows),{getCellStyle:B,getSummaryStyle:z,styleKey:V}=Ja(L,f,v);function K(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}function G(e,t,a){if(!a)return`${e} × ${t}: No data`;let n=`${e} × ${t}: ${za(a,_.value.aggregation)} (${a.count} calls)`;if(a.excludedCounts){const e=[];a.excludedCounts.nonNumeric>0&&e.push(`${a.excludedCounts.nonNumeric} non-numeric responses excluded`),a.excludedCounts.nullUndefined>0&&e.push(`${a.excludedCounts.nullUndefined} null/empty responses`),e.length>0&&(n+=` | ${e.join(", ")}`)}return a.error&&(n+=` - ERROR: ${a.error}`),n}function Y(e,t,a){if(!a)return`${e} by ${t}: No data`;const n=za(a,_.value.aggregation);return a.error?`${e} by ${t}: ${n} with data integrity error: ${a.error}`:`${e} by ${t}: ${n} from ${a.count} API calls`}function H(e,t){"rowField"!==e&&"columnField"!==e&&"valueField"!==e&&"aggregation"!==e||(_.value[e]=t),u("config-change",{..._.value})}function J(e,t,a){a&&u("cell-click",{row:e,column:t,cell:a})}function W(){m.value=!m.value,m.value?document.body.style.overflow="hidden":document.body.style.overflow=""}return c(()=>{m.value&&(document.body.style.overflow="")}),I([w,()=>i.apiCalls.length],([e])=>{i.apiCalls.length>0&&(!_.value.rowField||""===_.value.rowField)&&e.categorical.length>0&&(_.value.rowField=e.categorical.find(e=>"model"!==e&&"status"!==e&&"error_type"!==e)||e.categorical[0]||"model",_.value.columnField=_.value.columnField||"model",_.value.valueField=_.value.valueField||"success",_.value.aggregation=_.value.aggregation||"mean",u("config-change",{..._.value}))},{immediate:!0}),(e,r)=>(a(),t("div",{class:S(["pivot-table-core",{fullscreen:m.value}])},[T([w.value,_.value],()=>(a(),t("div",null,[d(vn,{config:_.value,"available-fields":w.value,onUpdateConfig:H},null,8,["config","available-fields"])])),r,0),d(Sn,{"selected-color-scale":f.value,"gradient-mode":v.value,"is-fullscreen":m.value,onUpdateColorScale:r[1]||(r[1]=e=>f.value=e),onUpdateGradientMode:r[2]||(r[2]=e=>v.value=e),onToggleFullscreen:W},null,8,["selected-color-scale","gradient-mode","is-fullscreen"]),Object.keys(O.value).length>0?T([O.value,y.value],()=>(a(),t("div",{key:0,class:"data-filters"},[l("div",In,[O.value.model&&O.value.model.length>1?(a(),t("div",Pn,[r[7]||(r[7]=l("label",{for:"filter-model",class:"filter-label"},"Model:",-1)),E(l("select",{id:"filter-model","onUpdate:modelValue":r[3]||(r[3]=e=>y.value.model=e),class:"filter-select","aria-label":"Filter by model",onChange:D},[r[6]||(r[6]=l("option",{value:""},"All Models",-1)),(a(!0),t(g,null,b(O.value.model,e=>(a(),t("option",{key:e,value:e},h(e),9,Tn))),128))],544),[[N,y.value.model]])])):n("",!0),(a(!0),t(g,null,b(j.value,(e,n)=>(a(),t("div",{key:n,class:"filter-group"},[l("label",{for:`filter-${n}`,class:"filter-label"},h(K(String(n)))+": ",9,An),E(l("select",{id:`filter-${n}`,"onUpdate:modelValue":e=>y.value[n]=e,class:"filter-select","aria-label":`Filter by ${K(String(n))}`,onChange:D},[l("option",En,"All "+h(K(String(n))),1),(a(!0),t(g,null,b(e,e=>(a(),t("option",{key:e,value:e},h(e),9,Nn))),128))],40,Mn),[[N,y.value[n]]])]))),128)),O.value.status&&O.value.status.length>1?(a(),t("div",$n,[r[9]||(r[9]=l("label",{for:"filter-status",class:"filter-label"},"Status:",-1)),E(l("select",{id:"filter-status","onUpdate:modelValue":r[4]||(r[4]=e=>y.value.status=e),class:"filter-select","aria-label":"Filter by status",onChange:D},[r[8]||(r[8]=l("option",{value:""},"All Statuses",-1)),(a(!0),t(g,null,b(O.value.status,e=>(a(),t("option",{key:e,value:e},h(e),9,On))),128))],544),[[N,y.value.status]])])):n("",!0),k.value?(a(),t("button",{key:2,type:"button",class:"clear-filters-btn",title:"Clear all filters","aria-label":"Clear all filters",onClick:q}," Clear Filters ")):n("",!0)])])),r,5):n("",!0),l("div",Fn,[0===i.apiCalls.length?(a(),t("div",Rn,r[10]||(r[10]=[l("p",null,"No data available for pivot table analysis.",-1)]))):_.value.aggregation in p(Ba)?(a(),t("div",Dn,[l("table",qn,[l("thead",null,[l("tr",Ln,[l("th",Un,h(K(_.value.rowField)||"Items")+" / "+h(K(_.value.columnField)||"Aggregated"),1),(a(!0),t(g,null,b(L.value.columns,e=>(a(),t("th",{key:e,class:"column-header",role:"columnheader"},h(e),1))),128)),_.value.columnField&&e.showTotals?(a(),t("th",Bn," Total ")):n("",!0)])]),l("tbody",null,[(a(!0),t(g,null,b(U.value,r=>(a(),t("tr",{key:`${r.label}-${p(V)}`,class:"data-row",role:"row"},[l("td",zn,h(r.label),1),(a(!0),t(g,null,b(r.cells,(e,n)=>(a(),t("td",{key:`${n}-${p(V)}`,class:S(["data-cell",{"error-cell":e?.error}]),"data-testid":e?.error?"pivot-cell-error":"pivot-cell",style:M(p(B)(e,r.label,n)),title:G(r.label,L.value.columns[n],e),"aria-label":Y(r.label,L.value.columns[n],e),role:e?.error?"alert":"cell",tabindex:"0",onClick:t=>J(r.label,L.value.columns[n],e),onKeydown:[A(t=>J(r.label,L.value.columns[n],e),["enter"]),A(x(t=>J(r.label,L.value.columns[n],e),["prevent"]),["space"])]},[e?.error?(a(),t("div",Kn,[l("span",{class:"error-indicator",title:e.error},"⚠️",8,Gn),l("span",Yn,h(e?p(za)(e,_.value.aggregation):"-"),1),l("div",Hn,h(e.error),1)])):(a(),t("span",Jn,h(e?p(za)(e,_.value.aggregation):"-"),1))],46,Vn))),128)),_.value.columnField&&e.showTotals?(a(),t("td",{key:0,class:"total-cell",style:M(p(z)(r.total)),role:"cell"},h(p(za)(r.total,_.value.aggregation)),5)):n("",!0)]))),128)),_.value.rowField&&e.showTotals?(a(),t("tr",{key:`totals-${p(V)}`,class:"total-row",role:"row"},[r[12]||(r[12]=l("td",{class:"row-header",role:"rowheader"},"Total",-1)),(a(!0),t(g,null,b(L.value.totals,(e,n)=>(a(),t("td",{key:`total-${n}-${p(V)}`,class:"total-cell",style:M(p(z)(e)),role:"cell"},h(p(za)(e,_.value.aggregation)),5))),128)),_.value.columnField?(a(),t("td",{key:0,class:"grand-total-cell",style:M(p(z)(L.value.grandTotal)),role:"cell"},h(p(za)(L.value.grandTotal,_.value.aggregation)),5)):n("",!0)])):n("",!0)])])])):(a(),t("div",jn,[l("p",null,"Invalid aggregation function: "+h(_.value.aggregation),1),r[11]||(r[11]=l("p",null,"Please select a valid aggregation method.",-1))]))])],2))}}),[["__scopeId","data-v-ffa2e33b"]]);export{qa as A,Wn as P,Pt as T,Lt as _,ta as a,Kt as p};
