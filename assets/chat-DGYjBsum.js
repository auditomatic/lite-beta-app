const e="openai-chat",t="OpenAI Chat Completions",o="/v1/chat/completions",n=[{type:"field_transform",config:{field:"response_format",transform:"string_to_object",transformConfig:{objectWrapper:"type"},description:"Wrap response_format string values in {type: value} object"}}],s={promptTokensPath:"usage.prompt_tokens",completionTokensPath:"usage.completion_tokens",totalTokensPath:"usage.total_tokens"},r=[{pattern:"^gpt-5",name:"GPT-5 Series (Reasoning Models)",params:{max_completion_tokens:{type:"integer",description:"Maximum tokens for completion including reasoning",min:1,default:128,is_output_length:!0,basic:!0},reasoning_effort:{type:"string",description:"Reasoning effort level",enum:["low","medium","high"],basic:!0}},forbidden:["temperature","top_p","frequency_penalty","presence_penalty","stop","logprobs","top_logprobs"]},{pattern:"^o[0-9]",name:"O-Series (Reasoning Models)",params:{max_completion_tokens:{type:"integer",description:"Maximum tokens for completion including reasoning",min:1,default:128,is_output_length:!0,basic:!0},reasoning_effort:{type:"string",description:"Reasoning effort level",enum:["low","medium","high"],basic:!0}},forbidden:["temperature","top_p","frequency_penalty","presence_penalty","stop","logprobs","top_logprobs"]},{pattern:"^gpt-[234]",name:"GPT 2/3/4 Models",params:{temperature:{type:"number",description:"Sampling temperature",min:0,max:2,default:0,basic:!0},max_completion_tokens:{type:"integer",description:"Maximum tokens for completion",min:1,default:128,is_output_length:!0,basic:!0},logprobs:{type:"boolean",description:"Include log probabilities",basic:!1,enables_features:{logprobs:{boolean_value:!0}}},top_logprobs:{type:"integer",description:"Number of top log probabilities to return for each token",min:0,max:20,basic:!1}}},{pattern:".*",name:"Other Models",params:{temperature:{type:"number",description:"Sampling temperature",min:0,max:2,default:1,basic:!0},max_completion_tokens:{type:"integer",description:"Maximum tokens for completion",min:1,default:1e3,is_output_length:!0,basic:!0},top_p:{type:"number",description:"Top-p (nucleus) sampling",min:0,max:1,default:1,basic:!1},frequency_penalty:{type:"number",description:"Frequency penalty",min:-2,max:2,default:0,basic:!1},presence_penalty:{type:"number",description:"Presence penalty",min:-2,max:2,default:0,basic:!1}}}],a={text:{id:"text",label:"Text",description:"Standard text response",parameters:{},responseTransform:{contentPath:"choices[0].message.content",fallbackPaths:["choices[0].text","message.content"],errorPath:"error.message"}}},i={promptKey:"messages",wrapPrompt:!0,messageRole:"user"},p={id:e,name:t,endpoint:o,requestTransforms:n,usageExtraction:s,modelRules:r,responseModes:a,requestTransform:i};export{p as default,o as endpoint,e as id,r as modelRules,t as name,i as requestTransform,n as requestTransforms,a as responseModes,s as usageExtraction};
