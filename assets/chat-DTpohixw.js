const e="openai-chat",t="OpenAI Chat Completions",n="/v1/chat/completions",o="POST",s={promptKey:"messages",wrapPrompt:!0,messageRole:"user"},i={text:{id:"text",label:"Text",description:"Standard text response",parameters:{},responseTransform:{contentPath:"choices[0].message.content",fallbackPaths:["choices[0].text","message.content"],errorPath:"error.message",emptyContentHandler:{checkPath:"choices[0].finish_reason",handlers:{length:"Response Incomplete - Token limit reached",stop:"Empty response generated"},default:"No content generated"},responseMetadata:{fields:[{name:"finish_reason",path:"choices[0].finish_reason",label:"Finish reason"},{name:"prompt_tokens",path:"usage.prompt_tokens",label:"Prompt tokens"},{name:"completion_tokens",path:"usage.completion_tokens",label:"Completion tokens"},{name:"reasoning_tokens",path:"usage.completion_tokens_details.reasoning_tokens",label:"Reasoning tokens"},{name:"total_tokens",path:"usage.total_tokens",label:"Total tokens"}]},validationRules:{requireNonEmptyContent:!1}}},json_mode:{id:"json_mode",label:"JSON Mode",description:"Structured JSON output",parameters:{response_format:{type:"json_object"}},promptTransform:{append:"\nPlease respond with a JSON object in the form {'answer': answer}"},responseTransform:{contentPath:"choices[0].message.content",fallbackPaths:["choices[0].text","message.content"],errorPath:"error.message",isJSON:!0,validationRules:{requireNonEmptyContent:!0,conditions:[{type:"emptyWithReason",path:"choices[0].finish_reason",value:"length",errorMessage:"Response incomplete: max tokens reached (consider increasing max_completion_tokens)"}]}}},function_calling:{id:"function_calling",label:"Function Calling",description:"Call functions with structured parameters",parameters:{tools:[{type:"function",function:{name:"provide_answer",description:"Provides the answer to the question",parameters:{type:"object",properties:{answer:{type:"string",description:"The answer value"}},required:["answer"]}}}],tool_choice:{type:"function",function:{name:"provide_answer"}}},responseTransform:{contentPath:"choices[0].message.tool_calls[0].function.arguments",fallbackPaths:["choices[0].message.content"],errorPath:"error.message",isJSON:!0,validationRules:{requireNonEmptyContent:!0,conditions:[{type:"emptyWithReason",path:"choices[0].finish_reason",value:"length",errorMessage:"Response incomplete: max tokens reached (consider increasing max_completion_tokens)"}]}}}},r={logprobsPath:"choices[0].logprobs.content"},a=[{pattern:"^o[0-9]",name:"O-Series (Reasoning Models)",params:{max_completion_tokens:{type:"integer",description:"Maximum tokens for completion including reasoning",min:1,default:128,is_output_length:!0,basic:!0},reasoning_effort:{type:"string",description:"Reasoning effort level",enum:["low","medium","high"],basic:!1},seed:{type:"integer",description:"Seed for deterministic outputs",basic:!1},response_format:{type:"object",description:"Response format (text, json_object, or json_schema)",basic:!1},n:{type:"integer",description:"Number of completions to generate",basic:!1},user:{type:"string",description:"User identifier for tracking",basic:!1}},forbidden:["temperature","top_p","frequency_penalty","presence_penalty","stop","logprobs","top_logprobs"]},{pattern:"^gpt",name:"GPT Models",params:{temperature:{type:"number",description:"Sampling temperature",min:0,max:2,default:0,basic:!0},max_completion_tokens:{type:"integer",description:"Maximum tokens for completion",min:1,default:128,is_output_length:!0,basic:!0},top_p:{type:"number",description:"Nucleus sampling threshold",min:0,max:1,basic:!1},frequency_penalty:{type:"number",description:"Penalize frequent tokens",min:-2,max:2,basic:!1},presence_penalty:{type:"number",description:"Penalize tokens based on presence",min:-2,max:2,basic:!1},stop:{type:"array",description:"Stop sequences",basic:!1},seed:{type:"integer",description:"Seed for deterministic outputs",basic:!1},response_format:{type:"object",description:"Response format (text, json_object, or json_schema)",basic:!1},logprobs:{type:"boolean",description:"Include log probabilities",basic:!1,enables_features:{logprobs:{boolean_value:!0}}},top_logprobs:{type:"integer",description:"Number of top log probabilities",min:0,max:20,basic:!1},n:{type:"integer",description:"Number of completions to generate",basic:!1},user:{type:"string",description:"User identifier for tracking",basic:!1}}}],p={id:e,name:t,endpoint:n,method:o,requestTransform:s,responseModes:i,responseExtraction:r,modelRules:a};export{p as default,n as endpoint,e as id,o as method,a as modelRules,t as name,s as requestTransform,r as responseExtraction,i as responseModes};
