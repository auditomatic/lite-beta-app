import{_ as e,u as t,a,l as n,p as l,w as r,P as s,E as o,e as i,m as c,x as d,A as u,y as p,z as m,G as f}from"./index-CiDH-VjL.js";import{d as v,a6 as g,Y as b,a1 as h,_ as y,ae as _,f as k,c as C,o as x,b as w,V as S,Z as I,k as P,W as T,G as E,u as A,F as M,a8 as N,a0 as $,ak as O,a9 as F,n as R,B as j,aa as D,a7 as q,w as L,s as U,al as B,ab as z,ad as K,q as G,ai as V}from"./vendor-BARfHmiz.js";import{u as Y}from"./designs-db-DzGNAug3.js";import{u as H}from"./variables-db-BZ-Wb_AM.js";import{u as J}from"./models-db-4pNwwfI8.js";import{u as W}from"./EnvironmentalCostSummary-tKL0Opfv.js";import{a as X}from"./cost-formatting-Bv_drrqY.js";import{G as Q}from"./GenericModelSelectorModal-Cjao-z3K.js";import{_ as Z}from"./BaseModal.vue_vue_type_style_index_0_lang-DgBaQZ0f.js";const ee={class:"modal-footer"},te={key:0,class:"footer-left"},ae={class:"footer-actions"},ne=e(v({__name:"ModalFooter",setup:e=>(e,t)=>(b(),g("div",ee,[e.$slots.left?(b(),g("div",te,[_(e.$slots,"left",{},void 0,!0)])):h("",!0),y("div",ae,[_(e.$slots,"default",{},void 0,!0)])]))}),[["__scopeId","data-v-3a3879d0"]]),le={class:"streamlined-content"},re={class:"content-section"},se={class:"section-header"},oe={class:"section-body"},ie={key:0,class:"design-selector","data-testid":"design-selector"},ce={key:0,class:"no-designs-state"},de={class:"no-designs-content"},ue={key:1,class:"design-list","data-testid":"design-list"},pe=["data-design-id","data-design-name","onClick"],me={class:"design-header"},fe={class:"design-title-section"},ve={class:"design-name"},ge={key:0,class:"design-inline-description"},be={class:"design-date"},he=["innerHTML"],ye={class:"design-stats"},_e={class:"stat-item"},ke={class:"stat-value"},Ce={class:"stat-item"},xe={class:"stat-value"},we={class:"stat-item"},Se={class:"stat-value"},Ie={key:1,class:"selected-design-with-template"},Pe={class:"unified-header"},Te={class:"combinations-count"},Ee={class:"header-controls"},Ae=["innerHTML"],Me={key:0,class:"content-section","data-testid":"trial-config-section"},Ne={class:"section-body"},$e={class:"trial-config-table"},Oe={class:"config-header-row"},Fe={class:"config-trial-info"},Re={class:"trial-name-section"},je={class:"repeat-section"},De={class:"quick-add-row"},qe={class:"quick-add-section"},Le={class:"quick-add-buttons"},Ue={key:0,class:"quick-cost"},Be={class:"config-table","data-testid":"model-config-table"},ze=["data-config-index","data-provider","data-model"],Ke={class:"col-model"},Ge={class:"model-name"},Ve={class:"model-provider"},Ye={class:"col-params"},He={class:"params-text"},Je={class:"col-calls"},We={class:"calls-breakdown"},Xe={class:"calls-value"},Qe={class:"col-cost"},Ze={class:"cost-breakdown"},et={key:0,class:"cost-value"},tt={key:1,class:"env-cost"},at={class:"col-total"},nt={class:"cost-breakdown"},lt={key:0,class:"cost-value total-cost"},rt={key:1,class:"env-cost"},st={class:"col-actions"},ot={key:0,class:"table-summary-row"},it={class:"col-model"},ct={class:"summary-label"},dt={class:"col-calls"},ut={class:"summary-calls"},pt={class:"col-total"},mt={key:0,class:"summary-cost"},ft=e(v({__name:"TrialCreationModal",props:{initialDesignId:{},trialToDuplicate:{},isEditMode:{type:Boolean}},emits:["close","created","created-and-started","export-trial"],setup(e,{emit:d}){const u=e,p=d,m=F(),f=Y(),v=H(),_=t(),j=a(),{hasDataForModel:D}=W(),q=k(""),L=k(null),U=k([]),B=k(""),z=k(1),K=k(!1),G=k(!1);u.trialToDuplicate&&n.info("Duplicating trial",{trialName:u.trialToDuplicate.name});const V=k(0),ee=new Map,te=k(!1),ae=k(!1),ft=C(()=>j.financialCostsEnabled),vt=C(()=>{const e=J(),t=e=>j.hasApiKey(e),a=(t,a)=>!!e.enabledModels.find(e=>e.provider===t&&e.modelId===a&&e.enabled),n=[],r=new Set,s=[..._.trials].sort((e,t)=>new Date(t.created).getTime()-new Date(e.created).getTime());for(const p of s){if(n.length>=5)break;for(const e of p.configurationSnapshots||[]){if(n.length>=5)break;const s=`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`;if(!r.has(s)&&t(e.provider)&&a(e.provider,e.modelId)){const t=l.getParametersForModel(e.provider,e.modelId);if(!t)continue;if(Object.keys(e.parameters).some(e=>!(e in t)))continue;r.add(s),n.push({provider:e.provider,modelId:e.modelId,displayName:e.modelId,parameters:e.parameters,outputType:"text"})}}}const o=(e,t)=>{const a=l.getParametersForModel(e,t),n={},r=(e,t)=>{Object.entries(e).forEach(([e,a])=>{"object"===a.type&&a.properties?(t[e]={},r(a.properties,t[e])):void 0!==a.default&&(t[e]=a.default)})};r(a,n),n.temperature||!n.options||n.options.temperature||(n.options?n.options.temperature=0:n.temperature=0);const s=(e,t)=>{for(const[a,n]of Object.entries(e))"object"===n.type&&n.properties?(t[a]||(t[a]={}),s(n.properties,t[a])):n.is_output_length&&void 0===t[a]&&(t[a]=128)};return s(a,n),n},i=[{provider:"openai-chat",modelId:"gpt-4.1-nano",displayName:"gpt-4.1-nano",parameters:o("openai-chat","gpt-4.1-nano"),outputType:"text"},{provider:"openai-responses",modelId:"o4-mini",displayName:"o4-mini",parameters:o("openai-responses","o4-mini"),outputType:"text"},{provider:"anthropic",modelId:"claude-3-haiku-20240307",displayName:"claude-3-haiku-20240307",parameters:o("anthropic","claude-3-haiku-20240307"),outputType:"text"},{provider:"anthropic",modelId:"claude-4-sonnet-20250514",displayName:"claude-4-sonnet-20250514",parameters:o("anthropic","claude-4-sonnet-20250514"),outputType:"text"},{provider:"openrouter",modelId:"meta-llama/llama-3.1-8b-instruct",displayName:"meta-llama/llama-3.1-8b-instruct",parameters:o("openrouter","meta-llama/llama-3.1-8b-instruct"),outputType:"text"},{provider:"openrouter",modelId:"mistralai/mistral-nemo",displayName:"mistralai/mistral-nemo",parameters:o("openrouter","mistralai/mistral-nemo"),outputType:"text"},{provider:"openrouter",modelId:"deepseek/deepseek-chat-v3-0324",displayName:"deepseek/deepseek-chat-v3-0324",parameters:o("openrouter","deepseek/deepseek-chat-v3-0324"),outputType:"text"}],c=new Set(n.map(e=>`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`));for(const l of i){const e=`${l.provider}:${l.modelId}:${JSON.stringify(l.parameters)}`;!c.has(e)&&t(l.provider)&&a(l.provider,l.modelId)&&n.push(l)}const d=[],u=new Set;for(const l of n){const e=`${l.provider}:${l.modelId}`;u.has(e)||(u.add(e),d.push(l))}return d}),gt=C(()=>{const e=f.designs;if(n.info("Designs available",{count:e.length}),!q.value)return e;const t=q.value.toLowerCase();return e.filter(e=>e.name.toLowerCase().includes(t)||e.promptTemplate.toLowerCase().includes(t))}),bt=C(()=>{if(!L.value)return 0;let e=1;for(const t of Object.values(L.value.variableBindings))if("direct"===t.type)e*=t.values?.length||1;else if(t.listId){const a=v.lists.find(e=>e.id===t.listId);e*=a?.itemCount||1}return e}),ht=C(()=>bt.value*U.value.length*z.value),yt=C(()=>{let e=0;for(const t of U.value)e+=Rt(t)*bt.value*z.value;return e});function _t(e){L.value=e,B.value=Lt(),te.value=!0}function kt(){L.value=null,U.value=[],te.value=!1}function Ct(){p("close"),m.push({name:"designs",query:{create:"true"}})}function xt(e){return Object.keys(e.variableBindings).length}function wt(e){return e.replace(/\n+/g," ").replace(/\s+/g," ").trim()}function St(e){const t=new Date,a=t.getTime()-e.getTime(),n=Math.floor(a/864e5);if(0===n)return"Today";if(1===n)return"Yesterday";if(n<7)return`${n} days ago`;if(n<30){const e=Math.floor(n/7);return`${e} week${e>1?"s":""} ago`}return e.toLocaleDateString("en-US",{month:"short",day:"numeric",year:e.getFullYear()!==t.getFullYear()?"numeric":void 0})}function It(e){if(!e.variableBindings)return"1";let t=1;for(const a of Object.values(e.variableBindings))if("direct"===a.type&&a.values)t*=a.values.length;else if("list"===a.type&&a.listId){const e=v.lists.find(e=>e.id===a.listId);t*=e?.itemCount||1}return t>1e3?`${(t/1e3).toFixed(1)}k`:t.toString()}function Pt(e){const t=function(e){if(!e.variableBindings)return[{}];const t=[];for(const[a,n]of Object.entries(e.variableBindings))if("direct"===n.type&&n.values)t.push({name:a,values:n.values});else if("list"===n.type&&n.listId){const e=v.lists.find(e=>e.id===n.listId);if(e){let n=[];n="simple"===e.category&&e.values?e.values.slice(0,3):"attributed"===e.category&&e.items?e.items.slice(0,3).map(e=>e.value):[`${a}_sample`],t.push({name:a,values:n})}}if(0===t.length)return[{}];return t.map(e=>e.values).reduce((e,t)=>e.flatMap(e=>t.map(t=>[...e,t])),[[]]).map(e=>{const a={};return t.forEach((t,n)=>{a[t.name]=e[n]}),a})}(e);if(t.length<=1)return Tt(wt(e.promptTemplate));const a=t[V.value%t.length],n=["variable-highlight-blue","variable-highlight-green","variable-highlight-purple","variable-highlight-orange","variable-highlight-pink","variable-highlight-teal"];let l=e.promptTemplate;Object.keys(e.variableBindings||{}).forEach((e,t)=>{if(void 0!==a[e]){const r=new RegExp(`\\{\\{\\s*${e}\\s*\\}\\}`,"g"),s=`<span class="${n[t%n.length]}">${Tt(String(a[e]))}</span>`;l=l.replace(r,s)}});let r=Tt(l);return n.forEach(e=>{r=r.replace(new RegExp(`&lt;span class="${e}"&gt;`,"g"),`<span class="${e}">`).replace(/&lt;\/span&gt;/g,"</span>")}),wt(r)}function Tt(e){const t=document.createElement("div");return t.textContent=e,t.innerHTML}function Et(){te.value=!te.value}function At(){ae.value=!ae.value}function Mt(e){return U.value.some(t=>t.provider===e.provider&&t.modelId===e.modelId&&JSON.stringify(t.parameters)===JSON.stringify(e.parameters))}function $t(e){const t=J().enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t)return 0;const a=L.value?.tokenEstimate?.avgTokens||0,n=l.getParametersForModel(e.provider,e.modelId);let r=0;for(const[l,s]of Object.entries(n))if(s.is_output_length&&e.parameters[l]){r=e.parameters[l];break}if(0===a||0===r)return 0;return((t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*r)*bt.value*z.value}function Ot(e){const t=[];for(const[a,n]of Object.entries(e))null!=n&&t.push(`${a}=${n}`);return t.join(", ")||"Default settings"}function Ft(e){U.value.push(e),G.value=!1,setTimeout(()=>{R(()=>{const e=[".streamlined-content",".ant-modal-body",".ant-modal-wrap .ant-modal-body"];for(const t of e){const e=document.querySelector(t);if(e){e.scrollTo({top:e.scrollHeight,behavior:"smooth"});break}}})},100)}function Rt(e){const t=J().enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId);if(!t)return 0;const a=L.value?.tokenEstimate?.avgTokens||0,n=l.getParametersForModel(e.provider,e.modelId);let r=0;for(const[l,s]of Object.entries(n))if(s.is_output_length&&e.parameters[l]){r=e.parameters[l];break}if(0===a||0===r)return 0;return(t.capabilities?.inputCostPerToken||0)*a+(t.capabilities?.outputCostPerToken||0)*r}function jt(e){return Rt(e)*bt.value*z.value}function Dt(e){return D(e.provider,e.modelId)}function qt(e,t){if(!L.value||!Dt(e))return"";try{const a=L.value.tokenEstimate?.avgTokens||0;if(0===a)return"";const n=J();if(!n.enabledModels.find(t=>t.provider===e.provider&&t.modelId===e.modelId))return"";const r=l.getParametersForModel(e.provider,e.modelId);let s=0;for(const[t,l]of Object.entries(r))if(l.is_output_length&&e.parameters[t]){s=e.parameters[t];break}0===s&&(s=100);const o=a+s,i="per-call"===t?1:bt.value*z.value,c=o*i/1e3*.001;return c<.001?"<1mg CO₂e":c<1?`${(1e3*c).toFixed(0)}mg CO₂e`:`${c.toFixed(3)}g CO₂e`}catch(a){return n.warn("Error calculating environmental cost display",{error:a}),""}}function Lt(){if(!L.value)return"New Trial";const e=(new Date).toLocaleString("en-US",{month:"short",day:"numeric",hour:"2-digit",minute:"2-digit"});return`${L.value.name} - ${e}`}async function Ut(){if(L.value&&0!==U.value.length){K.value="start";try{const e=await _.createTrial({name:B.value||Lt(),designId:L.value.id,configurations:U.value,repeatConfig:z.value>1?{callsPerPrompt:z.value,strategy:"sequential"}:void 0});i.success("Trial created! Starting execution..."),p("created-and-started",e),p("close"),K.value=!1,setTimeout(async()=>{try{await _.executeTrial(e)}catch(t){n.error("Failed to start trial",t),i.error("Failed to start trial execution")}},100)}catch(e){n.error("Failed to create trial",e),i.error("Failed to create trial"),K.value=!1}}}async function Bt(){if(L.value&&0!==U.value.length){K.value="export";try{const e=await _.createTrial({name:B.value||Lt(),designId:L.value.id,configurations:U.value,repeatConfig:z.value>1?{callsPerPrompt:z.value,strategy:"sequential"}:void 0}),t=await _.getTrial(e);if(t){const{PythonExportService:e}=await c(async()=>{const{PythonExportService:e}=await Promise.resolve().then(()=>Nt);return{PythonExportService:e}},void 0,import.meta.url),a=e.validateTrialForExport(t);if(!a.valid)return void i.error(`Cannot export trial: ${a.errors.join(", ")}`);p("export-trial",t)}i.success("Trial created! Opening export options..."),p("created",e),p("close")}catch(e){n.error("Failed to create trial for export",e),i.error("Failed to create trial for export")}finally{K.value=!1}}}async function zt(){if(L.value&&0!==U.value.length){K.value="draft";try{if(u.isEditMode&&u.trialToDuplicate)await _.updateTrial(u.trialToDuplicate.id,{name:B.value||Lt()}),i.success("Trial updated!"),p("created",u.trialToDuplicate.id);else{const e=await _.createTrial({name:B.value||Lt(),designId:L.value.id,configurations:U.value,repeatConfig:z.value>1?{callsPerPrompt:z.value,strategy:"sequential"}:void 0});i.success("Trial created as draft!"),p("created",e)}p("close")}catch(e){n.error("Failed to create draft trial",e),i.error("Failed to create draft trial")}finally{K.value=!1}}}let Kt=null;return x(async()=>{if(await Promise.all([f.initialize(),v.initialize(),_.initialize()]),u.initialDesignId){const e=f.designs.find(e=>e.id===u.initialDesignId);e&&_t(e)}if(u.trialToDuplicate){const e=u.trialToDuplicate;n.info("Setting up trial duplication",{trialName:e.name});const t=()=>{if(f.designs.length>0){n.info("Available designs",{count:f.designs.length});const t=f.designs.find(t=>t.id===e.designSnapshot.originalId);n.info("Found design for duplication",{designName:t?.name}),t?(L.value=t,n.info("Set selectedDesign",{designName:L.value.name}),B.value=u.isEditMode?e.name:`Copy of ${e.name}`,e.repeatConfig?.callsPerPrompt&&(z.value=e.repeatConfig.callsPerPrompt),e.configurationSnapshots&&e.configurationSnapshots.length>0&&(U.value=e.configurationSnapshots.map(e=>({name:e.name||e.modelId,provider:e.provider,modelId:e.modelId,parameters:e.parameters||{}})),n.info("Set configurations",{count:U.value.length})),te.value=!0):n.error("Design not found for trial duplication",{designId:e.designSnapshot.originalId})}else n.info("Designs not loaded yet, waiting"),setTimeout(t,100)};t()}Kt=setInterval(()=>{te.value||V.value++},1e3)}),w(()=>{Kt&&clearInterval(Kt),ee.forEach(e=>clearInterval(e)),ee.clear()}),(e,t)=>{const a=T("a-button"),n=T("a-input"),l=T("a-tag"),i=T("a-input-number");return b(),S(Z,{"model-value":!0,title:u.isEditMode?"Edit Trial":u.trialToDuplicate?"Duplicate Trial":"Create New Trial",size:"full","data-testid":"modal-trial-creation","onUpdate:modelValue":t[6]||(t[6]=t=>e.$emit("close"))},{footer:I(()=>[P(ne,null,{default:I(()=>[P(a,{size:"large",onClick:zt,loading:"draft"===K.value,disabled:!L.value||0===U.value.length,"data-testid":"btn-create-draft","aria-label":"Create trial as draft"},{default:I(()=>t[29]||(t[29]=[E(" Create as Draft ")])),_:1,__:[29]},8,["loading","disabled"]),P(a,{size:"large",onClick:Bt,loading:"export"===K.value,disabled:!L.value||0===U.value.length,"data-testid":"btn-export-python","aria-label":"Export trial to Python"},{default:I(()=>t[30]||(t[30]=[E(" Export to Python ")])),_:1,__:[30]},8,["loading","disabled"]),P(a,{type:"primary",size:"large",onClick:Ut,loading:"start"===K.value,disabled:!L.value||0===U.value.length,"data-testid":"btn-create-and-start","aria-label":"Create and start trial execution"},{default:I(()=>[P(A(o)),t[31]||(t[31]=E(" Create and Start "))]),_:1,__:[31]},8,["loading","disabled"])]),_:1})]),default:I(()=>[y("div",le,[y("section",re,[y("div",se,[t[8]||(t[8]=y("h3",null,"What are you testing?",-1)),L.value?(b(),S(a,{key:0,onClick:kt,size:"small",class:"back-button",style:{"margin-left":"2em"}},{default:I(()=>t[7]||(t[7]=[E(" ← Back to Select Design ")])),_:1,__:[7]})):h("",!0)]),y("div",oe,[L.value?(b(),g("div",Ie,[y("div",Pe,[y("h4",null,$(L.value.name),1),y("span",Te,$(bt.value)+" combinations",1),y("div",Ee,[P(a,{onClick:Et,size:"small",type:te.value?"default":"primary",class:"pause-btn"},{icon:I(()=>[(b(),S(O(te.value?"PlayCircleOutlined":"PauseCircleOutlined")))]),default:I(()=>[E(" "+$(te.value?"Start Variable Substitution":"Pause Variable Substitution"),1)]),_:1},8,["type"]),P(a,{onClick:At,size:"small",type:ae.value?"primary":"default",class:"placeholders-btn"},{default:I(()=>[E($(ae.value?"Show Live":"Show Raw Template"),1)]),_:1},8,["type"])])]),y("div",{class:"live-template-preview",innerHTML:ae.value?Tt(L.value.promptTemplate):Pt(L.value)},null,8,Ae)])):(b(),g("div",ie,[P(n,{value:q.value,"onUpdate:value":t[0]||(t[0]=e=>q.value=e),placeholder:"Search designs...",size:"large",class:"design-search","data-testid":"input-design-search",allowClear:""},{prefix:I(()=>[P(A(r))]),_:1},8,["value"]),0===gt.value.length?(b(),g("div",ce,[y("div",de,[t[10]||(t[10]=y("p",null,"No designs found",-1)),P(a,{onClick:t[1]||(t[1]=()=>A(f).initialize())},{default:I(()=>t[9]||(t[9]=[E("Refresh Designs")])),_:1,__:[9]})])])):(b(),g("div",ue,[(b(!0),g(M,null,N(gt.value,e=>{return b(),g("div",{key:e.id,class:"design-item","data-testid":"design-item","data-design-id":e.id,"data-design-name":e.name,onClick:t=>_t(e)},[y("div",me,[y("div",fe,[y("h4",ve,[E($(e.name)+" ",1),e.description?(b(),g("span",ge,"- "+$(e.description),1)):h("",!0)])]),y("span",be,$(St(e.updated)),1)]),y("p",{class:"design-description",innerHTML:Pt(e)},null,8,he),y("div",ye,[P(l,{size:"small",color:(a=e.outputType,{text:"blue",number:"green",boolean:"purple",json:"orange"}[a]||"default"),class:"output-type-tag"},{default:I(()=>[E($(e.outputType||"text"),1)]),_:2},1032,["color"]),y("span",_e,[y("span",ke,$(xt(e)),1),t[11]||(t[11]=y("span",{class:"stat-label"},"vars",-1))]),t[14]||(t[14]=y("span",{class:"stat-divider"},"•",-1)),y("span",Ce,[y("span",xe,$(It(e)),1),t[12]||(t[12]=y("span",{class:"stat-label"},"combos",-1))]),t[15]||(t[15]=y("span",{class:"stat-divider"},"•",-1)),y("span",we,[y("span",Se,$(e.tokenEstimate?.avgTokens||"?"),1),t[13]||(t[13]=y("span",{class:"stat-label"},"tokens",-1))])])],8,pe);var a}),128)),y("div",{class:"design-card design-card-create","data-testid":"btn-create-design",onClick:Ct},[P(A(s),{style:{"font-size":"24px"}}),t[16]||(t[16]=y("span",null,"Create New Design",-1))])]))]))])]),L.value?(b(),g("section",Me,[t[28]||(t[28]=y("h3",null,"Trial Configuration",-1)),y("div",Ne,[y("div",$e,[y("div",Oe,[y("div",Fe,[y("div",Re,[t[17]||(t[17]=y("label",{class:"inline-label"},"Trial Name:",-1)),P(n,{value:B.value,"onUpdate:value":t[2]||(t[2]=e=>B.value=e),placeholder:"Enter trial name (optional)",class:"trial-name-input","data-testid":"input-trial-name"},null,8,["value"])]),y("div",je,[t[18]||(t[18]=y("label",{class:"inline-label"},"Repeat:",-1)),P(i,{value:z.value,"onUpdate:value":t[3]||(t[3]=e=>z.value=e),min:1,max:10,size:"large",class:"repeat-count-input"},null,8,["value"]),t[19]||(t[19]=y("span",{class:"repeat-suffix"},"times per prompt",-1))])])]),y("div",De,[P(a,{onClick:t[4]||(t[4]=e=>G.value=!0),type:"primary",size:"large",class:"big-add-model-btn","data-testid":"btn-add-model","aria-label":"Add Model Configuration"},{default:I(()=>[P(A(s)),t[20]||(t[20]=E(" Add Model "))]),_:1,__:[20]}),t[22]||(t[22]=y("div",{class:"separator-bar"},null,-1)),y("div",qe,[t[21]||(t[21]=y("div",{class:"quick-add-label"},"Quick add recent/popular models (with default temperature=0, max response length = 128):",-1)),y("div",Le,[(b(!0),g(M,null,N(vt.value,e=>(b(),S(a,{key:`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`,onClick:t=>function(e){Mt(e)||(U.value.push({name:e.displayName,provider:e.provider,modelId:e.modelId,parameters:e.parameters}),R(()=>{const e=document.querySelector(".ant-modal-body");e&&e.scrollTo({top:e.scrollHeight,behavior:"smooth"})}))}(e),size:"small",class:"quick-preset-btn",disabled:Mt(e),"data-testid":"quick-add-model","data-provider":e.provider,"data-model":e.modelId,"aria-label":`Quick add ${e.displayName} model`},{default:I(()=>[E($(e.displayName)+" ",1),ft.value?(b(),g("span",Ue,$(A(X)($t(e))),1)):h("",!0)]),_:2},1032,["onClick","disabled","data-provider","data-model","aria-label"]))),128))])])]),y("div",Be,[t[27]||(t[27]=y("div",{class:"table-header"},[y("div",{class:"col-model"},"Model"),y("div",{class:"col-params"},"Parameters"),y("div",{class:"col-calls"},"API Calls"),y("div",{class:"col-cost"},"Cost per Call"),y("div",{class:"col-total"},"Total Cost"),y("div",{class:"col-actions"},"Actions")],-1)),(b(!0),g(M,null,N(U.value,(e,n)=>(b(),g("div",{key:n,class:"table-row","data-testid":"model-config-row","data-config-index":n,"data-provider":e.provider,"data-model":e.modelId},[y("div",Ke,[y("div",Ge,$(e.provider)+":"+$(e.modelId),1),y("div",Ve,$(e.provider),1)]),y("div",Ye,[y("span",He,$(Ot(e.parameters)),1)]),y("div",Je,[y("span",We,$(bt.value)+" × "+$(z.value)+" = ",1),y("span",Xe,$(bt.value*z.value),1)]),y("div",Qe,[y("div",Ze,[ft.value?(b(),g("span",et,$(A(X)(Rt(e))),1)):h("",!0),A(j).environmentalCostsEnabled&&Dt(e)?(b(),g("small",tt,$(qt(e,"per-call")),1)):h("",!0)])]),y("div",at,[y("div",nt,[ft.value?(b(),g("span",lt,$(A(X)(jt(e))),1)):h("",!0),A(j).environmentalCostsEnabled&&Dt(e)?(b(),g("small",rt,$(qt(e,"total")),1)):h("",!0)])]),y("div",st,[P(a,{type:"text",size:"small",danger:"",onClick:e=>function(e){U.value.splice(e,1)}(n),class:"remove-btn","data-testid":"remove-model-config","data-config-index":n,"aria-label":`Remove ${e.provider} ${e.modelId} configuration`},{default:I(()=>t[23]||(t[23]=[E("Remove")])),_:2,__:[23]},1032,["onClick","data-config-index","aria-label"])])],8,ze))),128)),U.value.length>1?(b(),g("div",ot,[y("div",it,[y("div",ct,"TOTAL ("+$(U.value.length)+" models)",1)]),t[24]||(t[24]=y("div",{class:"col-params"},null,-1)),y("div",dt,[y("span",ut,$(ht.value),1)]),t[25]||(t[25]=y("div",{class:"col-cost"},null,-1)),y("div",pt,[ft.value?(b(),g("span",mt,$(A(X)(yt.value)),1)):h("",!0)]),t[26]||(t[26]=y("div",{class:"col-actions"},null,-1))])):h("",!0)])])])])):h("",!0)]),P(Q,{open:G.value&&!!L.value,mode:"trial",design:L.value||void 0,"existing-configurations":U.value,onClose:t[5]||(t[5]=e=>G.value=!1),onAddConfiguration:Ft},null,8,["open","design","existing-configurations"])]),_:1},8,["title"])}}}),[["__scopeId","data-v-53c8dbc9"]]),vt={class:"trial-overview"},gt={class:"overview-section"},bt={class:"cost-value"},ht={key:0,class:"text-secondary",style:{"margin-left":"8px"}},yt={class:"overview-section"},_t={class:"progress-details"},kt={class:"progress-stats"},Ct={class:"configurations-section"},xt={key:0,class:"model-info"},wt={key:0},St={class:"prompt-section"},It={key:0,class:"variables-section"},Pt=v({__name:"TrialDetailModal",props:{trial:{}},emits:["close","updated"],setup(e){const t=e,a=[{title:"Model",key:"model",width:200},{title:"Parameters",key:"params",width:300},{title:"Cost/Call",key:"cost",width:100,align:"right"}],n=C(()=>0===t.trial.progress.total?0:Math.round(t.trial.progress.completed/t.trial.progress.total*100));function l(e){const t=Object.entries(e).map(([e,t])=>`${e}: ${t}`).join(", ");return t.length>50?t.substring(0,50)+"...":t}function r(){const e=t.trial.variableSnapshots;return e&&0!==e.length?e.map(e=>({variable:e.variableName,listName:e.originalListName,count:e.data.itemCount})):[]}return(e,t)=>{const s=T("a-button"),o=T("a-tag"),i=T("a-descriptions-item"),c=T("a-descriptions"),d=T("a-progress"),u=T("a-typography-text"),p=T("a-table"),m=T("a-typography-paragraph"),f=T("a-list-item-meta"),v=T("a-list-item"),_=T("a-list");return b(),S(Z,{"model-value":!0,title:e.trial.name,size:"full","onUpdate:modelValue":t[1]||(t[1]=t=>e.$emit("close"))},{footer:I(()=>[P(s,{onClick:t[0]||(t[0]=t=>e.$emit("close")),size:"large","data-testid":"btn-close-trial-detail","aria-label":"Close trial details"},{default:I(()=>t[2]||(t[2]=[E(" Close ")])),_:1,__:[2]})]),default:I(()=>[y("div",vt,[y("div",gt,[t[3]||(t[3]=y("h3",null,"Trial Information",-1)),P(c,{column:2,size:"small",bordered:""},{default:I(()=>[P(i,{label:"Status"},{default:I(()=>{return[P(o,{color:(t=e.trial.status,{completed:"success",failed:"error",running:"processing",cancelled:"default",draft:"default",pending:"processing",paused:"warning"}[t]||"default"),"data-testid":"tag-trial-status","data-status":e.trial.status,"aria-label":`Trial status: ${e.trial.status}`},{default:I(()=>[E($(e.trial.status.toUpperCase()),1)]),_:1},8,["color","data-status","aria-label"])];var t}),_:1}),P(i,{label:"Design"},{default:I(()=>[E($(e.trial.designSnapshot.originalName),1)]),_:1}),P(i,{label:"Created"},{default:I(()=>{return[E($((t=e.trial.created,new Date(t).toLocaleString())),1)];var t}),_:1}),P(i,{label:"Estimated Cost"},{default:I(()=>[y("span",bt,"$"+$(e.trial.estimatedCost.toFixed(3)),1)]),_:1}),e.trial.repeatConfig?.callsPerPrompt&&e.trial.repeatConfig.callsPerPrompt>1?(b(),S(i,{key:0,label:"Repeat Configuration"},{default:I(()=>[P(o,{color:"purple"},{default:I(()=>[E($(e.trial.repeatConfig.callsPerPrompt)+"× repeat",1)]),_:1}),e.trial.repeatConfig.delayBetweenRepeats?(b(),g("span",ht,$(e.trial.repeatConfig.delayBetweenRepeats)+"ms delay ",1)):h("",!0)]),_:1})):h("",!0)]),_:1})]),y("div",yt,[t[4]||(t[4]=y("h3",null,"Progress",-1)),y("div",_t,[P(d,{percent:n.value,status:"failed"===e.trial.status?"exception":"active",size:"small","data-testid":"progress-trial-completion","aria-label":`Trial progress: ${n.value}% complete`},null,8,["percent","status","aria-label"]),y("div",kt,[P(o,{"data-testid":"tag-progress-completed","aria-label":`${e.trial.progress.completed} of ${e.trial.progress.total} calls completed`},{default:I(()=>[E($(e.trial.progress.completed)+" / "+$(e.trial.progress.total)+" completed",1)]),_:1},8,["aria-label"]),e.trial.progress.networkErrors>0?(b(),S(o,{key:0,color:"error","data-testid":"tag-network-errors","aria-label":`${e.trial.progress.networkErrors} network errors occurred`},{default:I(()=>[E($(e.trial.progress.networkErrors)+" network errors ",1)]),_:1},8,["aria-label"])):h("",!0)])])])]),y("div",Ct,[y("h3",null,"Configurations ("+$(e.trial.configurationSnapshots.length)+")",1),P(p,{columns:a,"data-source":e.trial.configurationSnapshots,pagination:!1,size:"small",scroll:{y:300},"row-key":"id"},{bodyCell:I(({column:e,record:t})=>["model"===e.key?(b(),g("div",xt,[y("strong",null,$(t.provider),1),y("small",null,$(t.modelId),1)])):h("",!0),"params"===e.key?(b(),S(u,{key:1,code:"",class:"params-preview"},{default:I(()=>[E($(l(t.parameters)),1)]),_:2},1024)):h("",!0),"cost"===e.key?(b(),g(M,{key:2},[(b(),g("span",wt," $"+$(.001.toFixed(4)),1))],64)):h("",!0)]),_:1},8,["data-source"])]),y("div",St,[t[5]||(t[5]=y("h3",null,"Prompt Template",-1)),P(m,{code:"",class:"prompt-template"},{default:I(()=>[E($(e.trial.designSnapshot.promptTemplate),1)]),_:1})]),e.trial.variableSnapshots?.length?(b(),g("div",It,[t[6]||(t[6]=y("h3",null,"Variables",-1)),P(_,{"data-source":r(),size:"small",split:!1},{renderItem:I(({item:e})=>[P(v,null,{default:I(()=>[P(f,null,{title:I(()=>[P(o,{color:"blue"},{default:I(()=>[E($(e.variable),1)]),_:2},1024)]),description:I(()=>[y("span",null,$(e.listName)+" ("+$(e.count)+" values)",1)]),_:2},1024)]),_:2},1024)]),_:1},8,["data-source"])])):h("",!0)]),_:1},8,["title"])}}});class Tt{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=new d({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),a=this.extractUniqueVariables(t),n=e.configurationSnapshots.map(e=>({provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:e.parameters})),r=new Set(n.map(e=>e.provider)),s={};for(const o of r){const e=l.getProvider(o);e&&(s[o]=this.buildProviderConfig(o,e))}return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:a},models:n,providerConfigs:s}}static extractUniqueVariables(e){const t={};for(const n of e)for(const[e,a]of Object.entries(n.variables))t[e]||(t[e]=new Set),t[e].add(a);const a={};for(const[n,l]of Object.entries(t))a[n]=Array.from(l).sort();return a}static buildProviderConfig(e,t){const a=t.requestTransform||{},n=t.auth||{type:"none"};let l="direct";"messages"===a.promptKey&&a.wrapPrompt?l="messages":"input"===a.promptKey&&(l="input");let r,s,o="root";"ollama-chat"===e?(o="options",r={max_tokens:"num_predict",max_completion_tokens:"num_predict"}):"ollama-generate"===e&&(o="mixed",s={root:["model","prompt","stream","format","raw"],options:["temperature","num_predict","top_k","top_p"]},r={max_tokens:"num_predict",max_completion_tokens:"num_predict"});const i=Object.values(t.responseModes||{})[0],c=this.parseResponsePath(i?.responseTransform?.contentPath),d=i?.responseTransform?.fallbackPaths?.map(e=>this.parseResponsePath(e)),u=t.api.baseUrl+(t.api.endpoints.chat||t.api.endpoints.generate||"");return{name:t.name,endpoint:u,auth:{type:n.type,header:n.header,prefix:"bearer"===n.type?"Bearer":void 0},headers:t.headers,request:{modelPrefixStrip:!0,promptFormat:l,messageRole:a.messageRole,paramLocation:o,paramRenames:r,mixedParams:s},response:{successPath:c,fallbackPaths:d,errorPath:["error","message"]}}}static parseResponsePath(e){return e?e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const t=parseInt(e);return isNaN(t)?e:t}):["content"]}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=JSON.stringify(e.providerConfigs,null,4);return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Simple Mode\n=====================================\nGenerated by Auditomatic Lite v${u.short} on ${a}\n\nThis script reproduces your experiment by generating API calls from variables.\nPerfect for understanding, modifying, and extending your experiments.\n\nOriginal trial: ${t}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${Object.keys(e.providerConfigs).map(e=>{const t=e.split("-")[0].toUpperCase();return`    "${e}": os.environ.get("${t}_API_KEY", ""),`}).join("\n")}\n}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Provider configurations (how to talk to each API)\nPROVIDER_CONFIGS = ${r}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef make_api_call(provider_id: str, model: str, prompt: str, params: dict) -> dict:\n    """\n    Universal API caller that handles all provider quirks.\n    \n    Returns dict with 'success', 'content', 'error', and timing info.\n    """\n    config = PROVIDER_CONFIGS[provider_id]\n    \n    # Build headers\n    headers = {"Content-Type": "application/json"}\n    \n    # Add authentication\n    auth = config["auth"]\n    if auth["type"] == "bearer":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = f"{auth['prefix']} {api_key}"\n    elif auth["type"] == "header":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = api_key\n    \n    # Add provider-specific headers\n    if config.get("headers"):\n        headers.update(config["headers"])\n    \n    # Build request body\n    request = config["request"]\n    \n    # Strip provider prefix from model\n    if request.get("modelPrefixStrip"):\n        model = model.split(":", 1)[-1]\n    \n    body = {"model": model}\n    \n    # Format prompt\n    if request["promptFormat"] == "messages":\n        body["messages"] = [{"role": request.get("messageRole", "user"), "content": prompt}]\n    elif request["promptFormat"] == "direct":\n        body["prompt"] = prompt\n    elif request["promptFormat"] == "input":\n        body["input"] = prompt\n    \n    # Handle parameters\n    processed_params = params.copy()\n    \n    # Apply renames\n    if request.get("paramRenames"):\n        for old_key, new_key in request["paramRenames"].items():\n            if old_key in processed_params:\n                processed_params[new_key] = processed_params.pop(old_key)\n    \n    # Place parameters\n    if request["paramLocation"] == "root":\n        body.update(processed_params)\n    elif request["paramLocation"] == "options":\n        body["options"] = processed_params\n    elif request.get("mixedParams"):\n        mixed = request["mixedParams"]\n        for key, value in processed_params.items():\n            if key in mixed.get("root", []):\n                body[key] = value\n            else:\n                if "options" not in body:\n                    body["options"] = {}\n                body["options"][key] = value\n    \n    # Make request\n    start_time = time.time()\n    try:\n        response = requests.post(\n            config["endpoint"],\n            headers=headers,\n            json=body,\n            timeout=30\n        )\n        latency_ms = (time.time() - start_time) * 1000\n        \n        if response.ok:\n            data = response.json()\n            content = extract_from_path(data, config["response"]["successPath"])\n            \n            # Try fallback paths\n            if content is None and config["response"].get("fallbackPaths"):\n                for path in config["response"]["fallbackPaths"]:\n                    content = extract_from_path(data, path)\n                    if content is not None:\n                        break\n            \n            return {\n                "success": True,\n                "content": content or "",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n        else:\n            return {\n                "success": False,\n                "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n            \n    except Exception as e:\n        return {\n            "success": False,\n            "error": str(e),\n            "latency_ms": (time.time() - start_time) * 1000\n        }\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(\n                model_config["provider"],\n                model_config["modelId"],\n                prompt,\n                model_config["parameters"]\n            )\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": result.get("content", ""),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                "status_code": result.get("status_code", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {result['content'][:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_results_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider not in API_KEYS or not API_KEYS[provider]:\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(set(missing_keys)))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns:\n            print(f"Avg latency: {df['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class Et{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=[],a=new f,r=new d({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),s=p(e);let o=0;for(const c of e.configurationSnapshots){const d=l.getProvider(c.provider);if(d)for(const l of r){const r=s>1?m():void 0;let u=e.designSnapshot.promptTemplate;for(const[e,t]of Object.entries(l.variables))u=u.replace(new RegExp(`{{${e}}}`,"g"),t);for(let e=0;e<s;e++){o++;try{const n={id:"export-config",name:c.name,provider:c.provider,model:c.modelId,params:c.parameters,created_at:new Date},i=a.buildAPIRequest(n,u),p={};for(const[e,t]of Object.entries(i.headers))"Authorization"===e&&t.startsWith("Bearer ")?p[e]=`Bearer $${c.provider.split("-")[0].toUpperCase()}_API_KEY`:e===d.auth.header&&"header"===d.auth.type?p[e]=`$${c.provider.split("-")[0].toUpperCase()}_API_KEY`:p[e]=t;const m=this.parseResponsePath(this.getDefaultResponsePath(c.provider));t.push({id:`call_${String(o).padStart(3,"0")}`,provider:c.provider,endpoint:i.url,headers:p,body:i.body,responsePath:m,metadata:{variables:l.variables,modelName:c.modelId,configName:c.name,...s>1&&{repeatIndex:e,repeatGroupId:r}}})}catch(i){n.warn("Failed to build API call for config",{configName:c.name,error:i})}}}}return{apiCalls:t,...e.repeatConfig&&{repeatConfig:{callsPerPrompt:e.repeatConfig.callsPerPrompt,delayBetweenRepeats:e.repeatConfig.delayBetweenRepeats}}}}static parseResponsePath(e){return e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const t=parseInt(e);return isNaN(t)?e:t})}static getDefaultResponsePath(e){switch(e){case"openai-chat":case"openrouter":return"choices[0].message.content";case"openai-responses":return"output[0].content[0].text";case"anthropic":return"content[0].text";case"ollama-chat":return"message.content";case"ollama-generate":return"response";default:return"content"}}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.apiCalls,null,4),l=[...new Set(e.apiCalls.map(e=>e.provider))],r=e.repeatConfig?`\nRepeat configuration: ${e.repeatConfig.callsPerPrompt} calls per prompt${e.repeatConfig.delayBetweenRepeats?`, ${e.repeatConfig.delayBetweenRepeats}ms delay`:""}`:"";return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Literal Mode\n======================================\nGenerated by Auditomatic Lite v${u.short} on ${a}\n\nThis script contains the EXACT API calls from your experiment.\nPerfect for bit-for-bit reproduction, debugging, and comparing results.\n\nOriginal trial: ${t}\nTotal API calls: ${e.apiCalls.length}${r}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${l.map(e=>{const t=e.split("-")[0].toUpperCase();return`    "${t}": os.environ.get("${t}_API_KEY", ""),`}).join("\n")}\n}\n\n# Pre-computed API calls from your experiment\nAPI_CALLS = ${n}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef execute_literal_calls():\n    """Execute pre-serialized API calls exactly as specified"""\n    results = []\n    total = len(API_CALLS)\n    \n    print(f"Executing {total} pre-computed API calls...")\n    print("=" * 60)\n    \n    for i, call in enumerate(API_CALLS):\n        print(f"[{i+1}/{total}] {call['metadata']['configName']} - ", end="")\n        \n        # Replace API key placeholders in headers\n        headers = {}\n        for key, value in call["headers"].items():\n            if "\\$" in str(value):\n                # Extract provider name from placeholder\n                for provider_key, api_key in API_KEYS.items():\n                    placeholder = f"\\\${provider_key}_API_KEY"\n                    if placeholder in value:\n                        headers[key] = value.replace(placeholder, api_key)\n                        break\n                else:\n                    headers[key] = value\n            else:\n                headers[key] = value\n        \n        # Check if we have required API key\n        provider_base = call["provider"].split("-")[0].upper()\n        if provider_base in ["OPENAI", "ANTHROPIC", "OPENROUTER"] and not API_KEYS.get(provider_base):\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": f"No API key for {provider_base}",\n                "latency_ms": 0,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ No API key")\n            continue\n        \n        # Make the exact API call\n        start_time = time.time()\n        try:\n            response = requests.post(\n                call["endpoint"],\n                headers=headers,\n                json=call["body"],\n                timeout=30\n            )\n            latency_ms = (time.time() - start_time) * 1000\n            \n            if response.ok:\n                data = response.json()\n                content = extract_from_path(data, call["responsePath"])\n                \n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": content or "",\n                    "success": True,\n                    "error": "",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    "full_response": json.dumps(data)[:500],  # First 500 chars\n                    **call["metadata"]["variables"]\n                })\n                print(f"✓ {(content or '')[:30]}")\n            else:\n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": "",\n                    "success": False,\n                    "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    **call["metadata"]["variables"]\n                })\n                print(f"✗ HTTP {response.status_code}")\n                \n        except Exception as e:\n            latency_ms = (time.time() - start_time) * 1000\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": str(e)[:200],\n                "latency_ms": latency_ms,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ {str(e)[:30]}")\n        \n        # Handle repeat delays if configured\n        if "repeatIndex" in call["metadata"] and call["metadata"]["repeatIndex"] > 0:\n            # Check if there's a repeat delay configured\n            delay_ms = ${e.repeatConfig?.delayBetweenRepeats||0}\n            if delay_ms > 0:\n                time.sleep(delay_ms / 1000.0)\n        \n        # Rate limiting\n        time.sleep(0.1)\n    \n    return results\n\ndef extract_prompt_from_body(body: dict) -> str:\n    """Extract the prompt from various request body formats"""\n    # Messages format (OpenAI, Anthropic, etc)\n    if "messages" in body and isinstance(body["messages"], list):\n        for msg in body["messages"]:\n            if msg.get("role") == "user":\n                return msg.get("content", "")\n    \n    # Direct prompt format (Ollama generate)\n    if "prompt" in body:\n        return body["prompt"]\n    \n    # Input format (OpenAI responses)\n    if "input" in body:\n        return body["input"]\n    \n    return ""\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    # Drop full_response column for cleaner output (except JSON)\n    if format != "json" and "full_response" in df.columns:\n        df = df.drop(columns=["full_response"])\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_literal_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    required_providers = set(call["provider"].split("-")[0].upper() for call in API_CALLS)\n    missing_keys = []\n    for provider in required_providers:\n        if provider not in ["OLLAMA"] and not API_KEYS.get(provider):\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(missing_keys))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Execute all calls\n    results = execute_literal_calls()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if df['success'].any():\n            print(f"Avg latency (successful): {df[df['success']]['latency_ms'].mean():.1f}ms")\n        \n        # Group by model\n        print(f"\\nBy Model:")\n        model_summary = df.groupby('config_name')['success'].agg(['count', 'sum', 'mean'])\n        model_summary.columns = ['total', 'successful', 'success_rate']\n        print(model_summary)\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class At{static generate(e){const t=this.extractData(e);return this.generateScript(t,e.name)}static extractData(e){const t=new d({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),a=this.extractUniqueVariables(t),n=e.configurationSnapshots.map(e=>{let t,a="text";return e.parameters.response_format?(a="json_mode",t={response_format:e.parameters.response_format}):e.parameters.tools&&(a="function_calling",t={tools:e.parameters.tools,tool_choice:e.parameters.tool_choice}),{provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:this.filterCoreParams(e.parameters),responseMode:a,responseModeParams:t}}),l=new Set(n.map(e=>e.provider)),r={"openai-chat":"openai","openai-responses":"openai",anthropic:"anthropic",openrouter:"openai","ollama-chat":"ollama","ollama-generate":"ollama"},s=[...new Set(Array.from(l).map(e=>r[e]).filter(Boolean))],o={"openai-chat":"OPENAI","openai-responses":"OPENAI",anthropic:"ANTHROPIC",openrouter:"OPENROUTER","ollama-chat":"","ollama-generate":""},i=[...new Set(Array.from(l).map(e=>o[e]).filter(Boolean))];return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:a},models:n,providerLibraries:{required:s,apiKeys:i}}}static extractUniqueVariables(e){const t={};for(const n of e)for(const[e,a]of Object.entries(n.variables))t[e]||(t[e]=new Set),t[e].add(a);const a={};for(const[n,l]of Object.entries(t))a[n]=Array.from(l).sort();return a}static filterCoreParams(e){const t={...e};return delete t.response_format,delete t.tools,delete t.tool_choice,t}static generateScript(e,t){const a=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=["import os","import json","import time","import pandas as pd","from datetime import datetime"];return e.providerLibraries.required.includes("openai")&&r.push("from openai import OpenAI"),e.providerLibraries.required.includes("anthropic")&&r.push("from anthropic import Anthropic"),e.providerLibraries.required.includes("ollama")&&r.push("import ollama"),`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Native Mode\n=====================================\nGenerated by Auditomatic Lite v${u.short} on ${a}\n\nThis script uses native Python libraries for each provider.\nCleanest code, best for production use.\n\nOriginal trial: ${t}\nRequired packages: ${e.providerLibraries.required.join(", ")}\n"""\n\n${r.join("\n")}\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\n${e.providerLibraries.apiKeys.map(e=>`os.environ.setdefault("${e}_API_KEY", "")  # Set your ${e} API key`).join("\n")}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\n# Initialize clients\nclients = {}\n\ndef get_client(provider):\n    """Get or create client for provider"""\n    if provider not in clients:\n        if provider in ["openai-chat", "openai-responses"]:\n            clients[provider] = OpenAI()\n        elif provider == "anthropic":\n            clients[provider] = Anthropic()\n        elif provider == "openrouter":\n            clients[provider] = OpenAI(\n                api_key=os.environ.get("OPENROUTER_API_KEY"),\n                base_url="https://openrouter.ai/api/v1"\n            )\n        # Ollama doesn't need a client\n    return clients.get(provider)\n\ndef make_api_call(model_config: dict, prompt: str) -> dict:\n    """Make API call using native provider library"""\n    provider = model_config["provider"]\n    model = model_config["modelId"]\n    params = model_config["parameters"].copy()\n    \n    try:\n        start_time = time.time()\n        \n        if provider == "openai-chat" or provider == "openrouter":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["response_format"] = {"type": "json_object"}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.chat.completions.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content based on response mode\n            if model_config["responseMode"] == "function_calling" and response.choices[0].message.tool_calls:\n                content = response.choices[0].message.tool_calls[0].function.arguments\n                if isinstance(content, str):\n                    content = json.loads(content)\n            else:\n                content = response.choices[0].message.content\n            \n        elif provider == "openai-responses":\n            client = get_client(provider)\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["text"] = {"format": {"type": "json_object"}}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.responses.create(\n                model=model,\n                input=prompt,\n                **params\n            )\n            \n            # Extract content\n            output = response.output\n            if isinstance(output, list) and len(output) > 0:\n                if hasattr(output[0], 'content') and isinstance(output[0].content, list):\n                    content = output[0].content[0].text if hasattr(output[0].content[0], 'text') else str(output[0].content[0])\n                else:\n                    content = str(output[0])\n            else:\n                content = str(output)\n            \n        elif provider == "anthropic":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.messages.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content\n            if model_config["responseMode"] == "function_calling" and hasattr(response.content[0], 'input'):\n                content = response.content[0].input\n            else:\n                content = response.content[0].text\n            \n        elif provider == "ollama-chat":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.chat(\n                model=model,\n                messages=[{"role": "user", "content": prompt}],\n                **params\n            )\n            \n            # Extract content\n            content = response["message"]["content"]\n            \n        elif provider == "ollama-generate":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.generate(\n                model=model,\n                prompt=prompt,\n                **params\n            )\n            \n            # Extract content\n            content = response["response"]\n        \n        else:\n            raise ValueError(f"Unknown provider: {provider}")\n        \n        latency_ms = (time.time() - start_time) * 1000\n        \n        return {\n            "success": True,\n            "content": content,\n            "latency_ms": latency_ms\n        }\n        \n    except Exception as e:\n        latency_ms = (time.time() - start_time) * 1000\n        return {\n            "success": False,\n            "content": "",\n            "error": str(e),\n            "latency_ms": latency_ms\n        }\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(model_config, prompt)\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": str(result.get("content", "")),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {str(result['content'])[:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: list, format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_native_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for required packages\n    required = ${JSON.stringify(e.providerLibraries.required)}\n    missing = []\n    for lib in required:\n        try:\n            __import__(lib)\n        except ImportError:\n            missing.append(lib)\n    \n    if missing:\n        print(f"ERROR: Missing required packages: {', '.join(missing)}")\n        print(f"Install with: pip install {' '.join(missing)}")\n        return\n    \n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider in ["openai-chat", "openai-responses"] and not os.environ.get("OPENAI_API_KEY"):\n            missing_keys.append("OPENAI_API_KEY")\n        elif provider == "anthropic" and not os.environ.get("ANTHROPIC_API_KEY"):\n            missing_keys.append("ANTHROPIC_API_KEY")\n        elif provider == "openrouter" and not os.environ.get("OPENROUTER_API_KEY"):\n            missing_keys.append("OPENROUTER_API_KEY")\n    \n    if missing_keys:\n        print(f"WARNING: Missing API keys: {', '.join(set(missing_keys))}")\n        print("Set them in the script or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns and df['success'].any():\n            print(f"Avg latency: {df[df['success']]['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class Mt{static async generatePythonScript(e,t){try{const a=t||this.getDefaultOptions(),n=this.validateTrialForExport(e);if(!n.valid)throw new Error(`Trial validation failed: ${n.errors.join(", ")}`);switch(a.mode){case"simple":return Tt.generate(e);case"literal":return Et.generate(e);case"native":return At.generate(e);default:throw new Error(`Unknown export mode: ${a.mode}`)}}catch(a){throw new Error(`Failed to generate Python export: ${a instanceof Error?a.message:String(a)}`)}}static async downloadPythonScript(e,t){const a=await this.generatePythonScript(e,t),n=t||this.getDefaultOptions(),l=new Blob([a],{type:"text/x-python"}),r=URL.createObjectURL(l),s=document.createElement("a");s.href=r,s.download=this.generateFilename(e,n.mode),document.body.appendChild(s),s.click(),document.body.removeChild(s),URL.revokeObjectURL(r)}static validateTrialForExport(e){const t=[];return e.designSnapshot?e.designSnapshot.promptTemplate||t.push("Design missing prompt template"):t.push("Trial missing design snapshot"),e.configurationSnapshots&&0!==e.configurationSnapshots.length?e.configurationSnapshots.forEach((e,a)=>{e.provider||t.push(`Configuration ${a+1} missing provider`),e.modelId||t.push(`Configuration ${a+1} missing model`),e.parameters||t.push(`Configuration ${a+1} missing parameters`)}):t.push("Trial missing model configurations"),e.variableSnapshots||t.push("Trial missing variable snapshots"),{valid:0===t.length,errors:t}}static getExportSummary(e){const t=new Set(e.configurationSnapshots.map(e=>e.provider)),a=e.totalCombinations||0;return{apiCallCount:e.configurationSnapshots.length*a,providersUsed:Array.from(t),variableCombinations:a,configurations:e.configurationSnapshots.length}}static getDefaultOptions(){return{mode:"simple"}}static generateFilename(e,t){const a=e.name||`trial_${e.id}`,n=(new Date).toISOString().split("T")[0];return`${a.toLowerCase().replace(/[^a-z0-9]/g,"_")}_${t}_${n}.py`}}const Nt=Object.freeze(Object.defineProperty({__proto__:null,PythonExportService:Mt},Symbol.toStringTag,{value:"Module"})),$t={class:"trial-info"},Ot={class:"trial-stats"},Ft={class:"export-section"},Rt={class:"mode-content"},jt={class:"mode-content"},Dt={class:"mode-content"},qt={class:"export-section"},Lt={class:"preview-content"},Ut={class:"preview-info"},Bt=v({__name:"PythonExportModal",props:{trial:{}},emits:["close","exported"],setup(e,{emit:t}){const a=e,l=t,r=k("simple"),s=k(!1),o=C(()=>a.trial.progress.total),i=C(()=>a.trial.configurationSnapshots?.length||0),c=C(()=>a.trial.totalCombinations||0),d=C(()=>{const e=.05*c.value+.3*i.value;return Math.round(15+e)}),u=C(()=>{const e=.5*o.value;return Math.round(10+e)}),p=C(()=>{const e=.05*c.value+.2*i.value;return Math.round(12+e)}),m=C(()=>{const e=a.trial.name.toLowerCase().replace(/\s+/g,"_"),t=(new Date).toISOString().split("T")[0];return`${e}_${r.value}_${t}.py`}),f=C(()=>{if("simple"===r.value){return 300+(c.value+10*i.value)}if("native"===r.value){return 250+(c.value+8*i.value)}return 200+15*o.value});async function v(){s.value=!0;try{const e={mode:r.value};await Mt.downloadPythonScript(a.trial,e),l("exported",m.value),l("close")}catch(e){n.error("Export failed",e),alert("Export failed: "+(e instanceof Error?e.message:"Unknown error"))}finally{s.value=!1}}return(e,t)=>{const a=T("a-button"),n=T("a-tag"),l=T("a-radio"),g=T("a-radio-group"),h=T("a-typography-text");return b(),S(Z,{"model-value":!0,title:"Export Python Script",size:"full","onUpdate:modelValue":t[2]||(t[2]=t=>e.$emit("close"))},{footer:I(()=>[P(a,{onClick:t[0]||(t[0]=t=>e.$emit("close")),size:"large","data-testid":"btn-cancel-python-export","aria-label":"Cancel Python export"},{default:I(()=>t[3]||(t[3]=[E(" Cancel ")])),_:1,__:[3]}),P(a,{type:"primary",onClick:v,loading:s.value,size:"large","data-testid":"btn-confirm-python-export","data-mode":r.value,"aria-label":`Export Python script in ${r.value} mode`},{default:I(()=>t[4]||(t[4]=[E(" Export Script ")])),_:1,__:[4]},8,["loading","data-mode","aria-label"])]),default:I(()=>[y("div",$t,[y("h3",null,$(e.trial.name),1),y("div",Ot,[P(n,null,{default:I(()=>[E($(o.value)+" API calls",1)]),_:1}),P(n,null,{default:I(()=>[E($(i.value)+" configurations",1)]),_:1}),P(n,null,{default:I(()=>[E($(c.value)+" variable combinations",1)]),_:1})])]),y("div",Ft,[t[11]||(t[11]=y("h4",null,"Export Mode",-1)),P(g,{value:r.value,"onUpdate:value":t[1]||(t[1]=e=>r.value=e),class:"mode-options","data-testid":"radiogroup-export-mode","aria-label":"Select Python export mode"},{default:I(()=>[P(l,{value:"simple",class:"mode-radio","data-testid":"radio-mode-simple","aria-label":"Simple script mode"},{default:I(()=>[y("div",Rt,[t[5]||(t[5]=y("div",{class:"mode-title"},"Simple Script",-1)),t[6]||(t[6]=y("div",{class:"mode-description"}," Educational script with variables as lists. Easy to understand, modify, and extend. Perfect for learning how AI APIs work. ",-1)),P(n,{color:"blue",size:"small"},{default:I(()=>[E("~"+$(d.value)+"KB",1)]),_:1})])]),_:1}),P(l,{value:"literal",class:"mode-radio","data-testid":"radio-mode-literal","aria-label":"Literal reproduction mode"},{default:I(()=>[y("div",jt,[t[7]||(t[7]=y("div",{class:"mode-title"},"Literal Reproduction",-1)),t[8]||(t[8]=y("div",{class:"mode-description"}," Exact API calls pre-computed. Bit-for-bit reproduction of your experiment. Best for debugging and comparing results. ",-1)),P(n,{color:"blue",size:"small"},{default:I(()=>[E("~"+$(u.value)+"KB",1)]),_:1})])]),_:1}),P(l,{value:"native",class:"mode-radio","data-testid":"radio-mode-native","aria-label":"Native libraries mode"},{default:I(()=>[y("div",Dt,[t[9]||(t[9]=y("div",{class:"mode-title"},"Native Libraries",-1)),t[10]||(t[10]=y("div",{class:"mode-description"}," Uses official Python SDKs (openai, anthropic, ollama). Cleanest code, best for production use. Requires: pip install openai anthropic ollama ",-1)),P(n,{color:"green",size:"small"},{default:I(()=>[E("~"+$(p.value)+"KB",1)]),_:1})])]),_:1})]),_:1},8,["value"])]),t[13]||(t[13]=y("div",{class:"export-section"},[y("h4",null,"Output Format"),y("div",{class:"format-info"},[y("p",null,"Both scripts save results using pandas in your choice of format:"),y("ul",null,[y("li",null,[y("strong",null,"CSV"),E(" - Universal format, opens in Excel/Google Sheets")]),y("li",null,[y("strong",null,"Excel"),E(" - Native Excel format")]),y("li",null,[y("strong",null,"JSON"),E(" - For programmatic access")]),y("li",null,[y("strong",null,"Parquet"),E(" - Efficient compressed format")]),y("li",null,[y("strong",null,"HTML"),E(" - For web viewing")]),y("li",null,[y("strong",null,"Markdown"),E(" - For documentation")]),y("li",null,[y("strong",null,"Stata"),E(" - For statistical analysis")]),y("li",null,[y("strong",null,"Pickle"),E(" - Python native format")])])])],-1)),y("div",qt,[t[12]||(t[12]=y("h4",null,"Script Preview",-1)),y("div",Lt,[P(h,{code:"",class:"preview-filename"},{default:I(()=>[E($(m.value),1)]),_:1}),y("div",Ut,[P(n,{size:"small"},{default:I(()=>[E($(f.value)+" lines",1)]),_:1}),P(n,{size:"small"},{default:I(()=>[E($(r.value)+" mode",1)]),_:1})])])])]),_:1,__:[13]})}}}),zt={class:"api-call-modal"},Kt={class:"modal-header"},Gt={class:"modal-content"},Vt={class:"section"},Yt={class:"info-grid"},Ht={class:"info-item"},Jt={class:"call-id"},Wt={class:"info-item"},Xt={class:"info-item"},Qt={class:"info-item"},Zt={key:0,class:"info-item"},ea={key:1,class:"info-item"},ta={key:2,class:"info-item"},aa={class:"section"},na={class:"variables-detail"},la={class:"variable-value"},ra={key:0,class:"attributes-section"},sa={class:"attribute-items"},oa={class:"section"},ia={class:"prompt-display"},ca={key:0,class:"section"},da={key:0,class:"response-info"},ua={class:"info-grid"},pa={class:"info-item"},ma={class:"info-item"},fa={key:1,class:"result-content"},va={key:0,class:"error-result"},ga={class:"error-message"},ba={key:0,class:"error-raw"},ha={class:"error-response"},ya={key:1,class:"content-result"},_a={class:"content-display"},ka={class:"section"},Ca={class:"raw-data"},xa={key:1,class:"section"},wa={class:"raw-data"},Sa={class:"modal-footer"},Ia=e(v({__name:"APICallDetailModal",props:{apiCall:{},trial:{}},emits:["close"],setup(e){const t=e,a=C(()=>{if(!t.apiCall.request)return"No request data";const e=JSON.parse(JSON.stringify(t.apiCall.request));return e.headers&&Object.keys(e.headers).forEach(t=>{const a=t.toLowerCase();(a.includes("authorization")||a.includes("api-key")||a.includes("x-api-key")||a.includes("bearer"))&&(e.headers[t]="[REDACTED]")}),JSON.stringify(e,null,2)});function l(){return t.trial&&t.trial.configurationSnapshots[t.apiCall.configurationIndex]&&t.trial.configurationSnapshots[t.apiCall.configurationIndex].name||`Configuration ${t.apiCall.configurationIndex+1}`}function r(e){const t="string"==typeof e?new Date(e):e;return isNaN(t.getTime())?"Invalid date":t.toLocaleString()}async function s(){const e={id:t.apiCall.id,status:t.apiCall.status,configuration:l(),variables:t.apiCall.variables,variableAttributes:t.apiCall.variableAttributes,prompt:t.apiCall.prompt,request:JSON.parse(a.value),response:t.apiCall.response,result:t.apiCall.result,created:t.apiCall.created,completed:t.apiCall.completed},r=JSON.stringify(e,null,2);try{if(navigator.clipboard&&navigator.clipboard.writeText)return await navigator.clipboard.writeText(r),void i.success("Details copied to clipboard!");const e=document.createElement("textarea");e.value=r,e.style.position="fixed",e.style.left="-999999px",e.style.top="-999999px",document.body.appendChild(e),e.focus(),e.select();const t=document.execCommand("copy");if(document.body.removeChild(e),!t)throw new Error("execCommand failed");i.success("Details copied to clipboard!")}catch(s){n.error("Failed to copy to clipboard",s),prompt("Copy this text manually:",r)}}return(e,t)=>{const n=T("a-button");return b(),g("div",{class:"modal-overlay",onClick:t[2]||(t[2]=j(t=>e.$emit("close"),["self"]))},[y("div",zt,[y("div",Kt,[t[3]||(t[3]=y("h2",null,"API Call Details",-1)),y("button",{class:"close-btn",onClick:t[0]||(t[0]=t=>e.$emit("close")),"data-testid":"btn-close-api-call-modal","aria-label":"Close API call details"},"×")]),y("div",Gt,[y("div",Vt,[t[11]||(t[11]=y("h3",null,"Overview",-1)),y("div",Yt,[y("div",Ht,[t[4]||(t[4]=y("label",null,"Call ID:",-1)),y("span",Jt,$(e.apiCall.id),1)]),y("div",Wt,[t[5]||(t[5]=y("label",null,"Status:",-1)),y("span",{class:D(["status-badge",e.apiCall.status])},$(e.apiCall.status),3)]),y("div",Xt,[t[6]||(t[6]=y("label",null,"Configuration:",-1)),y("span",null,$(l()),1)]),y("div",Qt,[t[7]||(t[7]=y("label",null,"Created:",-1)),y("span",null,$(r(e.apiCall.created)),1)]),e.apiCall.completed?(b(),g("div",Zt,[t[8]||(t[8]=y("label",null,"Completed:",-1)),y("span",null,$(r(e.apiCall.completed)),1)])):h("",!0),e.apiCall.completed?(b(),g("div",ea,[t[9]||(t[9]=y("label",null,"Duration:",-1)),y("span",null,$((o=e.apiCall.completed.getTime()-e.apiCall.created.getTime(),o<1e3?`${o}ms`:`${(o/1e3).toFixed(1)}s`)),1)])):h("",!0),e.apiCall.response?.latencyMs?(b(),g("div",ta,[t[10]||(t[10]=y("label",null,"API Latency:",-1)),y("span",null,$(e.apiCall.response.latencyMs)+"ms",1)])):h("",!0)])]),y("div",aa,[t[13]||(t[13]=y("h3",null,"Variables",-1)),y("div",na,[(b(!0),g(M,null,N(Object.entries(e.apiCall.variables),([e,t])=>(b(),g("div",{key:e,class:"variable-item"},[y("label",null,$(e)+":",1),y("span",la,$(t),1)]))),128))]),e.apiCall.variableAttributes&&Object.keys(e.apiCall.variableAttributes).length>0?(b(),g("div",ra,[t[12]||(t[12]=y("h4",null,"Variable Attributes",-1)),(b(!0),g(M,null,N(Object.entries(e.apiCall.variableAttributes),([e,t])=>(b(),g("div",{key:e,class:"attribute-group"},[y("h5",null,$(e),1),y("div",sa,[(b(!0),g(M,null,N(Object.entries(t),([e,t])=>(b(),g("div",{key:e,class:"attribute-item"},[y("label",null,$(e)+":",1),y("span",null,$(t),1)]))),128))])]))),128))])):h("",!0)]),y("div",oa,[t[14]||(t[14]=y("h3",null,"Resolved Prompt",-1)),y("div",ia,$(e.apiCall.prompt),1)]),e.apiCall.response||e.apiCall.result?(b(),g("div",ca,[t[20]||(t[20]=y("h3",null,"Response",-1)),e.apiCall.response?(b(),g("div",da,[y("div",ua,[y("div",pa,[t[15]||(t[15]=y("label",null,"HTTP Status:",-1)),y("span",null,$(e.apiCall.response.status),1)]),y("div",ma,[t[16]||(t[16]=y("label",null,"Latency:",-1)),y("span",null,$(e.apiCall.response.latencyMs)+"ms",1)])])])):h("",!0),e.apiCall.result?(b(),g("div",fa,[!1===e.apiCall.result.success?(b(),g("div",va,[t[18]||(t[18]=y("h4",null,"Error",-1)),y("div",ga,$(e.apiCall.result.error),1),e.apiCall.response?(b(),g("div",ba,[t[17]||(t[17]=y("h5",null,"Raw Response:",-1)),y("pre",ha,$(JSON.stringify(e.apiCall.response,null,2)),1)])):h("",!0)])):h("",!0),e.apiCall.result.content?(b(),g("div",ya,[t[19]||(t[19]=y("h4",null,"Content",-1)),y("div",_a,$(e.apiCall.result.content),1)])):h("",!0)])):h("",!0)])):h("",!0),y("div",ka,[t[21]||(t[21]=y("h3",null,"Raw Request",-1)),y("pre",Ca,$(a.value),1)]),e.apiCall.response?(b(),g("div",xa,[t[22]||(t[22]=y("h3",null,"Raw Response",-1)),y("pre",wa,$(JSON.stringify(e.apiCall.response,null,2)),1)])):h("",!0)]),y("div",Sa,[P(n,{onClick:t[1]||(t[1]=t=>e.$emit("close")),size:"large",class:"footer-button","data-testid":"btn-close-modal-footer","aria-label":"Close modal"},{default:I(()=>t[23]||(t[23]=[E(" Close ")])),_:1,__:[23]}),P(n,{type:"primary",onClick:s,size:"large",class:"footer-button footer-button-primary","data-testid":"btn-copy-api-call-details","aria-label":"Copy API call details to clipboard"},{default:I(()=>t[24]||(t[24]=[E(" Copy Details ")])),_:1,__:[24]})])])]);var o}}}),[["__scopeId","data-v-d79e18d5"]]);function Pa(e,t){const a=new Set,n=new Set,l=new Set;e.forEach(e=>{e.variables&&Object.keys(e.variables).forEach(e=>a.add(e)),e.variableAttributes&&Object.values(e.variableAttributes).forEach(e=>{e&&Object.keys(e).forEach(e=>n.add(e))})});const r=Array.from(a).sort(),s=Array.from(n).sort(),o=Array.from(l).sort(),i=[];t?.designSnapshot?.extractPattern&&i.push("extracted_value");const c=["success","refused",...i,...o];return{categorical:[...r,...s,"model","status","error_type"],numeric:["response_time","total_tokens","prompt_tokens","completion_tokens",...i].sort(),extracted:c}}function Ta(e,t,a){switch(t){case"model":if(a&&e.configurationIndex<a.configurationSnapshots.length){return a.configurationSnapshots[e.configurationIndex].modelId||"Unknown"}return"Unknown";case"status":return e.status;case"response_time":return e.response?.latencyMs||0;case"total_tokens":if(e.response?.body?.usage){const t=e.response.body.usage;return t.total_tokens||t.prompt_tokens+t.completion_tokens||0}return 0;case"prompt_tokens":return e.response?.body?.usage?.prompt_tokens||e.response?.body?.usage?.input_tokens||0;case"completion_tokens":return e.response?.body?.usage?.completion_tokens||e.response?.body?.usage?.output_tokens||0;case"error_type":return e.result?.errorType||(!1===e.result?.success?"api_error":"success");case"success":return e.result?.success?1:0;case"refused":return e.result?.refused?1:0;case"extracted_value":if(e.result?.success&&void 0!==e.result?.content){const t=String(e.result.content),a=parseFloat(t);return isNaN(a)?t:a}return null}if(void 0!==e.variables?.[t])return e.variables[t];if(e.variableAttributes)for(const n of Object.keys(e.variableAttributes)){const a=e.variableAttributes[n];if(a&&void 0!==a[t])return a[t]}return null}const Ea={count:{label:"Count",calculate:e=>e.length,format:e=>e.toString(),needsNumeric:!1},sum:{label:"Sum",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?t.reduce((e,t)=>e+t,0):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mean:{label:"Mean",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?t.reduce((e,t)=>e+t,0)/t.length:null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},median:{label:"Median",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(0===t.length)return null;const a=[...t].sort((e,t)=>e-t),n=Math.floor(a.length/2);return a.length%2==0?(a[n-1]+a[n])/2:a[n]},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mode:{label:"Mode",calculate:e=>{if(0===e.length)return null;const t=new Map;e.forEach(e=>t.set(e,(t.get(e)||0)+1));let a=0,n=null;return t.forEach((e,t)=>{e>a&&(a=e,n=t)}),{value:n,count:a,total:e.length}},format:e=>e?`${e.value} (${e.count}/${e.total})`:"-",needsNumeric:!1},variance:{label:"Variance",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(t.length<=1)return null;const a=t.reduce((e,t)=>e+t,0)/t.length;return t.reduce((e,t)=>e+Math.pow(t-a,2),0)/(t.length-1)},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},std_dev:{label:"Std Dev",calculate:e=>{const t=Ea.variance.calculate(e);return null!==t?Math.sqrt(t):null},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},min:{label:"Min",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?Math.min(...t):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},max:{label:"Max",calculate:e=>{const t=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return t.length>0?Math.max(...t):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},success_rate:{label:"Success Rate",calculate:(e,t)=>{const a=t.filter(e=>e.result?.success).length;return t.length>0?a/t.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},refusal_rate:{label:"Refusal Rate",calculate:(e,t)=>{const a=t.filter(e=>e.result?.refused).length;return t.length>0?a/t.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},avg_time:{label:"Avg Time (ms)",calculate:(e,t)=>{const a=t.filter(e=>e.response?.latencyMs).map(e=>e.response.latencyMs);return a.length>0?a.reduce((e,t)=>e+t,0)/a.length:null},format:e=>e?`${Math.round(e)}ms`:"-",needsNumeric:!1,usesApiCalls:!0}};function Aa(e,t){if(!e||null===e.value)return"-";return Ea[t].format(e.value)}const Ma={"blue-subtle":{name:"Blue (Subtle)",colors:["rgba(59, 130, 246, 0.1)","rgba(59, 130, 246, 0.3)","rgba(59, 130, 246, 0.7)"]},"green-red":{name:"Green-Red",colors:["#dc2626","#fbbf24","#10b981"]},"blue-yellow":{name:"Blue-Yellow",colors:["#1e40af","#3b82f6","#fbbf24"]},"purple-orange":{name:"Purple-Orange",colors:["#7c3aed","#a855f7","#ff9500"]},grayscale:{name:"Grayscale",colors:["#f3f4f6","#9ca3af","#374151"]},viridis:{name:"Viridis",colors:["#440154","#482878","#3e4989","#31688e","#26828e","#1f9e89","#35b779","#6ece58","#b5de2b","#fde725"]},inferno:{name:"Inferno",colors:["#000004","#1b0c41","#4a0c6b","#781c6d","#a52c60","#cf4446","#ed6925","#fb9b06","#f7d13d","#fcffa4"]},magma:{name:"Magma",colors:["#000004","#180f3d","#440f76","#721f81","#9e2f7f","#cd4071","#f1605d","#fd9668","#feca8d","#fcfdbf"]},plasma:{name:"Plasma",colors:["#0d0887","#46039f","#7201a8","#9c179e","#bd3786","#d8576b","#ed7953","#fb9f3a","#fdca26","#f0f921"]}};function Na(e,t){if(0===t.length)return"transparent";if(1===t.length)return t[0];e=Math.max(0,Math.min(1,e));const a=1/(t.length-1),n=Math.floor(e/a),l=e%a/a;return $a(t[Math.min(n,t.length-1)],t[Math.min(n+1,t.length-1)],l)}function $a(e,t,a){if(e.startsWith("rgba")&&t.startsWith("rgba")){const n=e=>{const t=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);return t?{r:parseInt(t[1]),g:parseInt(t[2]),b:parseInt(t[3]),a:t[4]?parseFloat(t[4]):1}:null},l=n(e),r=n(t);if(l&&r){return`rgba(${Math.round(l.r+(r.r-l.r)*a)}, ${Math.round(l.g+(r.g-l.g)*a)}, ${Math.round(l.b+(r.b-l.b)*a)}, ${(l.a+(r.a-l.a)*a).toFixed(2)})`}}if(e.startsWith("rgba")||t.startsWith("rgba"))return a<.5?e:t;const n=e.replace("#",""),l=t.replace("#",""),r=parseInt(n.substr(0,2),16),s=parseInt(n.substr(2,2),16),o=parseInt(n.substr(4,2),16),i=parseInt(l.substr(0,2),16),c=parseInt(l.substr(2,2),16),d=parseInt(l.substr(4,2),16),u=Math.round(r+(i-r)*a),p=Math.round(s+(c-s)*a),m=Math.round(o+(d-o)*a);return`#${u.toString(16).padStart(2,"0")}${p.toString(16).padStart(2,"0")}${m.toString(16).padStart(2,"0")}`}function Oa(e){let t,a,n;if(e.startsWith("rgba")){const l=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);if(!l)return!1;t=parseInt(l[1]),a=parseInt(l[2]),n=parseInt(l[3])}else{const l="#"===e.charAt(0)?e.substring(1,7):e;t=parseInt(l.substring(0,2),16),a=parseInt(l.substring(2,4),16),n=parseInt(l.substring(4,6),16)}const l=[t/255,a/255,n/255].map(e=>e<=.03928?e/12.92:Math.pow((e+.055)/1.055,2.4));return.2126*l[0]+.7152*l[1]+.0722*l[2]<=.179}function Fa(e){return Oa(e)?"#FFFFFF":"#000000"}function Ra(e,t,a){const{colorScales:n,interpolateColor:l,getContrastColor:r}={colorScales:Ma,interpolateColor:Na,interpolateBetweenColors:$a,colorIsDarkAdvanced:Oa,getContrastColor:Fa};function s(e){if("number"==typeof e)return e;if("string"==typeof e){const t=parseFloat(e);return isNaN(t)?null:t}return null}return{getCellStyle:function(o,i,c){if(!o||null===o.value||"number"!=typeof o.value)return{};const d=n[t.value];if(!d)return{};const u=function(t,n,l){const r=s(t.value);if(null===r)return.5;if("global"===a.value){const t=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(t.length>0){const e=Math.min(...t),a=Math.max(...t);if(a!==e)return(r-e)/(a-e)}}else if("column"===a.value){const t=e.value.rows.map(e=>e.cells[l]).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(t.length>0){const e=Math.min(...t),a=Math.max(...t);if(a!==e)return(r-e)/(a-e)}}else if("row"===a.value){const t=e.value.rows.find(e=>e.label===n);if(t){const e=t.cells.filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(e.length>0){const t=Math.min(...e),a=Math.max(...e);if(a!==t)return(r-t)/(a-t)}}}return.5}(o,i,c),p=l(u,d.colors);return{backgroundColor:`${p} !important`,color:`${r(p)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},getSummaryStyle:function(a){if(!a||null===a.value||"number"!=typeof a.value)return{};const o=n[t.value];if(!o)return{};let i=.5;const c=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(c.length>0){const e=Math.min(...c),t=Math.max(...c),n=s(a.value);null!==n&&(i=t!==e?(n-e)/(t-e):.5)}const d=l(i,o.colors);return{backgroundColor:`${d} !important`,color:`${r(d)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},styleKey:C(()=>`${t.value}-${a.value}`)}}const ja={class:"pivot-config"},Da={class:"config-row"},qa={class:"config-group"},La=["value","aria-label"],Ua={label:"Categorical"},Ba=["value"],za={class:"config-group"},Ka=["value","aria-label"],Ga={label:"Categorical"},Va=["value"],Ya={class:"config-group"},Ha=["value","aria-label"],Ja={label:"Extracted Values"},Wa=["value"],Xa={label:"Numeric Fields"},Qa=["value"],Za={class:"config-group"},en=["value","aria-label"],tn=e(v({__name:"PivotConfiguration",props:{config:{},availableFields:{}},emits:["update-config"],setup(e,{emit:t}){const a=t;function n(e,t){a("update-config",e,t)}function l(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}return(e,t)=>(b(),g("div",ja,[y("div",Da,[y("div",qa,[t[4]||(t[4]=y("label",{for:"pivot-row-field"},"Rows (Group by):",-1)),y("select",{id:"pivot-row-field",value:e.config.rowField,"aria-label":"Group rows by "+l(e.config.rowField),onChange:t[0]||(t[0]=e=>n("rowField",e.target.value))},[y("optgroup",Ua,[(b(!0),g(M,null,N(e.availableFields.categorical,e=>(b(),g("option",{key:e,value:e},$(l(e)),9,Ba))),128))])],40,La)]),y("div",za,[t[5]||(t[5]=y("label",{for:"pivot-column-field"},"Columns (Group by):",-1)),y("select",{id:"pivot-column-field",value:e.config.columnField,"aria-label":"Group columns by "+l(e.config.columnField),onChange:t[1]||(t[1]=e=>n("columnField",e.target.value))},[y("optgroup",Ga,[(b(!0),g(M,null,N(e.availableFields.categorical,e=>(b(),g("option",{key:e,value:e},$(l(e)),9,Va))),128))])],40,Ka)]),y("div",Ya,[t[6]||(t[6]=y("label",{for:"pivot-value-field"},"Values (Aggregate):",-1)),y("select",{id:"pivot-value-field",value:e.config.valueField,"aria-label":"Aggregate "+e.config.valueField+" values",onChange:t[2]||(t[2]=e=>n("valueField",e.target.value))},[y("optgroup",Ja,[(b(!0),g(M,null,N(e.availableFields.extracted,e=>(b(),g("option",{key:e,value:e},$(e),9,Wa))),128))]),y("optgroup",Xa,[(b(!0),g(M,null,N(e.availableFields.numeric,e=>(b(),g("option",{key:e,value:e},$(l(e)),9,Qa))),128))])],40,Ha)]),y("div",Za,[t[8]||(t[8]=y("label",{for:"pivot-aggregation"},"Aggregation:",-1)),y("select",{id:"pivot-aggregation",value:e.config.aggregation,"aria-label":"Aggregation method: "+e.config.aggregation,onChange:t[3]||(t[3]=e=>n("aggregation",e.target.value))},t[7]||(t[7]=[q('<optgroup label="Statistical" data-v-efb8a7c2><option value="mean" data-v-efb8a7c2>Mean</option><option value="median" data-v-efb8a7c2>Median</option><option value="variance" data-v-efb8a7c2>Variance</option><option value="std_dev" data-v-efb8a7c2>Std Dev</option><option value="min" data-v-efb8a7c2>Min</option><option value="max" data-v-efb8a7c2>Max</option></optgroup><optgroup label="Frequency" data-v-efb8a7c2><option value="count" data-v-efb8a7c2>Count</option><option value="mode" data-v-efb8a7c2>Mode</option></optgroup><optgroup label="Performance" data-v-efb8a7c2><option value="success_rate" data-v-efb8a7c2>Success Rate</option><option value="refusal_rate" data-v-efb8a7c2>Refusal Rate</option><option value="avg_time" data-v-efb8a7c2>Avg Time</option></optgroup>',3)]),40,en)])])]))}}),[["__scopeId","data-v-efb8a7c2"]]),an={class:"heatmap-controls"},nn={class:"color-scale-selector"},ln=["value","aria-label"],rn={class:"gradient-mode-selector"},sn={class:"gradient-toggle",role:"group","aria-label":"Gradient mode selector"},on=["aria-pressed"],cn=["aria-pressed"],dn=["aria-pressed"],un=["title","aria-label"],pn=e(v({__name:"PivotHeatmapControls",props:{selectedColorScale:{},gradientMode:{},isFullscreen:{type:Boolean}},emits:["update-color-scale","update-gradient-mode","toggle-fullscreen"],setup(e,{emit:t}){const a=t;function n(e){const t=e.target.value;a("update-color-scale",t)}function l(e){a("update-gradient-mode",e)}return(e,t)=>(b(),g("div",an,[y("div",nn,[t[5]||(t[5]=y("label",{for:"heatmap-color-scale"},"Color Scale:",-1)),y("select",{id:"heatmap-color-scale",value:e.selectedColorScale,"aria-label":"Color scale: "+e.selectedColorScale,onChange:n},t[4]||(t[4]=[q('<option value="blue-subtle" data-v-4b4f9d62>Blue (Subtle)</option><option value="green-red" data-v-4b4f9d62>Green-Red (Success)</option><option value="blue-yellow" data-v-4b4f9d62>Blue-Yellow (Performance)</option><option value="purple-orange" data-v-4b4f9d62>Purple-Orange (General)</option><option value="viridis" data-v-4b4f9d62>Viridis</option><option value="inferno" data-v-4b4f9d62>Inferno</option><option value="magma" data-v-4b4f9d62>Magma</option><option value="plasma" data-v-4b4f9d62>Plasma</option><option value="grayscale" data-v-4b4f9d62>Grayscale</option>',9)]),40,ln)]),y("div",rn,[t[6]||(t[6]=y("label",null,"Gradient Mode:",-1)),y("div",sn,[y("button",{type:"button",class:D(["toggle-btn",{active:"global"===e.gradientMode}]),"aria-pressed":"global"===e.gradientMode,onClick:t[0]||(t[0]=e=>l("global"))}," Global ",10,on),y("button",{type:"button",class:D(["toggle-btn",{active:"column"===e.gradientMode}]),"aria-pressed":"column"===e.gradientMode,onClick:t[1]||(t[1]=e=>l("column"))}," Per Column ",10,cn),y("button",{type:"button",class:D(["toggle-btn",{active:"row"===e.gradientMode}]),"aria-pressed":"row"===e.gradientMode,onClick:t[2]||(t[2]=e=>l("row"))}," Per Row ",10,dn)])]),y("button",{type:"button",class:"fullscreen-btn",title:e.isFullscreen?"Exit Fullscreen":"Enter Fullscreen","aria-label":e.isFullscreen?"Exit fullscreen mode":"Enter fullscreen mode",onClick:t[3]||(t[3]=t=>e.$emit("toggle-fullscreen"))},$(e.isFullscreen?"⊟":"⊞"),9,un)]))}}),[["__scopeId","data-v-4b4f9d62"]]),mn={class:"filters-row"},fn={key:0,class:"filter-group"},vn=["value"],gn=["for"],bn=["id","onUpdate:modelValue","aria-label"],hn={value:""},yn=["value"],_n={key:1,class:"filter-group"},kn=["value"],Cn={class:"table-view"},xn={key:0,class:"empty-state","data-testid":"empty-data-message"},wn={key:1,class:"error-state","data-testid":"invalid-aggregation-error"},Sn={key:2,class:"pivot-table-container"},In={class:"pivot-table-grid responsive-table",role:"table"},Pn={role:"row"},Tn={class:"corner-cell",role:"columnheader"},En={key:0,class:"total-header",role:"columnheader"},An={class:"row-header",role:"rowheader"},Mn=["data-testid","title","aria-label","role","onClick","onKeydown"],Nn={key:0,class:"cell-content"},$n=["title"],On={class:"cell-value"},Fn={class:"error-message"},Rn={key:1},jn=e(v({__name:"PivotTableCore",props:{apiCalls:{},trial:{default:null},config:{},maxTableRows:{default:1e4},showTotals:{type:Boolean,default:!0}},emits:["config-change","cell-click"],setup(e,{emit:t}){const a=e,l=t,r=k(!1),s=k("viridis"),o=k("global"),i=k({rowField:a.config?.rowField||"",columnField:a.config?.columnField||"",valueField:a.config?.valueField||"",aggregation:a.config?.aggregation||"mean"});L(()=>a.config,e=>{e&&Object.assign(i.value,e)},{deep:!0});const c=k({}),d=k([]),u=C(()=>Object.values(c.value).some(e=>""!==e)),p=U(Pa(a.apiCalls,a.trial));let m=0;L(()=>a.apiCalls,e=>{if(0===e.length||0===m||e.length-m>=10){const t=d.value.length>0||u.value?d.value:e;p.value=Pa(t,a.trial),m=e.length}},{immediate:!0});const f=U({});let v=0;L(()=>a.apiCalls.length,e=>{(0===e||0===v||e-v>=5)&&((()=>{if(0===a.apiCalls.length)return void(f.value={});const e={};a.apiCalls.forEach(t=>{if(a.trial&&t.configurationIndex<a.trial.configurationSnapshots.length){const n=a.trial.configurationSnapshots[t.configurationIndex].modelId||"Unknown";e.model||(e.model=new Set),e.model.add(n)}t.status&&(e.status||(e.status=new Set),e.status.add(t.status)),t.variables&&Object.entries(t.variables).forEach(([t,a])=>{a&&String(a).trim()&&(e[t]||(e[t]=new Set),e[t].add(String(a)))})});const t={};Object.entries(e).forEach(([e,a])=>{t[e]=Array.from(a).sort()}),f.value=t})(),v=e)},{immediate:!0});const _=C(()=>{const{model:e,status:t,...a}=f.value;return a});function x(){d.value=a.apiCalls.filter(e=>{if(c.value.model&&""!==c.value.model){if(!a.trial||e.configurationIndex>=a.trial.configurationSnapshots.length)return!1;if((a.trial.configurationSnapshots[e.configurationIndex].modelId||"Unknown")!==c.value.model)return!1}if(c.value.status&&""!==c.value.status&&e.status!==c.value.status)return!1;for(const[t,a]of Object.entries(c.value))if(a&&""!==a&&"model"!==t&&"status"!==t){const n=e.variables?.[t];if(n!==a)return!1}return!0})}function S(){c.value={},x()}L(()=>a.apiCalls,()=>{u.value?x():d.value=a.apiCalls},{immediate:!0});const I=C(()=>{const e=d.value.length>0||u.value?d.value:a.apiCalls;return 0===e.length?{rows:[],columns:[],totals:[],grandTotal:{value:0,count:0,apiCalls:[],rawValues:[]}}:function(e,t,a){const l=new Map,r=new Set,s=new Set;e.forEach(e=>{const n=String(Ta(e,t.rowField,a)||"Unknown"),o=String(Ta(e,t.columnField,a)||"Unknown");r.add(n),s.add(o),l.has(n)||l.set(n,new Map),l.get(n).has(o)||l.get(n).set(o,[]),l.get(n).get(o).push(e)});const o=e=>e.every(e=>!isNaN(Number(e))&&""!==e.trim())?e.sort((e,t)=>Number(e)-Number(t)):e.sort(),i=o(Array.from(r)),c=o(Array.from(s)),d=Ea[t.aggregation];function u(e){const l=e.map(e=>Ta(e,t.valueField,a));if(!d||"function"!=typeof d.calculate)return n.error("Invalid aggregation function:",t.aggregation,d),{value:null,count:e.length,apiCalls:e,rawValues:l,error:"Invalid aggregation function"};const r={nonNumeric:0,nullUndefined:0};return d.needsNumeric&&(r.nonNumeric=l.filter(e=>"number"!=typeof e).length),r.nullUndefined=l.filter(e=>null==e).length,{value:d.usesApiCalls?d.calculate(l,e):d.calculate(l),count:e.length,apiCalls:e,rawValues:l,excludedCounts:r}}const p=i.map(e=>{const t=[],a=[];return c.forEach(n=>{const r=l.get(e)?.get(n)||[];t.push(r.length>0?u(r):null),a.push(...r)}),{label:e,cells:t,total:u(a)}}),m=c.map(e=>{const t=[];return i.forEach(a=>{const n=l.get(a)?.get(e)||[];t.push(...n)}),u(t)});return{rows:p,columns:c,totals:m,grandTotal:u(e)}}(e,i.value,a.trial)}),T=C(()=>I.value.rows),{getCellStyle:E,getSummaryStyle:O,styleKey:F}=Ra(I,s,o);function R(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}function q(e,t,a){if(!a)return`${e} × ${t}: No data`;let n=`${e} × ${t}: ${Aa(a,i.value.aggregation)} (${a.count} calls)`;if(a.excludedCounts){const e=[];a.excludedCounts.nonNumeric>0&&e.push(`${a.excludedCounts.nonNumeric} non-numeric responses excluded`),a.excludedCounts.nullUndefined>0&&e.push(`${a.excludedCounts.nullUndefined} null/empty responses`),e.length>0&&(n+=` | ${e.join(", ")}`)}return a.error&&(n+=` - ERROR: ${a.error}`),n}function Y(e,t,a){if(!a)return`${e} by ${t}: No data`;const n=Aa(a,i.value.aggregation);return a.error?`${e} by ${t}: ${n} with data integrity error: ${a.error}`:`${e} by ${t}: ${n} from ${a.count} API calls`}function H(e,t){"rowField"!==e&&"columnField"!==e&&"valueField"!==e&&"aggregation"!==e||(i.value[e]=t),l("config-change",{...i.value})}function J(e,t,a){a&&l("cell-click",{row:e,column:t,cell:a})}function W(){r.value=!r.value,r.value?document.body.style.overflow="hidden":document.body.style.overflow=""}return w(()=>{r.value&&(document.body.style.overflow="")}),L([p,()=>a.apiCalls.length],([e])=>{a.apiCalls.length>0&&(!i.value.rowField||""===i.value.rowField)&&e.categorical.length>0&&(i.value.rowField=e.categorical.find(e=>"model"!==e&&"status"!==e&&"error_type"!==e)||e.categorical[0]||"model",i.value.columnField=i.value.columnField||"model",i.value.valueField=i.value.valueField||"success",i.value.aggregation=i.value.aggregation||"mean",l("config-change",{...i.value}))},{immediate:!0}),(e,t)=>(b(),g("div",{class:D(["pivot-table-core",{fullscreen:r.value}])},[B([p.value,i.value],()=>(b(),g("div",null,[P(tn,{config:i.value,"available-fields":p.value,onUpdateConfig:H},null,8,["config","available-fields"])])),t,0),P(pn,{"selected-color-scale":s.value,"gradient-mode":o.value,"is-fullscreen":r.value,onUpdateColorScale:t[1]||(t[1]=e=>s.value=e),onUpdateGradientMode:t[2]||(t[2]=e=>o.value=e),onToggleFullscreen:W},null,8,["selected-color-scale","gradient-mode","is-fullscreen"]),Object.keys(f.value).length>0?B([f.value,c.value],()=>(b(),g("div",{key:0,class:"data-filters"},[y("div",mn,[f.value.model&&f.value.model.length>1?(b(),g("div",fn,[t[7]||(t[7]=y("label",{for:"filter-model",class:"filter-label"},"Model:",-1)),G(y("select",{id:"filter-model","onUpdate:modelValue":t[3]||(t[3]=e=>c.value.model=e),class:"filter-select","aria-label":"Filter by model",onChange:x},[t[6]||(t[6]=y("option",{value:""},"All Models",-1)),(b(!0),g(M,null,N(f.value.model,e=>(b(),g("option",{key:e,value:e},$(e),9,vn))),128))],544),[[V,c.value.model]])])):h("",!0),(b(!0),g(M,null,N(_.value,(e,t)=>(b(),g("div",{key:t,class:"filter-group"},[y("label",{for:`filter-${t}`,class:"filter-label"},$(R(String(t)))+": ",9,gn),G(y("select",{id:`filter-${t}`,"onUpdate:modelValue":e=>c.value[t]=e,class:"filter-select","aria-label":`Filter by ${R(String(t))}`,onChange:x},[y("option",hn,"All "+$(R(String(t))),1),(b(!0),g(M,null,N(e,e=>(b(),g("option",{key:e,value:e},$(e),9,yn))),128))],40,bn),[[V,c.value[t]]])]))),128)),f.value.status&&f.value.status.length>1?(b(),g("div",_n,[t[9]||(t[9]=y("label",{for:"filter-status",class:"filter-label"},"Status:",-1)),G(y("select",{id:"filter-status","onUpdate:modelValue":t[4]||(t[4]=e=>c.value.status=e),class:"filter-select","aria-label":"Filter by status",onChange:x},[t[8]||(t[8]=y("option",{value:""},"All Statuses",-1)),(b(!0),g(M,null,N(f.value.status,e=>(b(),g("option",{key:e,value:e},$(e),9,kn))),128))],544),[[V,c.value.status]])])):h("",!0),u.value?(b(),g("button",{key:2,type:"button",class:"clear-filters-btn",title:"Clear all filters","aria-label":"Clear all filters",onClick:S}," Clear Filters ")):h("",!0)])])),t,5):h("",!0),y("div",Cn,[0===a.apiCalls.length?(b(),g("div",xn,t[10]||(t[10]=[y("p",null,"No data available for pivot table analysis.",-1)]))):i.value.aggregation in A(Ea)?(b(),g("div",Sn,[y("table",In,[y("thead",null,[y("tr",Pn,[y("th",Tn,$(R(i.value.rowField)||"Items")+" / "+$(R(i.value.columnField)||"Aggregated"),1),(b(!0),g(M,null,N(I.value.columns,e=>(b(),g("th",{key:e,class:"column-header",role:"columnheader"},$(e),1))),128)),i.value.columnField&&e.showTotals?(b(),g("th",En," Total ")):h("",!0)])]),y("tbody",null,[(b(!0),g(M,null,N(T.value,t=>(b(),g("tr",{key:`${t.label}-${A(F)}`,class:"data-row",role:"row"},[y("td",An,$(t.label),1),(b(!0),g(M,null,N(t.cells,(e,a)=>(b(),g("td",{key:`${a}-${A(F)}`,class:D(["data-cell",{"error-cell":e?.error}]),"data-testid":e?.error?"pivot-cell-error":"pivot-cell",style:K(A(E)(e,t.label,a)),title:q(t.label,I.value.columns[a],e),"aria-label":Y(t.label,I.value.columns[a],e),role:e?.error?"alert":"cell",tabindex:"0",onClick:n=>J(t.label,I.value.columns[a],e),onKeydown:[z(n=>J(t.label,I.value.columns[a],e),["enter"]),z(j(n=>J(t.label,I.value.columns[a],e),["prevent"]),["space"])]},[e?.error?(b(),g("div",Nn,[y("span",{class:"error-indicator",title:e.error},"⚠️",8,$n),y("span",On,$(e?A(Aa)(e,i.value.aggregation):"-"),1),y("div",Fn,$(e.error),1)])):(b(),g("span",Rn,$(e?A(Aa)(e,i.value.aggregation):"-"),1))],46,Mn))),128)),i.value.columnField&&e.showTotals?(b(),g("td",{key:0,class:"total-cell",style:K(A(O)(t.total)),role:"cell"},$(A(Aa)(t.total,i.value.aggregation)),5)):h("",!0)]))),128)),i.value.rowField&&e.showTotals?(b(),g("tr",{key:`totals-${A(F)}`,class:"total-row",role:"row"},[t[12]||(t[12]=y("td",{class:"row-header",role:"rowheader"},"Total",-1)),(b(!0),g(M,null,N(I.value.totals,(e,t)=>(b(),g("td",{key:`total-${t}-${A(F)}`,class:"total-cell",style:K(A(O)(e)),role:"cell"},$(A(Aa)(e,i.value.aggregation)),5))),128)),i.value.columnField?(b(),g("td",{key:0,class:"grand-total-cell",style:K(A(O)(I.value.grandTotal)),role:"cell"},$(A(Aa)(I.value.grandTotal,i.value.aggregation)),5)):h("",!0)])):h("",!0)])])])):(b(),g("div",wn,[y("p",null,"Invalid aggregation function: "+$(i.value.aggregation),1),t[11]||(t[11]=y("p",null,"Please select a valid aggregation method.",-1))]))])],2))}}),[["__scopeId","data-v-ffa2e33b"]]);export{Ia as A,jn as P,ft as T,Pt as _,Bt as a,Nt as p};
