import{_ as e,u as a,a as t,l as n,p as l,w as r,P as s,E as o,e as i,m as c,x as d,A as u,y as p,z as m,G as f}from"./index-0dU5AN9h.js";import{d as v,r as g,V as b,Y as h,W as _,Z as y,k,a6 as C,a1 as x,_ as w,ae as S,f as I,c as P,o as T,b as E,G as A,u as M,F as $,a8 as N,a0 as O,ak as F,a9 as R,n as j,B as D,aa as q,a7 as U,w as L,s as B,al as z,ab as K,ad as G,q as V,ai as Y}from"./vendor-BARfHmiz.js";import{u as H}from"./designs-db-D0ajitFg.js";import{u as J}from"./variables-db-6zt3BIre.js";import{u as W}from"./models-db-CK0qIBeX.js";import{u as X}from"./EnvironmentalCostSummary-Cj112wWk.js";import{a as Q}from"./cost-formatting-Bv_drrqY.js";import{G as Z}from"./GenericModelSelectorModal-cbJk1Nin.js";import{_ as ee}from"./BaseModal.vue_vue_type_style_index_0_lang-DgBaQZ0f.js";const ae=v({__name:"ModelEditModal",props:{configuration:{},design:{}},emits:["close","save"],setup(e,{emit:a}){const t=e,n=a,l=g({...t.configuration,parameters:{...t.configuration.parameters}});function r(){n("save",l),n("close")}return(e,a)=>{const t=_("a-input"),n=_("a-form-item"),s=_("a-slider"),o=_("a-col"),i=_("a-input-number"),c=_("a-row"),d=_("a-form"),u=_("a-modal");return h(),b(u,{open:!0,title:"Edit Configuration",width:600,onOk:r,onCancel:a[3]||(a[3]=a=>e.$emit("close"))},{default:y(()=>[k(d,{layout:"vertical"},{default:y(()=>[k(n,{label:"Configuration Name"},{default:y(()=>[k(t,{value:l.name,"onUpdate:value":a[0]||(a[0]=e=>l.name=e),size:"large"},null,8,["value"])]),_:1}),k(c,{gutter:16},{default:y(()=>[k(o,{span:12},{default:y(()=>[k(n,{label:"Temperature"},{default:y(()=>[k(s,{value:l.parameters.temperature,"onUpdate:value":a[1]||(a[1]=e=>l.parameters.temperature=e),min:0,max:2,step:.1,marks:{0:"0",1:"1",2:"2"}},null,8,["value"])]),_:1})]),_:1}),k(o,{span:12},{default:y(()=>[k(n,{label:"Max Tokens"},{default:y(()=>[k(i,{value:l.parameters.max_tokens,"onUpdate:value":a[2]||(a[2]=e=>l.parameters.max_tokens=e),min:1,max:4096,size:"large",style:{width:"100%"}},null,8,["value"])]),_:1})]),_:1})]),_:1})]),_:1})]),_:1})}}}),te={class:"modal-footer"},ne={key:0,class:"footer-left"},le={class:"footer-actions"},re=e(v({__name:"ModalFooter",setup:e=>(e,a)=>(h(),C("div",te,[e.$slots.left?(h(),C("div",ne,[S(e.$slots,"left",{},void 0,!0)])):x("",!0),w("div",le,[S(e.$slots,"default",{},void 0,!0)])]))}),[["__scopeId","data-v-3a3879d0"]]),se={class:"streamlined-content"},oe={class:"content-section"},ie={class:"section-header"},ce={class:"section-body"},de={key:0,class:"design-selector","data-testid":"design-selector"},ue={key:0,class:"no-designs-state"},pe={class:"no-designs-content"},me={key:1,class:"design-list","data-testid":"design-list"},fe=["data-design-id","data-design-name","onClick"],ve={class:"design-header"},ge={class:"design-title-section"},be={class:"design-name"},he={key:0,class:"design-inline-description"},_e={class:"design-date"},ye=["innerHTML"],ke={class:"design-stats"},Ce={class:"stat-item"},xe={class:"stat-value"},we={class:"stat-item"},Se={class:"stat-value"},Ie={class:"stat-item"},Pe={class:"stat-value"},Te={key:1,class:"selected-design-with-template"},Ee={class:"unified-header"},Ae={class:"combinations-count"},Me={class:"header-controls"},$e=["innerHTML"],Ne={key:0,class:"content-section","data-testid":"trial-config-section"},Oe={class:"section-body"},Fe={class:"trial-config-table"},Re={class:"config-header-row"},je={class:"config-trial-info"},De={class:"trial-name-section"},qe={class:"repeat-section"},Ue={class:"quick-add-row"},Le={class:"quick-add-section"},Be={class:"quick-add-buttons"},ze={key:0,class:"quick-cost"},Ke={class:"config-table","data-testid":"model-config-table"},Ge=["data-config-index","data-provider","data-model"],Ve={class:"col-model"},Ye={class:"model-name"},He={class:"model-provider"},Je={class:"col-params"},We={class:"params-text"},Xe={class:"col-calls"},Qe={class:"calls-breakdown"},Ze={class:"calls-value"},ea={class:"col-cost"},aa={class:"cost-breakdown"},ta={key:0,class:"cost-value"},na={key:1,class:"env-cost"},la={class:"col-total"},ra={class:"cost-breakdown"},sa={key:0,class:"cost-value total-cost"},oa={key:1,class:"env-cost"},ia={class:"col-actions"},ca={key:0,class:"table-summary-row"},da={class:"col-model"},ua={class:"summary-label"},pa={class:"col-calls"},ma={class:"summary-calls"},fa={class:"col-total"},va={key:0,class:"summary-cost"},ga=e(v({__name:"TrialCreationModal",props:{initialDesignId:{},trialToDuplicate:{},isEditMode:{type:Boolean}},emits:["close","created","created-and-started","export-trial"],setup(e,{emit:d}){const u=e,p=d,m=R(),f=H(),v=J(),g=a(),S=t(),{hasDataForModel:D}=X(),q=I(""),U=I(null),L=I([]),B=I(""),z=I(1),K=I(!1),G=I(!1),V=I(null);u.trialToDuplicate&&n.info("Duplicating trial",{trialName:u.trialToDuplicate.name});const Y=I(0),te=new Map,ne=I(!1),le=I(!1),ga=P(()=>S.financialCostsEnabled),ba=P(()=>{const e=W(),a=e=>S.hasApiKey(e),t=(a,t)=>!!e.enabledModels.find(e=>e.provider===a&&e.modelId===t&&e.enabled),n=[],r=new Set,s=[...g.trials].sort((e,a)=>new Date(a.created).getTime()-new Date(e.created).getTime());for(const p of s){if(n.length>=5)break;for(const e of p.configurationSnapshots||[]){if(n.length>=5)break;const s=`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`;if(!r.has(s)&&a(e.provider)&&t(e.provider,e.modelId)){const a=l.getParametersForModel(e.provider,e.modelId);if(!a)continue;if(Object.keys(e.parameters).some(e=>!(e in a)))continue;r.add(s),n.push({provider:e.provider,modelId:e.modelId,displayName:e.modelId,parameters:e.parameters,outputType:"text"})}}}const o=(e,a)=>{const t=l.getParametersForModel(e,a),n={},r=(e,a="")=>{Object.entries(e).forEach(([e,t])=>{const l=a?`${a}.${e}`:e;"object"===t.type&&t.properties?r(t.properties,l):void 0!==t.default&&(n[l]=t.default)})};r(t),n.temperature||n["options.temperature"]||(n.temperature=0);for(const[l,s]of Object.entries(t)){if(s.is_output_length&&!n[l]){n[l]=128;break}}return n},i=[{provider:"openai-chat",modelId:"gpt-4.1-nano",displayName:"gpt-4.1-nano",parameters:o("openai-chat","gpt-4.1-nano"),outputType:"text"},{provider:"openai-responses",modelId:"o4-mini",displayName:"o4-mini",parameters:o("openai-responses","o4-mini"),outputType:"text"},{provider:"anthropic",modelId:"claude-3-haiku-20240307",displayName:"claude-3-haiku-20240307",parameters:o("anthropic","claude-3-haiku-20240307"),outputType:"text"},{provider:"anthropic",modelId:"claude-4-sonnet-20250514",displayName:"claude-4-sonnet-20250514",parameters:o("anthropic","claude-4-sonnet-20250514"),outputType:"text"},{provider:"openrouter",modelId:"meta-llama/llama-3.1-8b-instruct",displayName:"meta-llama/llama-3.1-8b-instruct",parameters:o("openrouter","meta-llama/llama-3.1-8b-instruct"),outputType:"text"},{provider:"openrouter",modelId:"mistralai/mistral-nemo",displayName:"mistralai/mistral-nemo",parameters:o("openrouter","mistralai/mistral-nemo"),outputType:"text"},{provider:"openrouter",modelId:"deepseek/deepseek-chat-v3-0324",displayName:"deepseek/deepseek-chat-v3-0324",parameters:o("openrouter","deepseek/deepseek-chat-v3-0324"),outputType:"text"}],c=new Set(n.map(e=>`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`));for(const l of i){const e=`${l.provider}:${l.modelId}:${JSON.stringify(l.parameters)}`;!c.has(e)&&a(l.provider)&&t(l.provider,l.modelId)&&n.push(l)}const d=[],u=new Set;for(const l of n){const e=`${l.provider}:${l.modelId}`;u.has(e)||(u.add(e),d.push(l))}return d}),ha=P(()=>{const e=f.designs;if(n.info("Designs available",{count:e.length}),!q.value)return e;const a=q.value.toLowerCase();return e.filter(e=>e.name.toLowerCase().includes(a)||e.promptTemplate.toLowerCase().includes(a))}),_a=P(()=>{if(!U.value)return 0;let e=1;for(const a of Object.values(U.value.variableBindings))if("direct"===a.type)e*=a.values?.length||1;else if(a.listId){const t=v.lists.find(e=>e.id===a.listId);e*=t?.itemCount||1}return e}),ya=P(()=>_a.value*L.value.length*z.value),ka=P(()=>{let e=0;for(const a of L.value)e+=qa(a)*_a.value*z.value;return e});function Ca(e){U.value=e,B.value=za(),ne.value=!0}function xa(){U.value=null,L.value=[],ne.value=!1}function wa(){p("close"),m.push({name:"designs",query:{create:"true"}})}function Sa(e){return Object.keys(e.variableBindings).length}function Ia(e){return e.replace(/\n+/g," ").replace(/\s+/g," ").trim()}function Pa(e){const a=new Date,t=a.getTime()-e.getTime(),n=Math.floor(t/864e5);if(0===n)return"Today";if(1===n)return"Yesterday";if(n<7)return`${n} days ago`;if(n<30){const e=Math.floor(n/7);return`${e} week${e>1?"s":""} ago`}return e.toLocaleDateString("en-US",{month:"short",day:"numeric",year:e.getFullYear()!==a.getFullYear()?"numeric":void 0})}function Ta(e){if(!e.variableBindings)return"1";let a=1;for(const t of Object.values(e.variableBindings))if("direct"===t.type&&t.values)a*=t.values.length;else if("list"===t.type&&t.listId){const e=v.lists.find(e=>e.id===t.listId);a*=e?.itemCount||1}return a>1e3?`${(a/1e3).toFixed(1)}k`:a.toString()}function Ea(e){const a=function(e){if(!e.variableBindings)return[{}];const a=[];for(const[t,n]of Object.entries(e.variableBindings))if("direct"===n.type&&n.values)a.push({name:t,values:n.values});else if("list"===n.type&&n.listId){const e=v.lists.find(e=>e.id===n.listId);if(e){let n=[];n="simple"===e.category&&e.values?e.values.slice(0,3):"attributed"===e.category&&e.items?e.items.slice(0,3).map(e=>e.value):[`${t}_sample`],a.push({name:t,values:n})}}if(0===a.length)return[{}];return a.map(e=>e.values).reduce((e,a)=>e.flatMap(e=>a.map(a=>[...e,a])),[[]]).map(e=>{const t={};return a.forEach((a,n)=>{t[a.name]=e[n]}),t})}(e);if(a.length<=1)return Aa(Ia(e.promptTemplate));const t=a[Y.value%a.length],n=["variable-highlight-blue","variable-highlight-green","variable-highlight-purple","variable-highlight-orange","variable-highlight-pink","variable-highlight-teal"];let l=e.promptTemplate;Object.keys(e.variableBindings||{}).forEach((e,a)=>{if(void 0!==t[e]){const r=new RegExp(`\\{\\{\\s*${e}\\s*\\}\\}`,"g"),s=`<span class="${n[a%n.length]}">${Aa(String(t[e]))}</span>`;l=l.replace(r,s)}});let r=Aa(l);return n.forEach(e=>{r=r.replace(new RegExp(`&lt;span class="${e}"&gt;`,"g"),`<span class="${e}">`).replace(/&lt;\/span&gt;/g,"</span>")}),Ia(r)}function Aa(e){const a=document.createElement("div");return a.textContent=e,a.innerHTML}function Ma(){ne.value=!ne.value}function $a(){le.value=!le.value}function Na(e){return L.value.some(a=>a.provider===e.provider&&a.modelId===e.modelId&&JSON.stringify(a.parameters)===JSON.stringify(e.parameters))}function Fa(e){const a=W().enabledModels.find(a=>a.provider===e.provider&&a.modelId===e.modelId);if(!a)return 0;const t=U.value?.tokenEstimate?.avgTokens||0,n=l.getParametersForModel(e.provider,e.modelId);let r=0;for(const[l,s]of Object.entries(n))if(s.is_output_length&&e.parameters[l]){r=e.parameters[l];break}if(0===t||0===r)return 0;return((a.capabilities?.inputCostPerToken||0)*t+(a.capabilities?.outputCostPerToken||0)*r)*_a.value*z.value}function Ra(e){const a=[];for(const[t,n]of Object.entries(e))null!=n&&a.push(`${t}=${n}`);return a.join(", ")||"Default settings"}function ja(e){L.value.push(e),G.value=!1,setTimeout(()=>{j(()=>{const e=[".streamlined-content",".ant-modal-body",".ant-modal-wrap .ant-modal-body"];for(const a of e){const e=document.querySelector(a);if(e){e.scrollTo({top:e.scrollHeight,behavior:"smooth"});break}}})},100)}function Da(e){null!==V.value&&(L.value[V.value]=e,V.value=null)}function qa(e){const a=W().enabledModels.find(a=>a.provider===e.provider&&a.modelId===e.modelId);if(!a)return 0;const t=U.value?.tokenEstimate?.avgTokens||0,n=l.getParametersForModel(e.provider,e.modelId);let r=0;for(const[l,s]of Object.entries(n))if(s.is_output_length&&e.parameters[l]){r=e.parameters[l];break}if(0===t||0===r)return 0;return(a.capabilities?.inputCostPerToken||0)*t+(a.capabilities?.outputCostPerToken||0)*r}function Ua(e){return qa(e)*_a.value*z.value}function La(e){return D(e.provider,e.modelId)}function Ba(e,a){if(!U.value||!La(e))return"";try{const t=U.value.tokenEstimate?.avgTokens||0;if(0===t)return"";const n=W();if(!n.enabledModels.find(a=>a.provider===e.provider&&a.modelId===e.modelId))return"";const r=l.getParametersForModel(e.provider,e.modelId);let s=0;for(const[a,l]of Object.entries(r))if(l.is_output_length&&e.parameters[a]){s=e.parameters[a];break}0===s&&(s=100);const o=t+s,i="per-call"===a?1:_a.value*z.value,c=o*i/1e3*.001;return c<.001?"<1mg CO₂e":c<1?`${(1e3*c).toFixed(0)}mg CO₂e`:`${c.toFixed(3)}g CO₂e`}catch(t){return n.warn("Error calculating environmental cost display",{error:t}),""}}function za(){if(!U.value)return"New Trial";const e=(new Date).toLocaleString("en-US",{month:"short",day:"numeric",hour:"2-digit",minute:"2-digit"});return`${U.value.name} - ${e}`}async function Ka(){if(U.value&&0!==L.value.length){K.value="start";try{const e=await g.createTrial({name:B.value||za(),designId:U.value.id,configurations:L.value,repeatConfig:z.value>1?{callsPerPrompt:z.value,strategy:"sequential"}:void 0});i.success("Trial created! Starting execution..."),p("created-and-started",e),p("close"),K.value=!1,setTimeout(async()=>{try{await g.executeTrial(e)}catch(a){n.error("Failed to start trial",a),i.error("Failed to start trial execution")}},100)}catch(e){n.error("Failed to create trial",e),i.error("Failed to create trial"),K.value=!1}}}async function Ga(){if(U.value&&0!==L.value.length){K.value="export";try{const e=await g.createTrial({name:B.value||za(),designId:U.value.id,configurations:L.value,repeatConfig:z.value>1?{callsPerPrompt:z.value,strategy:"sequential"}:void 0}),a=await g.getTrial(e);if(a){const{PythonExportService:e}=await c(async()=>{const{PythonExportService:e}=await Promise.resolve().then(()=>Oa);return{PythonExportService:e}},void 0,import.meta.url),t=e.validateTrialForExport(a);if(!t.valid)return void i.error(`Cannot export trial: ${t.errors.join(", ")}`);p("export-trial",a)}i.success("Trial created! Opening export options..."),p("created",e),p("close")}catch(e){n.error("Failed to create trial for export",e),i.error("Failed to create trial for export")}finally{K.value=!1}}}async function Va(){if(U.value&&0!==L.value.length){K.value="draft";try{if(u.isEditMode&&u.trialToDuplicate)await g.updateTrial(u.trialToDuplicate.id,{name:B.value||za()}),i.success("Trial updated!"),p("created",u.trialToDuplicate.id);else{const e=await g.createTrial({name:B.value||za(),designId:U.value.id,configurations:L.value,repeatConfig:z.value>1?{callsPerPrompt:z.value,strategy:"sequential"}:void 0});i.success("Trial created as draft!"),p("created",e)}p("close")}catch(e){n.error("Failed to create draft trial",e),i.error("Failed to create draft trial")}finally{K.value=!1}}}let Ya=null;return T(async()=>{if(await Promise.all([f.initialize(),v.initialize(),g.initialize()]),u.initialDesignId){const e=f.designs.find(e=>e.id===u.initialDesignId);e&&Ca(e)}if(u.trialToDuplicate){const e=u.trialToDuplicate;n.info("Setting up trial duplication",{trialName:e.name});const a=()=>{if(f.designs.length>0){n.info("Available designs",{count:f.designs.length});const a=f.designs.find(a=>a.id===e.designSnapshot.originalId);n.info("Found design for duplication",{designName:a?.name}),a?(U.value=a,n.info("Set selectedDesign",{designName:U.value.name}),B.value=u.isEditMode?e.name:`Copy of ${e.name}`,e.repeatConfig?.callsPerPrompt&&(z.value=e.repeatConfig.callsPerPrompt),e.configurationSnapshots&&e.configurationSnapshots.length>0&&(L.value=e.configurationSnapshots.map(e=>({name:e.name||e.modelId,provider:e.provider,modelId:e.modelId,parameters:e.parameters||{}})),n.info("Set configurations",{count:L.value.length})),ne.value=!0):n.error("Design not found for trial duplication",{designId:e.designSnapshot.originalId})}else n.info("Designs not loaded yet, waiting"),setTimeout(a,100)};a()}Ya=setInterval(()=>{ne.value||Y.value++},1e3)}),E(()=>{Ya&&clearInterval(Ya),te.forEach(e=>clearInterval(e)),te.clear()}),(e,a)=>{const t=_("a-button"),n=_("a-input"),l=_("a-tag"),i=_("a-input-number");return h(),b(ee,{"model-value":!0,title:u.isEditMode?"Edit Trial":u.trialToDuplicate?"Duplicate Trial":"Create New Trial",size:"full","data-testid":"modal-trial-creation","onUpdate:modelValue":a[7]||(a[7]=a=>e.$emit("close"))},{footer:y(()=>[k(re,null,{default:y(()=>[k(t,{size:"large",onClick:Va,loading:"draft"===K.value,disabled:!U.value||0===L.value.length,"data-testid":"btn-create-draft","aria-label":"Create trial as draft"},{default:y(()=>a[30]||(a[30]=[A(" Create as Draft ")])),_:1,__:[30]},8,["loading","disabled"]),k(t,{size:"large",onClick:Ga,loading:"export"===K.value,disabled:!U.value||0===L.value.length,"data-testid":"btn-export-python","aria-label":"Export trial to Python"},{default:y(()=>a[31]||(a[31]=[A(" Export to Python ")])),_:1,__:[31]},8,["loading","disabled"]),k(t,{type:"primary",size:"large",onClick:Ka,loading:"start"===K.value,disabled:!U.value||0===L.value.length,"data-testid":"btn-create-and-start","aria-label":"Create and start trial execution"},{default:y(()=>[k(M(o)),a[32]||(a[32]=A(" Create and Start "))]),_:1,__:[32]},8,["loading","disabled"])]),_:1})]),default:y(()=>[w("div",se,[w("section",oe,[w("div",ie,[a[9]||(a[9]=w("h3",null,"What are you testing?",-1)),U.value?(h(),b(t,{key:0,onClick:xa,size:"small",class:"back-button",style:{"margin-left":"2em"}},{default:y(()=>a[8]||(a[8]=[A(" ← Back to Select Design ")])),_:1,__:[8]})):x("",!0)]),w("div",ce,[U.value?(h(),C("div",Te,[w("div",Ee,[w("h4",null,O(U.value.name),1),w("span",Ae,O(_a.value)+" combinations",1),w("div",Me,[k(t,{onClick:Ma,size:"small",type:ne.value?"default":"primary",class:"pause-btn"},{icon:y(()=>[(h(),b(F(ne.value?"PlayCircleOutlined":"PauseCircleOutlined")))]),default:y(()=>[A(" "+O(ne.value?"Start Variable Substitution":"Pause Variable Substitution"),1)]),_:1},8,["type"]),k(t,{onClick:$a,size:"small",type:le.value?"primary":"default",class:"placeholders-btn"},{default:y(()=>[A(O(le.value?"Show Live":"Show Raw Template"),1)]),_:1},8,["type"])])]),w("div",{class:"live-template-preview",innerHTML:le.value?Aa(U.value.promptTemplate):Ea(U.value)},null,8,$e)])):(h(),C("div",de,[k(n,{value:q.value,"onUpdate:value":a[0]||(a[0]=e=>q.value=e),placeholder:"Search designs...",size:"large",class:"design-search","data-testid":"input-design-search",allowClear:""},{prefix:y(()=>[k(M(r))]),_:1},8,["value"]),0===ha.value.length?(h(),C("div",ue,[w("div",pe,[a[11]||(a[11]=w("p",null,"No designs found",-1)),k(t,{onClick:a[1]||(a[1]=()=>M(f).initialize())},{default:y(()=>a[10]||(a[10]=[A("Refresh Designs")])),_:1,__:[10]})])])):(h(),C("div",me,[(h(!0),C($,null,N(ha.value,e=>{return h(),C("div",{key:e.id,class:"design-item","data-testid":"design-item","data-design-id":e.id,"data-design-name":e.name,onClick:a=>Ca(e)},[w("div",ve,[w("div",ge,[w("h4",be,[A(O(e.name)+" ",1),e.description?(h(),C("span",he,"- "+O(e.description),1)):x("",!0)])]),w("span",_e,O(Pa(e.updated)),1)]),w("p",{class:"design-description",innerHTML:Ea(e)},null,8,ye),w("div",ke,[k(l,{size:"small",color:(t=e.outputType,{text:"blue",number:"green",boolean:"purple",json:"orange"}[t]||"default"),class:"output-type-tag"},{default:y(()=>[A(O(e.outputType||"text"),1)]),_:2},1032,["color"]),w("span",Ce,[w("span",xe,O(Sa(e)),1),a[12]||(a[12]=w("span",{class:"stat-label"},"vars",-1))]),a[15]||(a[15]=w("span",{class:"stat-divider"},"•",-1)),w("span",we,[w("span",Se,O(Ta(e)),1),a[13]||(a[13]=w("span",{class:"stat-label"},"combos",-1))]),a[16]||(a[16]=w("span",{class:"stat-divider"},"•",-1)),w("span",Ie,[w("span",Pe,O(e.tokenEstimate?.avgTokens||"?"),1),a[14]||(a[14]=w("span",{class:"stat-label"},"tokens",-1))])])],8,fe);var t}),128)),w("div",{class:"design-card design-card-create","data-testid":"btn-create-design",onClick:wa},[k(M(s),{style:{"font-size":"24px"}}),a[17]||(a[17]=w("span",null,"Create New Design",-1))])]))]))])]),U.value?(h(),C("section",Ne,[a[29]||(a[29]=w("h3",null,"Trial Configuration",-1)),w("div",Oe,[w("div",Fe,[w("div",Re,[w("div",je,[w("div",De,[a[18]||(a[18]=w("label",{class:"inline-label"},"Trial Name:",-1)),k(n,{value:B.value,"onUpdate:value":a[2]||(a[2]=e=>B.value=e),placeholder:"Enter trial name (optional)",class:"trial-name-input","data-testid":"input-trial-name"},null,8,["value"])]),w("div",qe,[a[19]||(a[19]=w("label",{class:"inline-label"},"Repeat:",-1)),k(i,{value:z.value,"onUpdate:value":a[3]||(a[3]=e=>z.value=e),min:1,max:10,size:"large",class:"repeat-count-input"},null,8,["value"]),a[20]||(a[20]=w("span",{class:"repeat-suffix"},"times per prompt",-1))])])]),w("div",Ue,[k(t,{onClick:a[4]||(a[4]=e=>G.value=!0),type:"primary",size:"large",class:"big-add-model-btn","data-testid":"btn-add-model","aria-label":"Add Model Configuration"},{default:y(()=>[k(M(s)),a[21]||(a[21]=A(" Add Model "))]),_:1,__:[21]}),a[23]||(a[23]=w("div",{class:"separator-bar"},null,-1)),w("div",Le,[a[22]||(a[22]=w("div",{class:"quick-add-label"},"Quick add recent/popular models (with default temperature=0, max response length = 128):",-1)),w("div",Be,[(h(!0),C($,null,N(ba.value,e=>(h(),b(t,{key:`${e.provider}:${e.modelId}:${JSON.stringify(e.parameters)}`,onClick:a=>function(e){Na(e)||(L.value.push({name:e.displayName,provider:e.provider,modelId:e.modelId,parameters:e.parameters}),j(()=>{const e=document.querySelector(".ant-modal-body");e&&e.scrollTo({top:e.scrollHeight,behavior:"smooth"})}))}(e),size:"small",class:"quick-preset-btn",disabled:Na(e),"data-testid":"quick-add-model","data-provider":e.provider,"data-model":e.modelId,"aria-label":`Quick add ${e.displayName} model`},{default:y(()=>[A(O(e.displayName)+" ",1),ga.value?(h(),C("span",ze,O(M(Q)(Fa(e))),1)):x("",!0)]),_:2},1032,["onClick","disabled","data-provider","data-model","aria-label"]))),128))])])]),w("div",Ke,[a[28]||(a[28]=w("div",{class:"table-header"},[w("div",{class:"col-model"},"Model"),w("div",{class:"col-params"},"Parameters"),w("div",{class:"col-calls"},"API Calls"),w("div",{class:"col-cost"},"Cost per Call"),w("div",{class:"col-total"},"Total Cost"),w("div",{class:"col-actions"},"Actions")],-1)),(h(!0),C($,null,N(L.value,(e,n)=>(h(),C("div",{key:n,class:"table-row","data-testid":"model-config-row","data-config-index":n,"data-provider":e.provider,"data-model":e.modelId},[w("div",Ve,[w("div",Ye,O(e.provider)+":"+O(e.modelId),1),w("div",He,O(e.provider),1)]),w("div",Je,[w("span",We,O(Ra(e.parameters)),1)]),w("div",Xe,[w("span",Qe,O(_a.value)+" × "+O(z.value)+" = ",1),w("span",Ze,O(_a.value*z.value),1)]),w("div",ea,[w("div",aa,[ga.value?(h(),C("span",ta,O(M(Q)(qa(e))),1)):x("",!0),M(S).environmentalCostsEnabled&&La(e)?(h(),C("small",na,O(Ba(e,"per-call")),1)):x("",!0)])]),w("div",la,[w("div",ra,[ga.value?(h(),C("span",sa,O(M(Q)(Ua(e))),1)):x("",!0),M(S).environmentalCostsEnabled&&La(e)?(h(),C("small",oa,O(Ba(e,"total")),1)):x("",!0)])]),w("div",ia,[k(t,{type:"text",size:"small",danger:"",onClick:e=>function(e){L.value.splice(e,1)}(n),class:"remove-btn","data-testid":"remove-model-config","data-config-index":n,"aria-label":`Remove ${e.provider} ${e.modelId} configuration`},{default:y(()=>a[24]||(a[24]=[A("Remove")])),_:2,__:[24]},1032,["onClick","data-config-index","aria-label"])])],8,Ge))),128)),L.value.length>1?(h(),C("div",ca,[w("div",da,[w("div",ua,"TOTAL ("+O(L.value.length)+" models)",1)]),a[25]||(a[25]=w("div",{class:"col-params"},null,-1)),w("div",pa,[w("span",ma,O(ya.value),1)]),a[26]||(a[26]=w("div",{class:"col-cost"},null,-1)),w("div",fa,[ga.value?(h(),C("span",va,O(M(Q)(ka.value)),1)):x("",!0)]),a[27]||(a[27]=w("div",{class:"col-actions"},null,-1))])):x("",!0)])])])])):x("",!0)]),k(Z,{open:G.value&&!!U.value,mode:"trial",design:U.value||void 0,"existing-configurations":L.value,onClose:a[5]||(a[5]=e=>G.value=!1),onAddConfiguration:ja},null,8,["open","design","existing-configurations"]),null!==V.value&&U.value?(h(),b(ae,{key:0,configuration:L.value[V.value],design:U.value,onClose:a[6]||(a[6]=e=>V.value=null),onSave:Da},null,8,["configuration","design"])):x("",!0)]),_:1},8,["title"])}}}),[["__scopeId","data-v-92bf6d96"]]),ba={class:"trial-overview"},ha={class:"overview-section"},_a={class:"cost-value"},ya={key:0,class:"text-secondary",style:{"margin-left":"8px"}},ka={class:"overview-section"},Ca={class:"progress-details"},xa={class:"progress-stats"},wa={class:"configurations-section"},Sa={key:0,class:"model-info"},Ia={key:0},Pa={class:"prompt-section"},Ta={key:0,class:"variables-section"},Ea=v({__name:"TrialDetailModal",props:{trial:{}},emits:["close","updated"],setup(e){const a=e,t=[{title:"Model",key:"model",width:200},{title:"Parameters",key:"params",width:300},{title:"Cost/Call",key:"cost",width:100,align:"right"}],n=P(()=>0===a.trial.progress.total?0:Math.round(a.trial.progress.completed/a.trial.progress.total*100));function l(e){const a=Object.entries(e).map(([e,a])=>`${e}: ${a}`).join(", ");return a.length>50?a.substring(0,50)+"...":a}function r(){const e=a.trial.variableSnapshots;return e&&0!==e.length?e.map(e=>({variable:e.variableName,listName:e.originalListName,count:e.data.itemCount})):[]}return(e,a)=>{const s=_("a-button"),o=_("a-tag"),i=_("a-descriptions-item"),c=_("a-descriptions"),d=_("a-progress"),u=_("a-typography-text"),p=_("a-table"),m=_("a-typography-paragraph"),f=_("a-list-item-meta"),v=_("a-list-item"),g=_("a-list");return h(),b(ee,{"model-value":!0,title:e.trial.name,size:"full","onUpdate:modelValue":a[1]||(a[1]=a=>e.$emit("close"))},{footer:y(()=>[k(s,{onClick:a[0]||(a[0]=a=>e.$emit("close")),size:"large","data-testid":"btn-close-trial-detail","aria-label":"Close trial details"},{default:y(()=>a[2]||(a[2]=[A(" Close ")])),_:1,__:[2]})]),default:y(()=>[w("div",ba,[w("div",ha,[a[3]||(a[3]=w("h3",null,"Trial Information",-1)),k(c,{column:2,size:"small",bordered:""},{default:y(()=>[k(i,{label:"Status"},{default:y(()=>{return[k(o,{color:(a=e.trial.status,{completed:"success",failed:"error",running:"processing",cancelled:"default",draft:"default",pending:"processing",paused:"warning"}[a]||"default"),"data-testid":"tag-trial-status","data-status":e.trial.status,"aria-label":`Trial status: ${e.trial.status}`},{default:y(()=>[A(O(e.trial.status.toUpperCase()),1)]),_:1},8,["color","data-status","aria-label"])];var a}),_:1}),k(i,{label:"Design"},{default:y(()=>[A(O(e.trial.designSnapshot.originalName),1)]),_:1}),k(i,{label:"Created"},{default:y(()=>{return[A(O((a=e.trial.created,new Date(a).toLocaleString())),1)];var a}),_:1}),k(i,{label:"Estimated Cost"},{default:y(()=>[w("span",_a,"$"+O(e.trial.estimatedCost.toFixed(3)),1)]),_:1}),e.trial.repeatConfig?.callsPerPrompt&&e.trial.repeatConfig.callsPerPrompt>1?(h(),b(i,{key:0,label:"Repeat Configuration"},{default:y(()=>[k(o,{color:"purple"},{default:y(()=>[A(O(e.trial.repeatConfig.callsPerPrompt)+"× repeat",1)]),_:1}),e.trial.repeatConfig.delayBetweenRepeats?(h(),C("span",ya,O(e.trial.repeatConfig.delayBetweenRepeats)+"ms delay ",1)):x("",!0)]),_:1})):x("",!0)]),_:1})]),w("div",ka,[a[4]||(a[4]=w("h3",null,"Progress",-1)),w("div",Ca,[k(d,{percent:n.value,status:"failed"===e.trial.status?"exception":"active",size:"small","data-testid":"progress-trial-completion","aria-label":`Trial progress: ${n.value}% complete`},null,8,["percent","status","aria-label"]),w("div",xa,[k(o,{"data-testid":"tag-progress-completed","aria-label":`${e.trial.progress.completed} of ${e.trial.progress.total} calls completed`},{default:y(()=>[A(O(e.trial.progress.completed)+" / "+O(e.trial.progress.total)+" completed",1)]),_:1},8,["aria-label"]),e.trial.progress.networkErrors>0?(h(),b(o,{key:0,color:"error","data-testid":"tag-network-errors","aria-label":`${e.trial.progress.networkErrors} network errors occurred`},{default:y(()=>[A(O(e.trial.progress.networkErrors)+" network errors ",1)]),_:1},8,["aria-label"])):x("",!0)])])])]),w("div",wa,[w("h3",null,"Configurations ("+O(e.trial.configurationSnapshots.length)+")",1),k(p,{columns:t,"data-source":e.trial.configurationSnapshots,pagination:!1,size:"small",scroll:{y:300},"row-key":"id"},{bodyCell:y(({column:e,record:a})=>["model"===e.key?(h(),C("div",Sa,[w("strong",null,O(a.provider),1),w("small",null,O(a.modelId),1)])):x("",!0),"params"===e.key?(h(),b(u,{key:1,code:"",class:"params-preview"},{default:y(()=>[A(O(l(a.parameters)),1)]),_:2},1024)):x("",!0),"cost"===e.key?(h(),C($,{key:2},[(h(),C("span",Ia," $"+O(.001.toFixed(4)),1))],64)):x("",!0)]),_:1},8,["data-source"])]),w("div",Pa,[a[5]||(a[5]=w("h3",null,"Prompt Template",-1)),k(m,{code:"",class:"prompt-template"},{default:y(()=>[A(O(e.trial.designSnapshot.promptTemplate),1)]),_:1})]),e.trial.variableSnapshots?.length?(h(),C("div",Ta,[a[6]||(a[6]=w("h3",null,"Variables",-1)),k(g,{"data-source":r(),size:"small",split:!1},{renderItem:y(({item:e})=>[k(v,null,{default:y(()=>[k(f,null,{title:y(()=>[k(o,{color:"blue"},{default:y(()=>[A(O(e.variable),1)]),_:2},1024)]),description:y(()=>[w("span",null,O(e.listName)+" ("+O(e.count)+" values)",1)]),_:2},1024)]),_:2},1024)]),_:1},8,["data-source"])])):x("",!0)]),_:1},8,["title"])}}});class Aa{static generate(e){const a=this.extractData(e);return this.generateScript(a,e.name)}static extractData(e){const a=new d({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),t=this.extractUniqueVariables(a),n=e.configurationSnapshots.map(e=>({provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:e.parameters})),r=new Set(n.map(e=>e.provider)),s={};for(const o of r){const e=l.getProvider(o);e&&(s[o]=this.buildProviderConfig(o,e))}return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:t},models:n,providerConfigs:s}}static extractUniqueVariables(e){const a={};for(const n of e)for(const[e,t]of Object.entries(n.variables))a[e]||(a[e]=new Set),a[e].add(t);const t={};for(const[n,l]of Object.entries(a))t[n]=Array.from(l).sort();return t}static buildProviderConfig(e,a){const t=a.requestTransform||{},n=a.auth||{type:"none"};let l="direct";"messages"===t.promptKey&&t.wrapPrompt?l="messages":"input"===t.promptKey&&(l="input");let r,s,o="root";"ollama-chat"===e?(o="options",r={max_tokens:"num_predict",max_completion_tokens:"num_predict"}):"ollama-generate"===e&&(o="mixed",s={root:["model","prompt","stream","format","raw"],options:["temperature","num_predict","top_k","top_p"]},r={max_tokens:"num_predict",max_completion_tokens:"num_predict"});const i=Object.values(a.responseModes||{})[0],c=this.parseResponsePath(i?.responseTransform?.contentPath),d=i?.responseTransform?.fallbackPaths?.map(e=>this.parseResponsePath(e)),u=a.api.baseUrl+(a.api.endpoints.chat||a.api.endpoints.generate||"");return{name:a.name,endpoint:u,auth:{type:n.type,header:n.header,prefix:"bearer"===n.type?"Bearer":void 0},headers:a.headers,request:{modelPrefixStrip:!0,promptFormat:l,messageRole:t.messageRole,paramLocation:o,paramRenames:r,mixedParams:s},response:{successPath:c,fallbackPaths:d,errorPath:["error","message"]}}}static parseResponsePath(e){return e?e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const a=parseInt(e);return isNaN(a)?e:a}):["content"]}static generateScript(e,a){const t=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=JSON.stringify(e.providerConfigs,null,4);return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Simple Mode\n=====================================\nGenerated by Auditomatic Lite v${u.short} on ${t}\n\nThis script reproduces your experiment by generating API calls from variables.\nPerfect for understanding, modifying, and extending your experiments.\n\nOriginal trial: ${a}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${Object.keys(e.providerConfigs).map(e=>{const a=e.split("-")[0].toUpperCase();return`    "${e}": os.environ.get("${a}_API_KEY", ""),`}).join("\n")}\n}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Provider configurations (how to talk to each API)\nPROVIDER_CONFIGS = ${r}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef make_api_call(provider_id: str, model: str, prompt: str, params: dict) -> dict:\n    """\n    Universal API caller that handles all provider quirks.\n    \n    Returns dict with 'success', 'content', 'error', and timing info.\n    """\n    config = PROVIDER_CONFIGS[provider_id]\n    \n    # Build headers\n    headers = {"Content-Type": "application/json"}\n    \n    # Add authentication\n    auth = config["auth"]\n    if auth["type"] == "bearer":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = f"{auth['prefix']} {api_key}"\n    elif auth["type"] == "header":\n        api_key = API_KEYS.get(provider_id, "")\n        if not api_key:\n            return {"success": False, "error": f"No API key for {provider_id}"}\n        headers[auth["header"]] = api_key\n    \n    # Add provider-specific headers\n    if config.get("headers"):\n        headers.update(config["headers"])\n    \n    # Build request body\n    request = config["request"]\n    \n    # Strip provider prefix from model\n    if request.get("modelPrefixStrip"):\n        model = model.split(":", 1)[-1]\n    \n    body = {"model": model}\n    \n    # Format prompt\n    if request["promptFormat"] == "messages":\n        body["messages"] = [{"role": request.get("messageRole", "user"), "content": prompt}]\n    elif request["promptFormat"] == "direct":\n        body["prompt"] = prompt\n    elif request["promptFormat"] == "input":\n        body["input"] = prompt\n    \n    # Handle parameters\n    processed_params = params.copy()\n    \n    # Apply renames\n    if request.get("paramRenames"):\n        for old_key, new_key in request["paramRenames"].items():\n            if old_key in processed_params:\n                processed_params[new_key] = processed_params.pop(old_key)\n    \n    # Place parameters\n    if request["paramLocation"] == "root":\n        body.update(processed_params)\n    elif request["paramLocation"] == "options":\n        body["options"] = processed_params\n    elif request.get("mixedParams"):\n        mixed = request["mixedParams"]\n        for key, value in processed_params.items():\n            if key in mixed.get("root", []):\n                body[key] = value\n            else:\n                if "options" not in body:\n                    body["options"] = {}\n                body["options"][key] = value\n    \n    # Make request\n    start_time = time.time()\n    try:\n        response = requests.post(\n            config["endpoint"],\n            headers=headers,\n            json=body,\n            timeout=30\n        )\n        latency_ms = (time.time() - start_time) * 1000\n        \n        if response.ok:\n            data = response.json()\n            content = extract_from_path(data, config["response"]["successPath"])\n            \n            # Try fallback paths\n            if content is None and config["response"].get("fallbackPaths"):\n                for path in config["response"]["fallbackPaths"]:\n                    content = extract_from_path(data, path)\n                    if content is not None:\n                        break\n            \n            return {\n                "success": True,\n                "content": content or "",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n        else:\n            return {\n                "success": False,\n                "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                "latency_ms": latency_ms,\n                "status_code": response.status_code\n            }\n            \n    except Exception as e:\n        return {\n            "success": False,\n            "error": str(e),\n            "latency_ms": (time.time() - start_time) * 1000\n        }\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(\n                model_config["provider"],\n                model_config["modelId"],\n                prompt,\n                model_config["parameters"]\n            )\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": result.get("content", ""),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                "status_code": result.get("status_code", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {result['content'][:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_results_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider not in API_KEYS or not API_KEYS[provider]:\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(set(missing_keys)))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns:\n            print(f"Avg latency: {df['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class Ma{static generate(e){const a=this.extractData(e);return this.generateScript(a,e.name)}static extractData(e){const a=[],t=new f,r=new d({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),s=p(e);let o=0;for(const c of e.configurationSnapshots){const d=l.getProvider(c.provider);if(d)for(const l of r){const r=s>1?m():void 0;let u=e.designSnapshot.promptTemplate;for(const[e,a]of Object.entries(l.variables))u=u.replace(new RegExp(`{{${e}}}`,"g"),a);for(let e=0;e<s;e++){o++;try{const n={id:"export-config",name:c.name,provider:c.provider,model:c.modelId,params:c.parameters,created_at:new Date},i=t.buildAPIRequest(n,u),p={};for(const[e,a]of Object.entries(i.headers))"Authorization"===e&&a.startsWith("Bearer ")?p[e]=`Bearer $${c.provider.split("-")[0].toUpperCase()}_API_KEY`:e===d.auth.header&&"header"===d.auth.type?p[e]=`$${c.provider.split("-")[0].toUpperCase()}_API_KEY`:p[e]=a;const m=this.parseResponsePath(this.getDefaultResponsePath(c.provider));a.push({id:`call_${String(o).padStart(3,"0")}`,provider:c.provider,endpoint:i.url,headers:p,body:i.body,responsePath:m,metadata:{variables:l.variables,modelName:c.modelId,configName:c.name,...s>1&&{repeatIndex:e,repeatGroupId:r}}})}catch(i){n.warn("Failed to build API call for config",{configName:c.name,error:i})}}}}return{apiCalls:a,...e.repeatConfig&&{repeatConfig:{callsPerPrompt:e.repeatConfig.callsPerPrompt,delayBetweenRepeats:e.repeatConfig.delayBetweenRepeats}}}}static parseResponsePath(e){return e.split(/[\.\[\]]/).filter(Boolean).map(e=>{const a=parseInt(e);return isNaN(a)?e:a})}static getDefaultResponsePath(e){switch(e){case"openai-chat":case"openrouter":return"choices[0].message.content";case"openai-responses":return"output[0].content[0].text";case"anthropic":return"content[0].text";case"ollama-chat":return"message.content";case"ollama-generate":return"response";default:return"content"}}static generateScript(e,a){const t=(new Date).toISOString(),n=JSON.stringify(e.apiCalls,null,4),l=[...new Set(e.apiCalls.map(e=>e.provider))],r=e.repeatConfig?`\nRepeat configuration: ${e.repeatConfig.callsPerPrompt} calls per prompt${e.repeatConfig.delayBetweenRepeats?`, ${e.repeatConfig.delayBetweenRepeats}ms delay`:""}`:"";return`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Literal Mode\n======================================\nGenerated by Auditomatic Lite v${u.short} on ${t}\n\nThis script contains the EXACT API calls from your experiment.\nPerfect for bit-for-bit reproduction, debugging, and comparing results.\n\nOriginal trial: ${a}\nTotal API calls: ${e.apiCalls.length}${r}\n"""\n\nimport os\nimport json\nimport time\nimport requests\nimport pandas as pd\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\nAPI_KEYS = {\n${l.map(e=>{const a=e.split("-")[0].toUpperCase();return`    "${a}": os.environ.get("${a}_API_KEY", ""),`}).join("\n")}\n}\n\n# Pre-computed API calls from your experiment\nAPI_CALLS = ${n}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\ndef execute_literal_calls():\n    """Execute pre-serialized API calls exactly as specified"""\n    results = []\n    total = len(API_CALLS)\n    \n    print(f"Executing {total} pre-computed API calls...")\n    print("=" * 60)\n    \n    for i, call in enumerate(API_CALLS):\n        print(f"[{i+1}/{total}] {call['metadata']['configName']} - ", end="")\n        \n        # Replace API key placeholders in headers\n        headers = {}\n        for key, value in call["headers"].items():\n            if "\\$" in str(value):\n                # Extract provider name from placeholder\n                for provider_key, api_key in API_KEYS.items():\n                    placeholder = f"\\\${provider_key}_API_KEY"\n                    if placeholder in value:\n                        headers[key] = value.replace(placeholder, api_key)\n                        break\n                else:\n                    headers[key] = value\n            else:\n                headers[key] = value\n        \n        # Check if we have required API key\n        provider_base = call["provider"].split("-")[0].upper()\n        if provider_base in ["OPENAI", "ANTHROPIC", "OPENROUTER"] and not API_KEYS.get(provider_base):\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": f"No API key for {provider_base}",\n                "latency_ms": 0,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ No API key")\n            continue\n        \n        # Make the exact API call\n        start_time = time.time()\n        try:\n            response = requests.post(\n                call["endpoint"],\n                headers=headers,\n                json=call["body"],\n                timeout=30\n            )\n            latency_ms = (time.time() - start_time) * 1000\n            \n            if response.ok:\n                data = response.json()\n                content = extract_from_path(data, call["responsePath"])\n                \n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": content or "",\n                    "success": True,\n                    "error": "",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    "full_response": json.dumps(data)[:500],  # First 500 chars\n                    **call["metadata"]["variables"]\n                })\n                print(f"✓ {(content or '')[:30]}")\n            else:\n                results.append({\n                    "call_id": call["id"],\n                    "timestamp": datetime.now(),\n                    "provider": call["provider"],\n                    "model": call["metadata"]["modelName"],\n                    "config_name": call["metadata"]["configName"],\n                    "prompt": extract_prompt_from_body(call["body"]),\n                    "response": "",\n                    "success": False,\n                    "error": f"HTTP {response.status_code}: {response.text[:200]}",\n                    "latency_ms": latency_ms,\n                    "status_code": response.status_code,\n                    **call["metadata"]["variables"]\n                })\n                print(f"✗ HTTP {response.status_code}")\n                \n        except Exception as e:\n            latency_ms = (time.time() - start_time) * 1000\n            results.append({\n                "call_id": call["id"],\n                "timestamp": datetime.now(),\n                "provider": call["provider"],\n                "model": call["metadata"]["modelName"],\n                "config_name": call["metadata"]["configName"],\n                "prompt": extract_prompt_from_body(call["body"]),\n                "response": "",\n                "success": False,\n                "error": str(e)[:200],\n                "latency_ms": latency_ms,\n                "status_code": 0,\n                **call["metadata"]["variables"]\n            })\n            print(f"✗ {str(e)[:30]}")\n        \n        # Handle repeat delays if configured\n        if "repeatIndex" in call["metadata"] and call["metadata"]["repeatIndex"] > 0:\n            # Check if there's a repeat delay configured\n            delay_ms = ${e.repeatConfig?.delayBetweenRepeats||0}\n            if delay_ms > 0:\n                time.sleep(delay_ms / 1000.0)\n        \n        # Rate limiting\n        time.sleep(0.1)\n    \n    return results\n\ndef extract_prompt_from_body(body: dict) -> str:\n    """Extract the prompt from various request body formats"""\n    # Messages format (OpenAI, Anthropic, etc)\n    if "messages" in body and isinstance(body["messages"], list):\n        for msg in body["messages"]:\n            if msg.get("role") == "user":\n                return msg.get("content", "")\n    \n    # Direct prompt format (Ollama generate)\n    if "prompt" in body:\n        return body["prompt"]\n    \n    # Input format (OpenAI responses)\n    if "input" in body:\n        return body["input"]\n    \n    return ""\n\ndef extract_from_path(data: Any, path: List[Any]) -> Optional[str]:\n    """Extract value from nested data using a path like ['choices', 0, 'message', 'content']"""\n    try:\n        current = data\n        for key in path:\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                return None\n        return str(current) if current is not None else None\n    except (KeyError, IndexError, TypeError):\n        return None\n\ndef save_results(results: List[Dict[str, Any]], format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    # Drop full_response column for cleaner output (except JSON)\n    if format != "json" and "full_response" in df.columns:\n        df = df.drop(columns=["full_response"])\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_literal_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for API keys\n    required_providers = set(call["provider"].split("-")[0].upper() for call in API_CALLS)\n    missing_keys = []\n    for provider in required_providers:\n        if provider not in ["OLLAMA"] and not API_KEYS.get(provider):\n            missing_keys.append(provider)\n    \n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(missing_keys))\n        print("Set them in the API_KEYS dict or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Execute all calls\n    results = execute_literal_calls()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if df['success'].any():\n            print(f"Avg latency (successful): {df[df['success']]['latency_ms'].mean():.1f}ms")\n        \n        # Group by model\n        print(f"\\nBy Model:")\n        model_summary = df.groupby('config_name')['success'].agg(['count', 'sum', 'mean'])\n        model_summary.columns = ['total', 'successful', 'success_rate']\n        print(model_summary)\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class $a{static generate(e){const a=this.extractData(e);return this.generateScript(a,e.name)}static extractData(e){const a=new d({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),t=this.extractUniqueVariables(a),n=e.configurationSnapshots.map(e=>{let a,t="text";return e.parameters.response_format?(t="json_mode",a={response_format:e.parameters.response_format}):e.parameters.tools&&(t="function_calling",a={tools:e.parameters.tools,tool_choice:e.parameters.tool_choice}),{provider:e.provider,modelId:e.modelId,displayName:e.name,parameters:this.filterCoreParams(e.parameters),responseMode:t,responseModeParams:a}}),l=new Set(n.map(e=>e.provider)),r={"openai-chat":"openai","openai-responses":"openai",anthropic:"anthropic",openrouter:"openai","ollama-chat":"ollama","ollama-generate":"ollama"},s=[...new Set(Array.from(l).map(e=>r[e]).filter(Boolean))],o={"openai-chat":"OPENAI","openai-responses":"OPENAI",anthropic:"ANTHROPIC",openrouter:"OPENROUTER","ollama-chat":"","ollama-generate":""},i=[...new Set(Array.from(l).map(e=>o[e]).filter(Boolean))];return{experiment:{promptTemplate:e.designSnapshot.promptTemplate,variables:t},models:n,providerLibraries:{required:s,apiKeys:i}}}static extractUniqueVariables(e){const a={};for(const n of e)for(const[e,t]of Object.entries(n.variables))a[e]||(a[e]=new Set),a[e].add(t);const t={};for(const[n,l]of Object.entries(a))t[n]=Array.from(l).sort();return t}static filterCoreParams(e){const a={...e};return delete a.response_format,delete a.tools,delete a.tool_choice,a}static generateScript(e,a){const t=(new Date).toISOString(),n=JSON.stringify(e.experiment.variables,null,4),l=JSON.stringify(e.models,null,4),r=["import os","import json","import time","import pandas as pd","from datetime import datetime"];return e.providerLibraries.required.includes("openai")&&r.push("from openai import OpenAI"),e.providerLibraries.required.includes("anthropic")&&r.push("from anthropic import Anthropic"),e.providerLibraries.required.includes("ollama")&&r.push("import ollama"),`#!/usr/bin/env python3\n"""\nAI Model Testing Script - Native Mode\n=====================================\nGenerated by Auditomatic Lite v${u.short} on ${t}\n\nThis script uses native Python libraries for each provider.\nCleanest code, best for production use.\n\nOriginal trial: ${a}\nRequired packages: ${e.providerLibraries.required.join(", ")}\n"""\n\n${r.join("\n")}\n\n# === CONFIGURATION ===\n\n# API Keys - Add your keys here or set as environment variables\n${e.providerLibraries.apiKeys.map(e=>`os.environ.setdefault("${e}_API_KEY", "")  # Set your ${e} API key`).join("\n")}\n\n# Your experiment design\nEXPERIMENT = {\n    "prompt_template": "${e.experiment.promptTemplate.replace(/"/g,'\\"')}",\n    "variables": ${n}\n}\n\n# Models to test\nMODELS = ${l}\n\n# Output settings\nOUTPUT_FORMAT = "csv"  # Options: csv, excel, json, parquet, html, markdown, stata, pickle\n\n# === IMPLEMENTATION ===\n\n# Initialize clients\nclients = {}\n\ndef get_client(provider):\n    """Get or create client for provider"""\n    if provider not in clients:\n        if provider in ["openai-chat", "openai-responses"]:\n            clients[provider] = OpenAI()\n        elif provider == "anthropic":\n            clients[provider] = Anthropic()\n        elif provider == "openrouter":\n            clients[provider] = OpenAI(\n                api_key=os.environ.get("OPENROUTER_API_KEY"),\n                base_url="https://openrouter.ai/api/v1"\n            )\n        # Ollama doesn't need a client\n    return clients.get(provider)\n\ndef make_api_call(model_config: dict, prompt: str) -> dict:\n    """Make API call using native provider library"""\n    provider = model_config["provider"]\n    model = model_config["modelId"]\n    params = model_config["parameters"].copy()\n    \n    try:\n        start_time = time.time()\n        \n        if provider == "openai-chat" or provider == "openrouter":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["response_format"] = {"type": "json_object"}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.chat.completions.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content based on response mode\n            if model_config["responseMode"] == "function_calling" and response.choices[0].message.tool_calls:\n                content = response.choices[0].message.tool_calls[0].function.arguments\n                if isinstance(content, str):\n                    content = json.loads(content)\n            else:\n                content = response.choices[0].message.content\n            \n        elif provider == "openai-responses":\n            client = get_client(provider)\n            \n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["text"] = {"format": {"type": "json_object"}}\n            elif model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.responses.create(\n                model=model,\n                input=prompt,\n                **params\n            )\n            \n            # Extract content\n            output = response.output\n            if isinstance(output, list) and len(output) > 0:\n                if hasattr(output[0], 'content') and isinstance(output[0].content, list):\n                    content = output[0].content[0].text if hasattr(output[0].content[0], 'text') else str(output[0].content[0])\n                else:\n                    content = str(output[0])\n            else:\n                content = str(output)\n            \n        elif provider == "anthropic":\n            client = get_client(provider)\n            \n            # Build messages\n            messages = [{"role": "user", "content": prompt}]\n            \n            # Handle response modes\n            if model_config["responseMode"] == "function_calling":\n                params.update(model_config.get("responseModeParams", {}))\n            \n            # Make call\n            response = client.messages.create(\n                model=model,\n                messages=messages,\n                **params\n            )\n            \n            # Extract content\n            if model_config["responseMode"] == "function_calling" and hasattr(response.content[0], 'input'):\n                content = response.content[0].input\n            else:\n                content = response.content[0].text\n            \n        elif provider == "ollama-chat":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.chat(\n                model=model,\n                messages=[{"role": "user", "content": prompt}],\n                **params\n            )\n            \n            # Extract content\n            content = response["message"]["content"]\n            \n        elif provider == "ollama-generate":\n            # Handle response modes\n            if model_config["responseMode"] == "json_mode":\n                params["format"] = "json"\n            \n            # Make call\n            response = ollama.generate(\n                model=model,\n                prompt=prompt,\n                **params\n            )\n            \n            # Extract content\n            content = response["response"]\n        \n        else:\n            raise ValueError(f"Unknown provider: {provider}")\n        \n        latency_ms = (time.time() - start_time) * 1000\n        \n        return {\n            "success": True,\n            "content": content,\n            "latency_ms": latency_ms\n        }\n        \n    except Exception as e:\n        latency_ms = (time.time() - start_time) * 1000\n        return {\n            "success": False,\n            "content": "",\n            "error": str(e),\n            "latency_ms": latency_ms\n        }\n\ndef generate_prompts():\n    """Generate all prompts from template and variables"""\n    template = EXPERIMENT["prompt_template"]\n    variables = EXPERIMENT["variables"]\n    \n    # Get variable names from template\n    import re\n    var_names = re.findall(r'{{(\\w+)}}', template)\n    \n    # Generate all combinations\n    from itertools import product\n    \n    var_lists = [variables[var] for var in var_names]\n    for values in product(*var_lists):\n        var_dict = dict(zip(var_names, values))\n        \n        # Replace variables in template\n        prompt = template\n        for var, val in var_dict.items():\n            prompt = prompt.replace(f"{{{{{var}}}}}", str(val))\n        \n        yield prompt, var_dict\n\ndef run_experiment():\n    """Run the full experiment"""\n    results = []\n    total_calls = len(MODELS) * len(list(generate_prompts()))\n    current = 0\n    \n    print(f"Running experiment with {len(MODELS)} models and {total_calls} total API calls")\n    print("=" * 60)\n    \n    for model_config in MODELS:\n        print(f"\\nTesting {model_config['displayName']}...")\n        \n        for prompt, variables in generate_prompts():\n            current += 1\n            print(f"[{current}/{total_calls}] {prompt[:50]}...", end=" ")\n            \n            # Make API call\n            result = make_api_call(model_config, prompt)\n            \n            # Collect results\n            results.append({\n                "timestamp": datetime.now(),\n                "provider": model_config["provider"],\n                "model": model_config["modelId"],\n                "model_name": model_config["displayName"],\n                "prompt": prompt,\n                "response": str(result.get("content", "")),\n                "success": result.get("success", False),\n                "error": result.get("error", ""),\n                "latency_ms": result.get("latency_ms", 0),\n                **variables  # Add variables as columns\n            })\n            \n            # Show result\n            if result["success"]:\n                print(f"✓ {str(result['content'])[:30]}")\n            else:\n                print(f"✗ {result['error'][:30]}")\n            \n            # Rate limiting\n            time.sleep(0.1)\n    \n    return results\n\ndef save_results(results: list, format: str = OUTPUT_FORMAT):\n    """Save results using pandas in the specified format"""\n    df = pd.DataFrame(results)\n    \n    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")\n    base_filename = f"experiment_native_{timestamp}"\n    \n    if format == "csv":\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    elif format == "excel":\n        filename = f"{base_filename}.xlsx"\n        df.to_excel(filename, index=False)\n    elif format == "json":\n        filename = f"{base_filename}.json"\n        df.to_json(filename, orient="records", indent=2)\n    elif format == "parquet":\n        filename = f"{base_filename}.parquet"\n        df.to_parquet(filename)\n    elif format == "html":\n        filename = f"{base_filename}.html"\n        df.to_html(filename, index=False)\n    elif format == "markdown":\n        filename = f"{base_filename}.md"\n        with open(filename, "w") as f:\n            f.write(df.to_markdown(index=False))\n    elif format == "stata":\n        filename = f"{base_filename}.dta"\n        df.to_stata(filename)\n    elif format == "pickle":\n        filename = f"{base_filename}.pkl"\n        df.to_pickle(filename)\n    else:\n        filename = f"{base_filename}.csv"\n        df.to_csv(filename, index=False)\n    \n    print(f"\\nResults saved to {filename}")\n    return filename\n\ndef main():\n    """Main entry point"""\n    # Check for required packages\n    required = ${JSON.stringify(e.providerLibraries.required)}\n    missing = []\n    for lib in required:\n        try:\n            __import__(lib)\n        except ImportError:\n            missing.append(lib)\n    \n    if missing:\n        print(f"ERROR: Missing required packages: {', '.join(missing)}")\n        print(f"Install with: pip install {' '.join(missing)}")\n        return\n    \n    # Check for API keys\n    missing_keys = []\n    for model in MODELS:\n        provider = model["provider"]\n        if provider in ["openai-chat", "openai-responses"] and not os.environ.get("OPENAI_API_KEY"):\n            missing_keys.append("OPENAI_API_KEY")\n        elif provider == "anthropic" and not os.environ.get("ANTHROPIC_API_KEY"):\n            missing_keys.append("ANTHROPIC_API_KEY")\n        elif provider == "openrouter" and not os.environ.get("OPENROUTER_API_KEY"):\n            missing_keys.append("OPENROUTER_API_KEY")\n    \n    if missing_keys:\n        print(f"WARNING: Missing API keys: {', '.join(set(missing_keys))}")\n        print("Set them in the script or as environment variables.")\n        response = input("\\nContinue anyway? (y/N): ")\n        if response.lower() != 'y':\n            return\n    \n    # Run experiment\n    results = run_experiment()\n    \n    # Save results\n    if results:\n        save_results(results)\n        \n        # Basic summary\n        df = pd.DataFrame(results)\n        print(f"\\nSummary:")\n        print(f"Total calls: {len(df)}")\n        print(f"Successful: {df['success'].sum()}")\n        print(f"Failed: {(~df['success']).sum()}")\n        if 'latency_ms' in df.columns and df['success'].any():\n            print(f"Avg latency: {df[df['success']]['latency_ms'].mean():.1f}ms")\n    else:\n        print("\\nNo results to save")\n\nif __name__ == "__main__":\n    main()\n`}}class Na{static async generatePythonScript(e,a){try{const t=a||this.getDefaultOptions(),n=this.validateTrialForExport(e);if(!n.valid)throw new Error(`Trial validation failed: ${n.errors.join(", ")}`);switch(t.mode){case"simple":return Aa.generate(e);case"literal":return Ma.generate(e);case"native":return $a.generate(e);default:throw new Error(`Unknown export mode: ${t.mode}`)}}catch(t){throw new Error(`Failed to generate Python export: ${t instanceof Error?t.message:String(t)}`)}}static async downloadPythonScript(e,a){const t=await this.generatePythonScript(e,a),n=a||this.getDefaultOptions(),l=new Blob([t],{type:"text/x-python"}),r=URL.createObjectURL(l),s=document.createElement("a");s.href=r,s.download=this.generateFilename(e,n.mode),document.body.appendChild(s),s.click(),document.body.removeChild(s),URL.revokeObjectURL(r)}static validateTrialForExport(e){const a=[];return e.designSnapshot?e.designSnapshot.promptTemplate||a.push("Design missing prompt template"):a.push("Trial missing design snapshot"),e.configurationSnapshots&&0!==e.configurationSnapshots.length?e.configurationSnapshots.forEach((e,t)=>{e.provider||a.push(`Configuration ${t+1} missing provider`),e.modelId||a.push(`Configuration ${t+1} missing model`),e.parameters||a.push(`Configuration ${t+1} missing parameters`)}):a.push("Trial missing model configurations"),e.variableSnapshots||a.push("Trial missing variable snapshots"),{valid:0===a.length,errors:a}}static getExportSummary(e){const a=new Set(e.configurationSnapshots.map(e=>e.provider)),t=e.totalCombinations||0;return{apiCallCount:e.configurationSnapshots.length*t,providersUsed:Array.from(a),variableCombinations:t,configurations:e.configurationSnapshots.length}}static getDefaultOptions(){return{mode:"simple"}}static generateFilename(e,a){const t=e.name||`trial_${e.id}`,n=(new Date).toISOString().split("T")[0];return`${t.toLowerCase().replace(/[^a-z0-9]/g,"_")}_${a}_${n}.py`}}const Oa=Object.freeze(Object.defineProperty({__proto__:null,PythonExportService:Na},Symbol.toStringTag,{value:"Module"})),Fa={class:"trial-info"},Ra={class:"trial-stats"},ja={class:"export-section"},Da={class:"mode-content"},qa={class:"mode-content"},Ua={class:"mode-content"},La={class:"export-section"},Ba={class:"preview-content"},za={class:"preview-info"},Ka=v({__name:"PythonExportModal",props:{trial:{}},emits:["close","exported"],setup(e,{emit:a}){const t=e,l=a,r=I("simple"),s=I(!1),o=P(()=>t.trial.progress.total),i=P(()=>t.trial.configurationSnapshots?.length||0),c=P(()=>t.trial.totalCombinations||0),d=P(()=>{const e=.05*c.value+.3*i.value;return Math.round(15+e)}),u=P(()=>{const e=.5*o.value;return Math.round(10+e)}),p=P(()=>{const e=.05*c.value+.2*i.value;return Math.round(12+e)}),m=P(()=>{const e=t.trial.name.toLowerCase().replace(/\s+/g,"_"),a=(new Date).toISOString().split("T")[0];return`${e}_${r.value}_${a}.py`}),f=P(()=>{if("simple"===r.value){return 300+(c.value+10*i.value)}if("native"===r.value){return 250+(c.value+8*i.value)}return 200+15*o.value});async function v(){s.value=!0;try{const e={mode:r.value};await Na.downloadPythonScript(t.trial,e),l("exported",m.value),l("close")}catch(e){n.error("Export failed",e),alert("Export failed: "+(e instanceof Error?e.message:"Unknown error"))}finally{s.value=!1}}return(e,a)=>{const t=_("a-button"),n=_("a-tag"),l=_("a-radio"),g=_("a-radio-group"),C=_("a-typography-text");return h(),b(ee,{"model-value":!0,title:"Export Python Script",size:"full","onUpdate:modelValue":a[2]||(a[2]=a=>e.$emit("close"))},{footer:y(()=>[k(t,{onClick:a[0]||(a[0]=a=>e.$emit("close")),size:"large","data-testid":"btn-cancel-python-export","aria-label":"Cancel Python export"},{default:y(()=>a[3]||(a[3]=[A(" Cancel ")])),_:1,__:[3]}),k(t,{type:"primary",onClick:v,loading:s.value,size:"large","data-testid":"btn-confirm-python-export","data-mode":r.value,"aria-label":`Export Python script in ${r.value} mode`},{default:y(()=>a[4]||(a[4]=[A(" Export Script ")])),_:1,__:[4]},8,["loading","data-mode","aria-label"])]),default:y(()=>[w("div",Fa,[w("h3",null,O(e.trial.name),1),w("div",Ra,[k(n,null,{default:y(()=>[A(O(o.value)+" API calls",1)]),_:1}),k(n,null,{default:y(()=>[A(O(i.value)+" configurations",1)]),_:1}),k(n,null,{default:y(()=>[A(O(c.value)+" variable combinations",1)]),_:1})])]),w("div",ja,[a[11]||(a[11]=w("h4",null,"Export Mode",-1)),k(g,{value:r.value,"onUpdate:value":a[1]||(a[1]=e=>r.value=e),class:"mode-options","data-testid":"radiogroup-export-mode","aria-label":"Select Python export mode"},{default:y(()=>[k(l,{value:"simple",class:"mode-radio","data-testid":"radio-mode-simple","aria-label":"Simple script mode"},{default:y(()=>[w("div",Da,[a[5]||(a[5]=w("div",{class:"mode-title"},"Simple Script",-1)),a[6]||(a[6]=w("div",{class:"mode-description"}," Educational script with variables as lists. Easy to understand, modify, and extend. Perfect for learning how AI APIs work. ",-1)),k(n,{color:"blue",size:"small"},{default:y(()=>[A("~"+O(d.value)+"KB",1)]),_:1})])]),_:1}),k(l,{value:"literal",class:"mode-radio","data-testid":"radio-mode-literal","aria-label":"Literal reproduction mode"},{default:y(()=>[w("div",qa,[a[7]||(a[7]=w("div",{class:"mode-title"},"Literal Reproduction",-1)),a[8]||(a[8]=w("div",{class:"mode-description"}," Exact API calls pre-computed. Bit-for-bit reproduction of your experiment. Best for debugging and comparing results. ",-1)),k(n,{color:"blue",size:"small"},{default:y(()=>[A("~"+O(u.value)+"KB",1)]),_:1})])]),_:1}),k(l,{value:"native",class:"mode-radio","data-testid":"radio-mode-native","aria-label":"Native libraries mode"},{default:y(()=>[w("div",Ua,[a[9]||(a[9]=w("div",{class:"mode-title"},"Native Libraries",-1)),a[10]||(a[10]=w("div",{class:"mode-description"}," Uses official Python SDKs (openai, anthropic, ollama). Cleanest code, best for production use. Requires: pip install openai anthropic ollama ",-1)),k(n,{color:"green",size:"small"},{default:y(()=>[A("~"+O(p.value)+"KB",1)]),_:1})])]),_:1})]),_:1},8,["value"])]),a[13]||(a[13]=w("div",{class:"export-section"},[w("h4",null,"Output Format"),w("div",{class:"format-info"},[w("p",null,"Both scripts save results using pandas in your choice of format:"),w("ul",null,[w("li",null,[w("strong",null,"CSV"),A(" - Universal format, opens in Excel/Google Sheets")]),w("li",null,[w("strong",null,"Excel"),A(" - Native Excel format")]),w("li",null,[w("strong",null,"JSON"),A(" - For programmatic access")]),w("li",null,[w("strong",null,"Parquet"),A(" - Efficient compressed format")]),w("li",null,[w("strong",null,"HTML"),A(" - For web viewing")]),w("li",null,[w("strong",null,"Markdown"),A(" - For documentation")]),w("li",null,[w("strong",null,"Stata"),A(" - For statistical analysis")]),w("li",null,[w("strong",null,"Pickle"),A(" - Python native format")])])])],-1)),w("div",La,[a[12]||(a[12]=w("h4",null,"Script Preview",-1)),w("div",Ba,[k(C,{code:"",class:"preview-filename"},{default:y(()=>[A(O(m.value),1)]),_:1}),w("div",za,[k(n,{size:"small"},{default:y(()=>[A(O(f.value)+" lines",1)]),_:1}),k(n,{size:"small"},{default:y(()=>[A(O(r.value)+" mode",1)]),_:1})])])])]),_:1,__:[13]})}}}),Ga={class:"api-call-modal"},Va={class:"modal-header"},Ya={class:"modal-content"},Ha={class:"section"},Ja={class:"info-grid"},Wa={class:"info-item"},Xa={class:"call-id"},Qa={class:"info-item"},Za={class:"info-item"},et={class:"info-item"},at={key:0,class:"info-item"},tt={key:1,class:"info-item"},nt={key:2,class:"info-item"},lt={class:"section"},rt={class:"variables-detail"},st={class:"variable-value"},ot={key:0,class:"attributes-section"},it={class:"attribute-items"},ct={class:"section"},dt={class:"prompt-display"},ut={key:0,class:"section"},pt={key:0,class:"response-info"},mt={class:"info-grid"},ft={class:"info-item"},vt={class:"info-item"},gt={key:1,class:"result-content"},bt={key:0,class:"error-result"},ht={class:"error-message"},_t={key:0,class:"error-raw"},yt={class:"error-response"},kt={key:1,class:"content-result"},Ct={class:"content-display"},xt={class:"section"},wt={class:"raw-data"},St={key:1,class:"section"},It={class:"raw-data"},Pt={class:"modal-footer"},Tt=e(v({__name:"APICallDetailModal",props:{apiCall:{},trial:{}},emits:["close"],setup(e){const a=e,t=P(()=>{if(!a.apiCall.request)return"No request data";const e=JSON.parse(JSON.stringify(a.apiCall.request));return e.headers&&Object.keys(e.headers).forEach(a=>{const t=a.toLowerCase();(t.includes("authorization")||t.includes("api-key")||t.includes("x-api-key")||t.includes("bearer"))&&(e.headers[a]="[REDACTED]")}),JSON.stringify(e,null,2)});function l(){return a.trial&&a.trial.configurationSnapshots[a.apiCall.configurationIndex]&&a.trial.configurationSnapshots[a.apiCall.configurationIndex].name||`Configuration ${a.apiCall.configurationIndex+1}`}function r(e){const a="string"==typeof e?new Date(e):e;return isNaN(a.getTime())?"Invalid date":a.toLocaleString()}async function s(){const e={id:a.apiCall.id,status:a.apiCall.status,configuration:l(),variables:a.apiCall.variables,variableAttributes:a.apiCall.variableAttributes,prompt:a.apiCall.prompt,request:JSON.parse(t.value),response:a.apiCall.response,result:a.apiCall.result,created:a.apiCall.created,completed:a.apiCall.completed},r=JSON.stringify(e,null,2);try{if(navigator.clipboard&&navigator.clipboard.writeText)return await navigator.clipboard.writeText(r),void i.success("Details copied to clipboard!");const e=document.createElement("textarea");e.value=r,e.style.position="fixed",e.style.left="-999999px",e.style.top="-999999px",document.body.appendChild(e),e.focus(),e.select();const a=document.execCommand("copy");if(document.body.removeChild(e),!a)throw new Error("execCommand failed");i.success("Details copied to clipboard!")}catch(s){n.error("Failed to copy to clipboard",s),prompt("Copy this text manually:",r)}}return(e,a)=>{const n=_("a-button");return h(),C("div",{class:"modal-overlay",onClick:a[2]||(a[2]=D(a=>e.$emit("close"),["self"]))},[w("div",Ga,[w("div",Va,[a[3]||(a[3]=w("h2",null,"API Call Details",-1)),w("button",{class:"close-btn",onClick:a[0]||(a[0]=a=>e.$emit("close")),"data-testid":"btn-close-api-call-modal","aria-label":"Close API call details"},"×")]),w("div",Ya,[w("div",Ha,[a[11]||(a[11]=w("h3",null,"Overview",-1)),w("div",Ja,[w("div",Wa,[a[4]||(a[4]=w("label",null,"Call ID:",-1)),w("span",Xa,O(e.apiCall.id),1)]),w("div",Qa,[a[5]||(a[5]=w("label",null,"Status:",-1)),w("span",{class:q(["status-badge",e.apiCall.status])},O(e.apiCall.status),3)]),w("div",Za,[a[6]||(a[6]=w("label",null,"Configuration:",-1)),w("span",null,O(l()),1)]),w("div",et,[a[7]||(a[7]=w("label",null,"Created:",-1)),w("span",null,O(r(e.apiCall.created)),1)]),e.apiCall.completed?(h(),C("div",at,[a[8]||(a[8]=w("label",null,"Completed:",-1)),w("span",null,O(r(e.apiCall.completed)),1)])):x("",!0),e.apiCall.completed?(h(),C("div",tt,[a[9]||(a[9]=w("label",null,"Duration:",-1)),w("span",null,O((o=e.apiCall.completed.getTime()-e.apiCall.created.getTime(),o<1e3?`${o}ms`:`${(o/1e3).toFixed(1)}s`)),1)])):x("",!0),e.apiCall.response?.latencyMs?(h(),C("div",nt,[a[10]||(a[10]=w("label",null,"API Latency:",-1)),w("span",null,O(e.apiCall.response.latencyMs)+"ms",1)])):x("",!0)])]),w("div",lt,[a[13]||(a[13]=w("h3",null,"Variables",-1)),w("div",rt,[(h(!0),C($,null,N(Object.entries(e.apiCall.variables),([e,a])=>(h(),C("div",{key:e,class:"variable-item"},[w("label",null,O(e)+":",1),w("span",st,O(a),1)]))),128))]),e.apiCall.variableAttributes&&Object.keys(e.apiCall.variableAttributes).length>0?(h(),C("div",ot,[a[12]||(a[12]=w("h4",null,"Variable Attributes",-1)),(h(!0),C($,null,N(Object.entries(e.apiCall.variableAttributes),([e,a])=>(h(),C("div",{key:e,class:"attribute-group"},[w("h5",null,O(e),1),w("div",it,[(h(!0),C($,null,N(Object.entries(a),([e,a])=>(h(),C("div",{key:e,class:"attribute-item"},[w("label",null,O(e)+":",1),w("span",null,O(a),1)]))),128))])]))),128))])):x("",!0)]),w("div",ct,[a[14]||(a[14]=w("h3",null,"Resolved Prompt",-1)),w("div",dt,O(e.apiCall.prompt),1)]),e.apiCall.response||e.apiCall.result?(h(),C("div",ut,[a[20]||(a[20]=w("h3",null,"Response",-1)),e.apiCall.response?(h(),C("div",pt,[w("div",mt,[w("div",ft,[a[15]||(a[15]=w("label",null,"HTTP Status:",-1)),w("span",null,O(e.apiCall.response.status),1)]),w("div",vt,[a[16]||(a[16]=w("label",null,"Latency:",-1)),w("span",null,O(e.apiCall.response.latencyMs)+"ms",1)])])])):x("",!0),e.apiCall.result?(h(),C("div",gt,[!1===e.apiCall.result.success?(h(),C("div",bt,[a[18]||(a[18]=w("h4",null,"Error",-1)),w("div",ht,O(e.apiCall.result.error),1),e.apiCall.response?(h(),C("div",_t,[a[17]||(a[17]=w("h5",null,"Raw Response:",-1)),w("pre",yt,O(JSON.stringify(e.apiCall.response,null,2)),1)])):x("",!0)])):x("",!0),e.apiCall.result.content?(h(),C("div",kt,[a[19]||(a[19]=w("h4",null,"Content",-1)),w("div",Ct,O(e.apiCall.result.content),1)])):x("",!0)])):x("",!0)])):x("",!0),w("div",xt,[a[21]||(a[21]=w("h3",null,"Raw Request",-1)),w("pre",wt,O(t.value),1)]),e.apiCall.response?(h(),C("div",St,[a[22]||(a[22]=w("h3",null,"Raw Response",-1)),w("pre",It,O(JSON.stringify(e.apiCall.response,null,2)),1)])):x("",!0)]),w("div",Pt,[k(n,{onClick:a[1]||(a[1]=a=>e.$emit("close")),size:"large",class:"footer-button","data-testid":"btn-close-modal-footer","aria-label":"Close modal"},{default:y(()=>a[23]||(a[23]=[A(" Close ")])),_:1,__:[23]}),k(n,{type:"primary",onClick:s,size:"large",class:"footer-button footer-button-primary","data-testid":"btn-copy-api-call-details","aria-label":"Copy API call details to clipboard"},{default:y(()=>a[24]||(a[24]=[A(" Copy Details ")])),_:1,__:[24]})])])]);var o}}}),[["__scopeId","data-v-d79e18d5"]]);function Et(e,a){const t=new Set,n=new Set,l=new Set;e.forEach(e=>{e.variables&&Object.keys(e.variables).forEach(e=>t.add(e)),e.variableAttributes&&Object.values(e.variableAttributes).forEach(e=>{e&&Object.keys(e).forEach(e=>n.add(e))})});const r=Array.from(t).sort(),s=Array.from(n).sort(),o=Array.from(l).sort(),i=[];a?.designSnapshot?.extractPattern&&i.push("extracted_value");const c=["success","refused",...i,...o];return{categorical:[...r,...s,"model","status","error_type"],numeric:["response_time","total_tokens","prompt_tokens","completion_tokens",...i].sort(),extracted:c}}function At(e,a,t){switch(a){case"model":if(t&&e.configurationIndex<t.configurationSnapshots.length){return t.configurationSnapshots[e.configurationIndex].modelId||"Unknown"}return"Unknown";case"status":return e.status;case"response_time":return e.response?.latencyMs||0;case"total_tokens":if(e.response?.body?.usage){const a=e.response.body.usage;return a.total_tokens||a.prompt_tokens+a.completion_tokens||0}return 0;case"prompt_tokens":return e.response?.body?.usage?.prompt_tokens||e.response?.body?.usage?.input_tokens||0;case"completion_tokens":return e.response?.body?.usage?.completion_tokens||e.response?.body?.usage?.output_tokens||0;case"error_type":return e.result?.errorType||(!1===e.result?.success?"api_error":"success");case"success":return e.result?.success?1:0;case"refused":return e.result?.refused?1:0;case"extracted_value":if(e.result?.success&&void 0!==e.result?.content){const a=String(e.result.content),t=parseFloat(a);return isNaN(t)?a:t}return null}if(void 0!==e.variables?.[a])return e.variables[a];if(e.variableAttributes)for(const n of Object.keys(e.variableAttributes)){const t=e.variableAttributes[n];if(t&&void 0!==t[a])return t[a]}return null}const Mt={count:{label:"Count",calculate:e=>e.length,format:e=>e.toString(),needsNumeric:!1},sum:{label:"Sum",calculate:e=>{const a=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return a.length>0?a.reduce((e,a)=>e+a,0):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mean:{label:"Mean",calculate:e=>{const a=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return a.length>0?a.reduce((e,a)=>e+a,0)/a.length:null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},median:{label:"Median",calculate:e=>{const a=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(0===a.length)return null;const t=[...a].sort((e,a)=>e-a),n=Math.floor(t.length/2);return t.length%2==0?(t[n-1]+t[n])/2:t[n]},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},mode:{label:"Mode",calculate:e=>{if(0===e.length)return null;const a=new Map;e.forEach(e=>a.set(e,(a.get(e)||0)+1));let t=0,n=null;return a.forEach((e,a)=>{e>t&&(t=e,n=a)}),{value:n,count:t,total:e.length}},format:e=>e?`${e.value} (${e.count}/${e.total})`:"-",needsNumeric:!1},variance:{label:"Variance",calculate:e=>{const a=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);if(a.length<=1)return null;const t=a.reduce((e,a)=>e+a,0)/a.length;return a.reduce((e,a)=>e+Math.pow(a-t,2),0)/(a.length-1)},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},std_dev:{label:"Std Dev",calculate:e=>{const a=Mt.variance.calculate(e);return null!==a?Math.sqrt(a):null},format:e=>e?.toFixed(3)||"-",needsNumeric:!0},min:{label:"Min",calculate:e=>{const a=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return a.length>0?Math.min(...a):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},max:{label:"Max",calculate:e=>{const a=e.map(e=>"number"==typeof e?e:null).filter(e=>null!==e);return a.length>0?Math.max(...a):null},format:e=>e?.toFixed(2)||"-",needsNumeric:!0},success_rate:{label:"Success Rate",calculate:(e,a)=>{const t=a.filter(e=>e.result?.success).length;return a.length>0?t/a.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},refusal_rate:{label:"Refusal Rate",calculate:(e,a)=>{const t=a.filter(e=>e.result?.refused).length;return a.length>0?t/a.length:0},format:e=>`${Math.round(100*e)}%`,needsNumeric:!1,usesApiCalls:!0},avg_time:{label:"Avg Time (ms)",calculate:(e,a)=>{const t=a.filter(e=>e.response?.latencyMs).map(e=>e.response.latencyMs);return t.length>0?t.reduce((e,a)=>e+a,0)/t.length:null},format:e=>e?`${Math.round(e)}ms`:"-",needsNumeric:!1,usesApiCalls:!0}};function $t(e,a){if(!e||null===e.value)return"-";return Mt[a].format(e.value)}const Nt={"blue-subtle":{name:"Blue (Subtle)",colors:["rgba(59, 130, 246, 0.1)","rgba(59, 130, 246, 0.3)","rgba(59, 130, 246, 0.7)"]},"green-red":{name:"Green-Red",colors:["#dc2626","#fbbf24","#10b981"]},"blue-yellow":{name:"Blue-Yellow",colors:["#1e40af","#3b82f6","#fbbf24"]},"purple-orange":{name:"Purple-Orange",colors:["#7c3aed","#a855f7","#ff9500"]},grayscale:{name:"Grayscale",colors:["#f3f4f6","#9ca3af","#374151"]},viridis:{name:"Viridis",colors:["#440154","#482878","#3e4989","#31688e","#26828e","#1f9e89","#35b779","#6ece58","#b5de2b","#fde725"]},inferno:{name:"Inferno",colors:["#000004","#1b0c41","#4a0c6b","#781c6d","#a52c60","#cf4446","#ed6925","#fb9b06","#f7d13d","#fcffa4"]},magma:{name:"Magma",colors:["#000004","#180f3d","#440f76","#721f81","#9e2f7f","#cd4071","#f1605d","#fd9668","#feca8d","#fcfdbf"]},plasma:{name:"Plasma",colors:["#0d0887","#46039f","#7201a8","#9c179e","#bd3786","#d8576b","#ed7953","#fb9f3a","#fdca26","#f0f921"]}};function Ot(e,a){if(0===a.length)return"transparent";if(1===a.length)return a[0];e=Math.max(0,Math.min(1,e));const t=1/(a.length-1),n=Math.floor(e/t),l=e%t/t;return Ft(a[Math.min(n,a.length-1)],a[Math.min(n+1,a.length-1)],l)}function Ft(e,a,t){if(e.startsWith("rgba")&&a.startsWith("rgba")){const n=e=>{const a=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);return a?{r:parseInt(a[1]),g:parseInt(a[2]),b:parseInt(a[3]),a:a[4]?parseFloat(a[4]):1}:null},l=n(e),r=n(a);if(l&&r){return`rgba(${Math.round(l.r+(r.r-l.r)*t)}, ${Math.round(l.g+(r.g-l.g)*t)}, ${Math.round(l.b+(r.b-l.b)*t)}, ${(l.a+(r.a-l.a)*t).toFixed(2)})`}}if(e.startsWith("rgba")||a.startsWith("rgba"))return t<.5?e:a;const n=e.replace("#",""),l=a.replace("#",""),r=parseInt(n.substr(0,2),16),s=parseInt(n.substr(2,2),16),o=parseInt(n.substr(4,2),16),i=parseInt(l.substr(0,2),16),c=parseInt(l.substr(2,2),16),d=parseInt(l.substr(4,2),16),u=Math.round(r+(i-r)*t),p=Math.round(s+(c-s)*t),m=Math.round(o+(d-o)*t);return`#${u.toString(16).padStart(2,"0")}${p.toString(16).padStart(2,"0")}${m.toString(16).padStart(2,"0")}`}function Rt(e){let a,t,n;if(e.startsWith("rgba")){const l=e.match(/rgba?\((\d+),\s*(\d+),\s*(\d+),?\s*([\d.]*)\)/);if(!l)return!1;a=parseInt(l[1]),t=parseInt(l[2]),n=parseInt(l[3])}else{const l="#"===e.charAt(0)?e.substring(1,7):e;a=parseInt(l.substring(0,2),16),t=parseInt(l.substring(2,4),16),n=parseInt(l.substring(4,6),16)}const l=[a/255,t/255,n/255].map(e=>e<=.03928?e/12.92:Math.pow((e+.055)/1.055,2.4));return.2126*l[0]+.7152*l[1]+.0722*l[2]<=.179}function jt(e){return Rt(e)?"#FFFFFF":"#000000"}function Dt(e,a,t){const{colorScales:n,interpolateColor:l,getContrastColor:r}={colorScales:Nt,interpolateColor:Ot,interpolateBetweenColors:Ft,colorIsDarkAdvanced:Rt,getContrastColor:jt};function s(e){if("number"==typeof e)return e;if("string"==typeof e){const a=parseFloat(e);return isNaN(a)?null:a}return null}return{getCellStyle:function(o,i,c){if(!o||null===o.value||"number"!=typeof o.value)return{};const d=n[a.value];if(!d)return{};const u=function(a,n,l){const r=s(a.value);if(null===r)return.5;if("global"===t.value){const a=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(a.length>0){const e=Math.min(...a),t=Math.max(...a);if(t!==e)return(r-e)/(t-e)}}else if("column"===t.value){const a=e.value.rows.map(e=>e.cells[l]).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(a.length>0){const e=Math.min(...a),t=Math.max(...a);if(t!==e)return(r-e)/(t-e)}}else if("row"===t.value){const a=e.value.rows.find(e=>e.label===n);if(a){const e=a.cells.filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(e.length>0){const a=Math.min(...e),t=Math.max(...e);if(t!==a)return(r-a)/(t-a)}}}return.5}(o,i,c),p=l(u,d.colors);return{backgroundColor:`${p} !important`,color:`${r(p)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},getSummaryStyle:function(t){if(!t||null===t.value||"number"!=typeof t.value)return{};const o=n[a.value];if(!o)return{};let i=.5;const c=e.value.rows.flatMap(e=>e.cells).filter(e=>null!==e).map(e=>s(e.value)).filter(e=>null!==e);if(c.length>0){const e=Math.min(...c),a=Math.max(...c),n=s(t.value);null!==n&&(i=a!==e?(n-e)/(a-e):.5)}const d=l(i,o.colors);return{backgroundColor:`${d} !important`,color:`${r(d)} !important`,fontSize:"15px !important",fontWeight:"600 !important"}},styleKey:P(()=>`${a.value}-${t.value}`)}}const qt={class:"pivot-config"},Ut={class:"config-row"},Lt={class:"config-group"},Bt=["value","aria-label"],zt={label:"Categorical"},Kt=["value"],Gt={class:"config-group"},Vt=["value","aria-label"],Yt={label:"Categorical"},Ht=["value"],Jt={class:"config-group"},Wt=["value","aria-label"],Xt={label:"Extracted Values"},Qt=["value"],Zt={label:"Numeric Fields"},en=["value"],an={class:"config-group"},tn=["value","aria-label"],nn=e(v({__name:"PivotConfiguration",props:{config:{},availableFields:{}},emits:["update-config"],setup(e,{emit:a}){const t=a;function n(e,a){t("update-config",e,a)}function l(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}return(e,a)=>(h(),C("div",qt,[w("div",Ut,[w("div",Lt,[a[4]||(a[4]=w("label",{for:"pivot-row-field"},"Rows (Group by):",-1)),w("select",{id:"pivot-row-field",value:e.config.rowField,"aria-label":"Group rows by "+l(e.config.rowField),onChange:a[0]||(a[0]=e=>n("rowField",e.target.value))},[w("optgroup",zt,[(h(!0),C($,null,N(e.availableFields.categorical,e=>(h(),C("option",{key:e,value:e},O(l(e)),9,Kt))),128))])],40,Bt)]),w("div",Gt,[a[5]||(a[5]=w("label",{for:"pivot-column-field"},"Columns (Group by):",-1)),w("select",{id:"pivot-column-field",value:e.config.columnField,"aria-label":"Group columns by "+l(e.config.columnField),onChange:a[1]||(a[1]=e=>n("columnField",e.target.value))},[w("optgroup",Yt,[(h(!0),C($,null,N(e.availableFields.categorical,e=>(h(),C("option",{key:e,value:e},O(l(e)),9,Ht))),128))])],40,Vt)]),w("div",Jt,[a[6]||(a[6]=w("label",{for:"pivot-value-field"},"Values (Aggregate):",-1)),w("select",{id:"pivot-value-field",value:e.config.valueField,"aria-label":"Aggregate "+e.config.valueField+" values",onChange:a[2]||(a[2]=e=>n("valueField",e.target.value))},[w("optgroup",Xt,[(h(!0),C($,null,N(e.availableFields.extracted,e=>(h(),C("option",{key:e,value:e},O(e),9,Qt))),128))]),w("optgroup",Zt,[(h(!0),C($,null,N(e.availableFields.numeric,e=>(h(),C("option",{key:e,value:e},O(l(e)),9,en))),128))])],40,Wt)]),w("div",an,[a[8]||(a[8]=w("label",{for:"pivot-aggregation"},"Aggregation:",-1)),w("select",{id:"pivot-aggregation",value:e.config.aggregation,"aria-label":"Aggregation method: "+e.config.aggregation,onChange:a[3]||(a[3]=e=>n("aggregation",e.target.value))},a[7]||(a[7]=[U('<optgroup label="Statistical" data-v-efb8a7c2><option value="mean" data-v-efb8a7c2>Mean</option><option value="median" data-v-efb8a7c2>Median</option><option value="variance" data-v-efb8a7c2>Variance</option><option value="std_dev" data-v-efb8a7c2>Std Dev</option><option value="min" data-v-efb8a7c2>Min</option><option value="max" data-v-efb8a7c2>Max</option></optgroup><optgroup label="Frequency" data-v-efb8a7c2><option value="count" data-v-efb8a7c2>Count</option><option value="mode" data-v-efb8a7c2>Mode</option></optgroup><optgroup label="Performance" data-v-efb8a7c2><option value="success_rate" data-v-efb8a7c2>Success Rate</option><option value="refusal_rate" data-v-efb8a7c2>Refusal Rate</option><option value="avg_time" data-v-efb8a7c2>Avg Time</option></optgroup>',3)]),40,tn)])])]))}}),[["__scopeId","data-v-efb8a7c2"]]),ln={class:"heatmap-controls"},rn={class:"color-scale-selector"},sn=["value","aria-label"],on={class:"gradient-mode-selector"},cn={class:"gradient-toggle",role:"group","aria-label":"Gradient mode selector"},dn=["aria-pressed"],un=["aria-pressed"],pn=["aria-pressed"],mn=["title","aria-label"],fn=e(v({__name:"PivotHeatmapControls",props:{selectedColorScale:{},gradientMode:{},isFullscreen:{type:Boolean}},emits:["update-color-scale","update-gradient-mode","toggle-fullscreen"],setup(e,{emit:a}){const t=a;function n(e){const a=e.target.value;t("update-color-scale",a)}function l(e){t("update-gradient-mode",e)}return(e,a)=>(h(),C("div",ln,[w("div",rn,[a[5]||(a[5]=w("label",{for:"heatmap-color-scale"},"Color Scale:",-1)),w("select",{id:"heatmap-color-scale",value:e.selectedColorScale,"aria-label":"Color scale: "+e.selectedColorScale,onChange:n},a[4]||(a[4]=[U('<option value="blue-subtle" data-v-4b4f9d62>Blue (Subtle)</option><option value="green-red" data-v-4b4f9d62>Green-Red (Success)</option><option value="blue-yellow" data-v-4b4f9d62>Blue-Yellow (Performance)</option><option value="purple-orange" data-v-4b4f9d62>Purple-Orange (General)</option><option value="viridis" data-v-4b4f9d62>Viridis</option><option value="inferno" data-v-4b4f9d62>Inferno</option><option value="magma" data-v-4b4f9d62>Magma</option><option value="plasma" data-v-4b4f9d62>Plasma</option><option value="grayscale" data-v-4b4f9d62>Grayscale</option>',9)]),40,sn)]),w("div",on,[a[6]||(a[6]=w("label",null,"Gradient Mode:",-1)),w("div",cn,[w("button",{type:"button",class:q(["toggle-btn",{active:"global"===e.gradientMode}]),"aria-pressed":"global"===e.gradientMode,onClick:a[0]||(a[0]=e=>l("global"))}," Global ",10,dn),w("button",{type:"button",class:q(["toggle-btn",{active:"column"===e.gradientMode}]),"aria-pressed":"column"===e.gradientMode,onClick:a[1]||(a[1]=e=>l("column"))}," Per Column ",10,un),w("button",{type:"button",class:q(["toggle-btn",{active:"row"===e.gradientMode}]),"aria-pressed":"row"===e.gradientMode,onClick:a[2]||(a[2]=e=>l("row"))}," Per Row ",10,pn)])]),w("button",{type:"button",class:"fullscreen-btn",title:e.isFullscreen?"Exit Fullscreen":"Enter Fullscreen","aria-label":e.isFullscreen?"Exit fullscreen mode":"Enter fullscreen mode",onClick:a[3]||(a[3]=a=>e.$emit("toggle-fullscreen"))},O(e.isFullscreen?"⊟":"⊞"),9,mn)]))}}),[["__scopeId","data-v-4b4f9d62"]]),vn={class:"filters-row"},gn={key:0,class:"filter-group"},bn=["value"],hn=["for"],_n=["id","onUpdate:modelValue","aria-label"],yn={value:""},kn=["value"],Cn={key:1,class:"filter-group"},xn=["value"],wn={class:"table-view"},Sn={key:0,class:"empty-state","data-testid":"empty-data-message"},In={key:1,class:"error-state","data-testid":"invalid-aggregation-error"},Pn={key:2,class:"pivot-table-container"},Tn={class:"pivot-table-grid responsive-table",role:"table"},En={role:"row"},An={class:"corner-cell",role:"columnheader"},Mn={key:0,class:"total-header",role:"columnheader"},$n={class:"row-header",role:"rowheader"},Nn=["data-testid","title","aria-label","role","onClick","onKeydown"],On={key:0,class:"cell-content"},Fn=["title"],Rn={class:"cell-value"},jn={class:"error-message"},Dn={key:1},qn=e(v({__name:"PivotTableCore",props:{apiCalls:{},trial:{default:null},config:{},maxTableRows:{default:1e4},showTotals:{type:Boolean,default:!0}},emits:["config-change","cell-click"],setup(e,{emit:a}){const t=e,l=a,r=I(!1),s=I("viridis"),o=I("global"),i=I({rowField:t.config?.rowField||"",columnField:t.config?.columnField||"",valueField:t.config?.valueField||"",aggregation:t.config?.aggregation||"mean"});L(()=>t.config,e=>{e&&Object.assign(i.value,e)},{deep:!0});const c=I({}),d=I([]),u=P(()=>Object.values(c.value).some(e=>""!==e)),p=B(Et(t.apiCalls,t.trial));let m=0;L(()=>t.apiCalls,e=>{if(0===e.length||0===m||e.length-m>=10){const a=d.value.length>0||u.value?d.value:e;p.value=Et(a,t.trial),m=e.length}},{immediate:!0});const f=B({});let v=0;L(()=>t.apiCalls.length,e=>{(0===e||0===v||e-v>=5)&&((()=>{if(0===t.apiCalls.length)return void(f.value={});const e={};t.apiCalls.forEach(a=>{if(t.trial&&a.configurationIndex<t.trial.configurationSnapshots.length){const n=t.trial.configurationSnapshots[a.configurationIndex].modelId||"Unknown";e.model||(e.model=new Set),e.model.add(n)}a.status&&(e.status||(e.status=new Set),e.status.add(a.status)),a.variables&&Object.entries(a.variables).forEach(([a,t])=>{t&&String(t).trim()&&(e[a]||(e[a]=new Set),e[a].add(String(t)))})});const a={};Object.entries(e).forEach(([e,t])=>{a[e]=Array.from(t).sort()}),f.value=a})(),v=e)},{immediate:!0});const g=P(()=>{const{model:e,status:a,...t}=f.value;return t});function b(){d.value=t.apiCalls.filter(e=>{if(c.value.model&&""!==c.value.model){if(!t.trial||e.configurationIndex>=t.trial.configurationSnapshots.length)return!1;if((t.trial.configurationSnapshots[e.configurationIndex].modelId||"Unknown")!==c.value.model)return!1}if(c.value.status&&""!==c.value.status&&e.status!==c.value.status)return!1;for(const[a,t]of Object.entries(c.value))if(t&&""!==t&&"model"!==a&&"status"!==a){const n=e.variables?.[a];if(n!==t)return!1}return!0})}function _(){c.value={},b()}L(()=>t.apiCalls,()=>{u.value?b():d.value=t.apiCalls},{immediate:!0});const y=P(()=>{const e=d.value.length>0||u.value?d.value:t.apiCalls;return 0===e.length?{rows:[],columns:[],totals:[],grandTotal:{value:0,count:0,apiCalls:[],rawValues:[]}}:function(e,a,t){const l=new Map,r=new Set,s=new Set;e.forEach(e=>{const n=String(At(e,a.rowField,t)||"Unknown"),o=String(At(e,a.columnField,t)||"Unknown");r.add(n),s.add(o),l.has(n)||l.set(n,new Map),l.get(n).has(o)||l.get(n).set(o,[]),l.get(n).get(o).push(e)});const o=e=>e.every(e=>!isNaN(Number(e))&&""!==e.trim())?e.sort((e,a)=>Number(e)-Number(a)):e.sort(),i=o(Array.from(r)),c=o(Array.from(s)),d=Mt[a.aggregation];function u(e){const l=e.map(e=>At(e,a.valueField,t));if(!d||"function"!=typeof d.calculate)return n.error("Invalid aggregation function:",a.aggregation,d),{value:null,count:e.length,apiCalls:e,rawValues:l,error:"Invalid aggregation function"};const r={nonNumeric:0,nullUndefined:0};return d.needsNumeric&&(r.nonNumeric=l.filter(e=>"number"!=typeof e).length),r.nullUndefined=l.filter(e=>null==e).length,{value:d.usesApiCalls?d.calculate(l,e):d.calculate(l),count:e.length,apiCalls:e,rawValues:l,excludedCounts:r}}const p=i.map(e=>{const a=[],t=[];return c.forEach(n=>{const r=l.get(e)?.get(n)||[];a.push(r.length>0?u(r):null),t.push(...r)}),{label:e,cells:a,total:u(t)}}),m=c.map(e=>{const a=[];return i.forEach(t=>{const n=l.get(t)?.get(e)||[];a.push(...n)}),u(a)});return{rows:p,columns:c,totals:m,grandTotal:u(e)}}(e,i.value,t.trial)}),S=P(()=>y.value.rows),{getCellStyle:T,getSummaryStyle:A,styleKey:F}=Dt(y,s,o);function R(e){return{model:"Model",status:"Status",response_time:"Response Time (ms)",total_tokens:"Total Tokens",prompt_tokens:"Prompt Tokens",completion_tokens:"Completion Tokens",error_type:"Error Type",success:"Success",refused:"Refused",extracted_value:"Extracted Value"}[e]||e.replace(/_/g," ").replace(/\b\w/g,e=>e.toUpperCase())}function j(e,a,t){if(!t)return`${e} × ${a}: No data`;let n=`${e} × ${a}: ${$t(t,i.value.aggregation)} (${t.count} calls)`;if(t.excludedCounts){const e=[];t.excludedCounts.nonNumeric>0&&e.push(`${t.excludedCounts.nonNumeric} non-numeric responses excluded`),t.excludedCounts.nullUndefined>0&&e.push(`${t.excludedCounts.nullUndefined} null/empty responses`),e.length>0&&(n+=` | ${e.join(", ")}`)}return t.error&&(n+=` - ERROR: ${t.error}`),n}function U(e,a,t){if(!t)return`${e} by ${a}: No data`;const n=$t(t,i.value.aggregation);return t.error?`${e} by ${a}: ${n} with data integrity error: ${t.error}`:`${e} by ${a}: ${n} from ${t.count} API calls`}function H(e,a){"rowField"!==e&&"columnField"!==e&&"valueField"!==e&&"aggregation"!==e||(i.value[e]=a),l("config-change",{...i.value})}function J(e,a,t){t&&l("cell-click",{row:e,column:a,cell:t})}function W(){r.value=!r.value,r.value?document.body.style.overflow="hidden":document.body.style.overflow=""}return E(()=>{r.value&&(document.body.style.overflow="")}),L([p,()=>t.apiCalls.length],([e])=>{t.apiCalls.length>0&&(!i.value.rowField||""===i.value.rowField)&&e.categorical.length>0&&(i.value.rowField=e.categorical.find(e=>"model"!==e&&"status"!==e&&"error_type"!==e)||e.categorical[0]||"model",i.value.columnField=i.value.columnField||"model",i.value.valueField=i.value.valueField||"success",i.value.aggregation=i.value.aggregation||"mean",l("config-change",{...i.value}))},{immediate:!0}),(e,a)=>(h(),C("div",{class:q(["pivot-table-core",{fullscreen:r.value}])},[z([p.value,i.value],()=>(h(),C("div",null,[k(nn,{config:i.value,"available-fields":p.value,onUpdateConfig:H},null,8,["config","available-fields"])])),a,0),k(fn,{"selected-color-scale":s.value,"gradient-mode":o.value,"is-fullscreen":r.value,onUpdateColorScale:a[1]||(a[1]=e=>s.value=e),onUpdateGradientMode:a[2]||(a[2]=e=>o.value=e),onToggleFullscreen:W},null,8,["selected-color-scale","gradient-mode","is-fullscreen"]),Object.keys(f.value).length>0?z([f.value,c.value],()=>(h(),C("div",{key:0,class:"data-filters"},[w("div",vn,[f.value.model&&f.value.model.length>1?(h(),C("div",gn,[a[7]||(a[7]=w("label",{for:"filter-model",class:"filter-label"},"Model:",-1)),V(w("select",{id:"filter-model","onUpdate:modelValue":a[3]||(a[3]=e=>c.value.model=e),class:"filter-select","aria-label":"Filter by model",onChange:b},[a[6]||(a[6]=w("option",{value:""},"All Models",-1)),(h(!0),C($,null,N(f.value.model,e=>(h(),C("option",{key:e,value:e},O(e),9,bn))),128))],544),[[Y,c.value.model]])])):x("",!0),(h(!0),C($,null,N(g.value,(e,a)=>(h(),C("div",{key:a,class:"filter-group"},[w("label",{for:`filter-${a}`,class:"filter-label"},O(R(String(a)))+": ",9,hn),V(w("select",{id:`filter-${a}`,"onUpdate:modelValue":e=>c.value[a]=e,class:"filter-select","aria-label":`Filter by ${R(String(a))}`,onChange:b},[w("option",yn,"All "+O(R(String(a))),1),(h(!0),C($,null,N(e,e=>(h(),C("option",{key:e,value:e},O(e),9,kn))),128))],40,_n),[[Y,c.value[a]]])]))),128)),f.value.status&&f.value.status.length>1?(h(),C("div",Cn,[a[9]||(a[9]=w("label",{for:"filter-status",class:"filter-label"},"Status:",-1)),V(w("select",{id:"filter-status","onUpdate:modelValue":a[4]||(a[4]=e=>c.value.status=e),class:"filter-select","aria-label":"Filter by status",onChange:b},[a[8]||(a[8]=w("option",{value:""},"All Statuses",-1)),(h(!0),C($,null,N(f.value.status,e=>(h(),C("option",{key:e,value:e},O(e),9,xn))),128))],544),[[Y,c.value.status]])])):x("",!0),u.value?(h(),C("button",{key:2,type:"button",class:"clear-filters-btn",title:"Clear all filters","aria-label":"Clear all filters",onClick:_}," Clear Filters ")):x("",!0)])])),a,5):x("",!0),w("div",wn,[0===t.apiCalls.length?(h(),C("div",Sn,a[10]||(a[10]=[w("p",null,"No data available for pivot table analysis.",-1)]))):i.value.aggregation in M(Mt)?(h(),C("div",Pn,[w("table",Tn,[w("thead",null,[w("tr",En,[w("th",An,O(R(i.value.rowField)||"Items")+" / "+O(R(i.value.columnField)||"Aggregated"),1),(h(!0),C($,null,N(y.value.columns,e=>(h(),C("th",{key:e,class:"column-header",role:"columnheader"},O(e),1))),128)),i.value.columnField&&e.showTotals?(h(),C("th",Mn," Total ")):x("",!0)])]),w("tbody",null,[(h(!0),C($,null,N(S.value,a=>(h(),C("tr",{key:`${a.label}-${M(F)}`,class:"data-row",role:"row"},[w("td",$n,O(a.label),1),(h(!0),C($,null,N(a.cells,(e,t)=>(h(),C("td",{key:`${t}-${M(F)}`,class:q(["data-cell",{"error-cell":e?.error}]),"data-testid":e?.error?"pivot-cell-error":"pivot-cell",style:G(M(T)(e,a.label,t)),title:j(a.label,y.value.columns[t],e),"aria-label":U(a.label,y.value.columns[t],e),role:e?.error?"alert":"cell",tabindex:"0",onClick:n=>J(a.label,y.value.columns[t],e),onKeydown:[K(n=>J(a.label,y.value.columns[t],e),["enter"]),K(D(n=>J(a.label,y.value.columns[t],e),["prevent"]),["space"])]},[e?.error?(h(),C("div",On,[w("span",{class:"error-indicator",title:e.error},"⚠️",8,Fn),w("span",Rn,O(e?M($t)(e,i.value.aggregation):"-"),1),w("div",jn,O(e.error),1)])):(h(),C("span",Dn,O(e?M($t)(e,i.value.aggregation):"-"),1))],46,Nn))),128)),i.value.columnField&&e.showTotals?(h(),C("td",{key:0,class:"total-cell",style:G(M(A)(a.total)),role:"cell"},O(M($t)(a.total,i.value.aggregation)),5)):x("",!0)]))),128)),i.value.rowField&&e.showTotals?(h(),C("tr",{key:`totals-${M(F)}`,class:"total-row",role:"row"},[a[12]||(a[12]=w("td",{class:"row-header",role:"rowheader"},"Total",-1)),(h(!0),C($,null,N(y.value.totals,(e,a)=>(h(),C("td",{key:`total-${a}-${M(F)}`,class:"total-cell",style:G(M(A)(e)),role:"cell"},O(M($t)(e,i.value.aggregation)),5))),128)),i.value.columnField?(h(),C("td",{key:0,class:"grand-total-cell",style:G(M(A)(y.value.grandTotal)),role:"cell"},O(M($t)(y.value.grandTotal,i.value.aggregation)),5)):x("",!0)])):x("",!0)])])])):(h(),C("div",In,[w("p",null,"Invalid aggregation function: "+O(i.value.aggregation),1),a[11]||(a[11]=w("p",null,"Please select a valid aggregation method.",-1))]))])],2))}}),[["__scopeId","data-v-ffa2e33b"]]);export{Tt as A,qn as P,ga as T,Ea as _,Ka as a,Oa as p};
